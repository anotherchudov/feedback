{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61afee34",
   "metadata": {},
   "source": [
    "# run training\n",
    "\n",
    "> notebook to run the `train.py` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f259f5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T02:58:00.112394Z",
     "start_time": "2022-02-26T02:58:00.108480Z"
    }
   },
   "outputs": [],
   "source": [
    "install_pytorch = False\n",
    "if install_pytorch:\n",
    "    !pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio===0.8.1 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c8c22e",
   "metadata": {},
   "source": [
    "## Single GPU\n",
    "\n",
    "baseline + consine one cycle scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80571bec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:27:54.135896Z",
     "start_time": "2022-03-03T01:01:01.646464Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mducky\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmorning-cloud-93\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ducky/feedback_deberta_large\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ducky/feedback_deberta_large/runs/etwt2tak\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /home/feedback/working/feedback_ducky/baselinev1/wandb/run-20220303_010104-etwt2tak\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
      "\n",
      "Namespace(batch_size=6, ce_weight=0.9, cnn1d=False, cycle_mult=1.0, data_prefix='', dataset_path='../../feedback-prize-2021', dataset_version=2, ddp=False, decay_bias=False, device=device(type='cuda', index=2), dropout_ratio=0.0, epochs=9, extra_dense=False, gamma=0.8, global_attn=False, grad_acc_steps=1, grad_checkpt=True, label_smoothing=0.1, local_rank=-1, lr=1e-05, max_grad_norm=1.0, min_len=0, min_lr=1e-06, model='microsoft/deberta-v3-large', momentum=0.9, nesterov=True, num_worker=8, print_acc=500, rank=-1, rce_weight=0.1, save_path='result', seed=0, start_eval_at=0, swa=True, swa_update_per_epoch=3, use_groupped_weights=False, val_fold=0, wandb_comment='swa_batchsize6_plateau_nogradaccu_maxgrad1.0_amp', wandb_project='feedback_deberta_large', wandb_user='ducky', warmup_steps=500, weight_decay=0.01, weights_pow=0.1)\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[ TRAIN ] epoch 1 lr 0.0000100 acc: 0.4057 loss:  1.4165:  24%|‚ñè| 499/2076 [12:0Epoch: 1 | Step: 500 | Train Acc per class: tensor([3.4580e-01, 4.7907e-01, 6.9656e-01, 2.5025e-01, 4.5673e-01, 3.1504e-01,\n",
      "        9.0875e-01, 3.7806e-01, 4.4267e-01, 3.9724e-01, 8.4055e-01, 9.0580e-04,\n",
      "        1.5691e-01, 0.0000e+00, 9.1641e-02, 7.3556e-01])\n",
      "[ TRAIN ] epoch 1 lr 0.0000100 acc: 0.4927 loss:  1.3228:  48%|‚ñç| 999/2076 [22:5Epoch: 1 | Step: 1000 | Train Acc per class: tensor([0.3831, 0.6730, 0.7698, 0.4381, 0.5438, 0.4173, 0.9140, 0.4646, 0.4869,\n",
      "        0.5223, 0.8841, 0.1101, 0.3042, 0.0025, 0.2058, 0.7659])\n",
      "[ TRAIN ] epoch 1 lr 0.0000100 acc: 0.5421 loss:  1.2794:  72%|‚ñã| 1499/2076 [34:Epoch: 1 | Step: 1500 | Train Acc per class: tensor([0.4000, 0.7468, 0.8006, 0.5155, 0.5777, 0.4616, 0.9143, 0.5046, 0.5150,\n",
      "        0.5876, 0.8993, 0.2316, 0.3782, 0.0747, 0.2872, 0.7792])\n",
      "[ TRAIN ] epoch 1 lr 0.0000100 acc: 0.5750 loss:  1.2501:  96%|‚ñâ| 1999/2076 [45:Epoch: 1 | Step: 2000 | Train Acc per class: tensor([0.4127, 0.7855, 0.8162, 0.5578, 0.6013, 0.4923, 0.9157, 0.5278, 0.5316,\n",
      "        0.6241, 0.9087, 0.3115, 0.4272, 0.1646, 0.3369, 0.7883])\n",
      "[ TRAIN ] epoch 1 lr 0.0000100 acc: 0.5788 loss:  1.2471: 100%|‚ñà| 2076/2076 [46:\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 524/524 [02:10<00:00,  4.00it/s]\n",
      "Valid Acc per class: tensor([0.4254, 0.9432, 0.8697, 0.7022, 0.6559, 0.6398, 0.9052, 0.6607, 0.6431,\n",
      "        0.7891, 0.9649, 0.5699, 0.5491, 0.5242, 0.4064, 0.8150])\n",
      "0.6358018436795028\n",
      "save model .....\n",
      "[ TRAIN ] epoch 2 lr 0.0000100 acc: 0.7092 loss:  1.1091:  24%|‚ñè| 499/2076 [11:4Epoch: 2 | Step: 500 | Train Acc per class: tensor([0.4818, 0.9279, 0.9031, 0.7166, 0.7141, 0.6062, 0.9251, 0.6122, 0.6045,\n",
      "        0.7700, 0.9428, 0.5878, 0.6291, 0.5330, 0.5614, 0.8310])\n",
      "[ TRAIN ] epoch 2 lr 0.0000100 acc: 0.7074 loss:  1.1138:  48%|‚ñç| 999/2076 [23:1Epoch: 2 | Step: 1000 | Train Acc per class: tensor([0.4878, 0.9207, 0.8927, 0.7141, 0.7094, 0.6029, 0.9256, 0.6206, 0.6063,\n",
      "        0.7708, 0.9439, 0.5976, 0.6109, 0.5395, 0.5447, 0.8312])\n",
      "[ TRAIN ] epoch 2 lr 0.0000100 acc: 0.7087 loss:  1.1131:  72%|‚ñã| 1499/2076 [34:Epoch: 2 | Step: 1500 | Train Acc per class: tensor([0.4916, 0.9214, 0.8948, 0.7203, 0.7116, 0.6040, 0.9254, 0.6235, 0.6075,\n",
      "        0.7775, 0.9460, 0.5998, 0.6057, 0.5435, 0.5346, 0.8316])\n",
      "[ TRAIN ] epoch 2 lr 0.0000100 acc: 0.7112 loss:  1.1122:  96%|‚ñâ| 1999/2076 [45:Epoch: 2 | Step: 2000 | Train Acc per class: tensor([0.4985, 0.9219, 0.8940, 0.7197, 0.7095, 0.6076, 0.9252, 0.6262, 0.6077,\n",
      "        0.7807, 0.9474, 0.6053, 0.6113, 0.5507, 0.5418, 0.8323])\n",
      "[ TRAIN ] epoch 2 lr 0.0000100 acc: 0.7110 loss:  1.1120: 100%|‚ñà| 2076/2076 [47:\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 524/524 [02:10<00:00,  4.00it/s]\n",
      "Valid Acc per class: tensor([0.5109, 0.9207, 0.8711, 0.7279, 0.6709, 0.6354, 0.9060, 0.6688, 0.6283,\n",
      "        0.7866, 0.9629, 0.5976, 0.5890, 0.5634, 0.5160, 0.8228])\n",
      "0.6541308223885673\n",
      "save model .....\n",
      "[ TRAIN ] epoch 3 lr 0.0000100 acc: 0.7614 loss:  1.0476:  24%|‚ñè| 499/2076 [11:4Epoch: 3 | Step: 500 | Train Acc per class: tensor([0.5155, 0.9451, 0.9261, 0.7719, 0.7899, 0.6613, 0.9319, 0.6660, 0.6651,\n",
      "        0.8012, 0.9598, 0.6918, 0.7078, 0.6500, 0.6483, 0.8542])\n",
      "[ TRAIN ] epoch 3 lr 0.0000100 acc: 0.7615 loss:  1.0431:  48%|‚ñç| 999/2076 [22:5Epoch: 3 | Step: 1000 | Train Acc per class: tensor([0.5242, 0.9414, 0.9281, 0.7686, 0.7840, 0.6584, 0.9338, 0.6659, 0.6617,\n",
      "        0.8054, 0.9604, 0.6829, 0.7104, 0.6447, 0.6552, 0.8566])\n",
      "[ TRAIN ] epoch 3 lr 0.0000100 acc: 0.7599 loss:  1.0440:  72%|‚ñã| 1499/2076 [34:Epoch: 3 | Step: 1500 | Train Acc per class: tensor([0.5271, 0.9378, 0.9260, 0.7701, 0.7747, 0.6571, 0.9329, 0.6659, 0.6620,\n",
      "        0.8110, 0.9590, 0.6893, 0.7060, 0.6431, 0.6413, 0.8554])\n",
      "[ TRAIN ] epoch 3 lr 0.0000100 acc: 0.7588 loss:  1.0451:  96%|‚ñâ| 1999/2076 [45:Epoch: 3 | Step: 2000 | Train Acc per class: tensor([0.5336, 0.9364, 0.9231, 0.7687, 0.7734, 0.6523, 0.9323, 0.6646, 0.6616,\n",
      "        0.8123, 0.9593, 0.6850, 0.7009, 0.6392, 0.6423, 0.8553])\n",
      "[ TRAIN ] epoch 3 lr 0.0000100 acc: 0.7584 loss:  1.0452: 100%|‚ñà| 2076/2076 [47:\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 524/524 [02:10<00:00,  4.01it/s]\n",
      "Valid Acc per class: tensor([0.5343, 0.9197, 0.8772, 0.7388, 0.6874, 0.6283, 0.9042, 0.6692, 0.6150,\n",
      "        0.7902, 0.9570, 0.6204, 0.6106, 0.5945, 0.5545, 0.8233])\n",
      "0.6639675594513227\n",
      "save model .....\n",
      "[ TRAIN ] epoch 4 lr 0.0000100 acc: 0.8070 loss:  0.9757:  24%|‚ñè| 499/2076 [11:3Epoch: 4 | Step: 500 | Train Acc per class: tensor([0.6004, 0.9466, 0.9484, 0.8048, 0.8289, 0.6934, 0.9424, 0.7017, 0.7299,\n",
      "        0.8435, 0.9705, 0.7574, 0.7834, 0.7450, 0.7304, 0.8821])\n",
      "[ TRAIN ] epoch 4 lr 0.0000100 acc: 0.8042 loss:  0.9794:  48%|‚ñç| 999/2076 [23:1Epoch: 4 | Step: 1000 | Train Acc per class: tensor([0.5794, 0.9484, 0.9454, 0.8051, 0.8258, 0.6956, 0.9420, 0.7023, 0.7263,\n",
      "        0.8482, 0.9706, 0.7556, 0.7756, 0.7266, 0.7385, 0.8799])\n",
      "[ TRAIN ] epoch 4 lr 0.0000100 acc: 0.8031 loss:  0.9827:  72%|‚ñã| 1499/2076 [34:Epoch: 4 | Step: 1500 | Train Acc per class: tensor([0.5721, 0.9514, 0.9462, 0.8036, 0.8222, 0.6941, 0.9421, 0.7002, 0.7216,\n",
      "        0.8474, 0.9705, 0.7510, 0.7793, 0.7269, 0.7424, 0.8790])\n",
      "[ TRAIN ] epoch 4 lr 0.0000100 acc: 0.8009 loss:  0.9834:  96%|‚ñâ| 1999/2076 [45:Epoch: 4 | Step: 2000 | Train Acc per class: tensor([0.5718, 0.9513, 0.9473, 0.8024, 0.8201, 0.6920, 0.9413, 0.7017, 0.7217,\n",
      "        0.8456, 0.9707, 0.7437, 0.7745, 0.7185, 0.7321, 0.8786])\n",
      "[ TRAIN ] epoch 4 lr 0.0000100 acc: 0.8007 loss:  0.9833: 100%|‚ñà| 2076/2076 [47:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 524/524 [02:10<00:00,  4.01it/s]\n",
      "Valid Acc per class: tensor([0.5443, 0.9175, 0.8805, 0.7411, 0.6911, 0.6312, 0.9022, 0.6614, 0.6126,\n",
      "        0.7935, 0.9515, 0.6347, 0.6305, 0.6164, 0.5717, 0.8232])\n",
      "0.6685944150063275\n",
      "save model .....\n",
      "[ TRAIN ] epoch 5 lr 0.0000100 acc: 0.8320 loss:  0.9315:  24%|‚ñè| 499/2076 [11:4Epoch: 5 | Step: 500 | Train Acc per class: tensor([0.6324, 0.9626, 0.9690, 0.8288, 0.8667, 0.7363, 0.9513, 0.7288, 0.7779,\n",
      "        0.8614, 0.9750, 0.7816, 0.8129, 0.7444, 0.7792, 0.9002])\n",
      "[ TRAIN ] epoch 5 lr 0.0000100 acc: 0.8338 loss:  0.9298:  48%|‚ñç| 999/2076 [23:0Epoch: 5 | Step: 1000 | Train Acc per class: tensor([0.6365, 0.9632, 0.9661, 0.8319, 0.8687, 0.7275, 0.9509, 0.7325, 0.7734,\n",
      "        0.8571, 0.9738, 0.7878, 0.8218, 0.7564, 0.7920, 0.9001])\n",
      "[ TRAIN ] epoch 5 lr 0.0000100 acc: 0.8323 loss:  0.9307:  72%|‚ñã| 1499/2076 [34:Epoch: 5 | Step: 1500 | Train Acc per class: tensor([0.6295, 0.9627, 0.9643, 0.8324, 0.8672, 0.7294, 0.9504, 0.7308, 0.7729,\n",
      "        0.8612, 0.9744, 0.7862, 0.8180, 0.7526, 0.7865, 0.8990])\n",
      "[ TRAIN ] epoch 5 lr 0.0000100 acc: 0.8329 loss:  0.9304:  96%|‚ñâ| 1999/2076 [45:Epoch: 5 | Step: 2000 | Train Acc per class: tensor([0.6302, 0.9612, 0.9622, 0.8323, 0.8642, 0.7315, 0.9507, 0.7323, 0.7753,\n",
      "        0.8624, 0.9750, 0.7858, 0.8181, 0.7567, 0.7879, 0.8996])\n",
      "[ TRAIN ] epoch 5 lr 0.0000100 acc: 0.8329 loss:  0.9303: 100%|‚ñà| 2076/2076 [47:\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 524/524 [02:10<00:00,  4.01it/s]\n",
      "Valid Acc per class: tensor([0.5518, 0.9186, 0.8821, 0.7456, 0.6936, 0.6361, 0.8959, 0.6642, 0.6195,\n",
      "        0.7965, 0.9493, 0.6473, 0.6442, 0.6233, 0.5917, 0.8219])\n",
      "0.6714201360953614\n",
      "save model .....\n",
      "[ TRAIN ] epoch 6 lr 0.0000100 acc: 0.8657 loss:  0.8839:  24%|‚ñè| 499/2076 [12:1Epoch: 6 | Step: 500 | Train Acc per class: tensor([0.6709, 0.9696, 0.9726, 0.8548, 0.8935, 0.7670, 0.9598, 0.7644, 0.8267,\n",
      "        0.8760, 0.9830, 0.8276, 0.8726, 0.8199, 0.8725, 0.9191])\n",
      "[ TRAIN ] epoch 6 lr 0.0000100 acc: 0.8618 loss:  0.8885:  48%|‚ñç| 999/2076 [23:3Epoch: 6 | Step: 1000 | Train Acc per class: tensor([0.6868, 0.9662, 0.9678, 0.8557, 0.8910, 0.7633, 0.9595, 0.7629, 0.8179,\n",
      "        0.8836, 0.9818, 0.8152, 0.8634, 0.8014, 0.8537, 0.9178])\n",
      "[ TRAIN ] epoch 6 lr 0.0000100 acc: 0.8611 loss:  0.8896:  72%|‚ñã| 1499/2076 [34:Epoch: 6 | Step: 1500 | Train Acc per class: tensor([0.6863, 0.9664, 0.9685, 0.8524, 0.8895, 0.7623, 0.9590, 0.7612, 0.8174,\n",
      "        0.8786, 0.9812, 0.8215, 0.8671, 0.8050, 0.8441, 0.9172])\n",
      "[ TRAIN ] epoch 6 lr 0.0000100 acc: 0.8597 loss:  0.8901:  96%|‚ñâ| 1999/2076 [45:Epoch: 6 | Step: 2000 | Train Acc per class: tensor([0.6822, 0.9670, 0.9693, 0.8509, 0.8879, 0.7644, 0.9591, 0.7615, 0.8172,\n",
      "        0.8763, 0.9808, 0.8149, 0.8652, 0.7982, 0.8427, 0.9170])\n",
      "[ TRAIN ] epoch 6 lr 0.0000100 acc: 0.8596 loss:  0.8899: 100%|‚ñà| 2076/2076 [47:\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 524/524 [02:10<00:00,  4.01it/s]\n",
      "Valid Acc per class: tensor([0.5572, 0.9186, 0.8810, 0.7449, 0.6972, 0.6334, 0.8955, 0.6632, 0.6165,\n",
      "        0.7961, 0.9448, 0.6490, 0.6450, 0.6290, 0.5967, 0.8213])\n",
      "0.6739975650762652\n",
      "save model .....\n",
      "[ TRAIN ] epoch 7 lr 0.0000100 acc: 0.8815 loss:  0.8550:  24%|‚ñè| 499/2076 [11:5Epoch: 7 | Step: 500 | Train Acc per class: tensor([0.7325, 0.9786, 0.9779, 0.8724, 0.9186, 0.7947, 0.9672, 0.7756, 0.8552,\n",
      "        0.8863, 0.9844, 0.8554, 0.8979, 0.8051, 0.8722, 0.9320])\n",
      "[ TRAIN ] epoch 7 lr 0.0000100 acc: 0.8819 loss:  0.8543:  48%|‚ñç| 999/2076 [22:5Epoch: 7 | Step: 1000 | Train Acc per class: tensor([0.7346, 0.9745, 0.9775, 0.8709, 0.9175, 0.7951, 0.9674, 0.7816, 0.8558,\n",
      "        0.8850, 0.9834, 0.8419, 0.8888, 0.8196, 0.8831, 0.9329])\n",
      "[ TRAIN ] epoch 7 lr 0.0000100 acc: 0.8814 loss:  0.8546:  72%|‚ñã| 1499/2076 [34:Epoch: 7 | Step: 1500 | Train Acc per class: tensor([0.7281, 0.9714, 0.9770, 0.8731, 0.9187, 0.7966, 0.9672, 0.7811, 0.8534,\n",
      "        0.8840, 0.9832, 0.8418, 0.8867, 0.8243, 0.8834, 0.9325])\n",
      "[ TRAIN ] epoch 7 lr 0.0000100 acc: 0.8804 loss:  0.8558:  96%|‚ñâ| 1999/2076 [45:Epoch: 7 | Step: 2000 | Train Acc per class: tensor([0.7317, 0.9716, 0.9764, 0.8708, 0.9156, 0.7963, 0.9666, 0.7825, 0.8518,\n",
      "        0.8868, 0.9833, 0.8403, 0.8882, 0.8155, 0.8767, 0.9318])\n",
      "[ TRAIN ] epoch 7 lr 0.0000100 acc: 0.8805 loss:  0.8559: 100%|‚ñà| 2076/2076 [47:\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 524/524 [02:10<00:00,  4.01it/s]\n",
      "Valid Acc per class: tensor([0.5649, 0.9186, 0.8784, 0.7446, 0.6990, 0.6349, 0.8923, 0.6601, 0.6188,\n",
      "        0.7961, 0.9424, 0.6481, 0.6414, 0.6290, 0.5919, 0.8198])\n",
      "0.67420387058754\n",
      "save model .....\n",
      "[ TRAIN ] epoch 8 lr 0.0000100 acc: 0.8990 loss:  0.8272:  24%|‚ñè| 499/2076 [11:3Epoch: 8 | Step: 500 | Train Acc per class: tensor([0.7871, 0.9768, 0.9799, 0.8855, 0.9357, 0.8263, 0.9736, 0.8023, 0.8831,\n",
      "        0.8875, 0.9822, 0.8557, 0.9220, 0.8417, 0.8980, 0.9454])\n",
      "[ TRAIN ] epoch 8 lr 0.0000100 acc: 0.8993 loss:  0.8266:  48%|‚ñç| 999/2076 [22:5Epoch: 8 | Step: 1000 | Train Acc per class: tensor([0.7833, 0.9755, 0.9801, 0.8888, 0.9343, 0.8230, 0.9734, 0.8082, 0.8866,\n",
      "        0.8954, 0.9840, 0.8622, 0.9151, 0.8338, 0.9005, 0.9456])\n",
      "[ TRAIN ] epoch 8 lr 0.0000100 acc: 0.8981 loss:  0.8278:  72%|‚ñã| 1499/2076 [34:Epoch: 8 | Step: 1500 | Train Acc per class: tensor([0.7811, 0.9761, 0.9808, 0.8864, 0.9327, 0.8235, 0.9739, 0.8064, 0.8838,\n",
      "        0.8951, 0.9848, 0.8564, 0.9096, 0.8347, 0.8997, 0.9454])\n",
      "[ TRAIN ] epoch 8 lr 0.0000100 acc: 0.8976 loss:  0.8303:  96%|‚ñâ| 1999/2076 [45:Epoch: 8 | Step: 2000 | Train Acc per class: tensor([0.7755, 0.9756, 0.9810, 0.8886, 0.9336, 0.8202, 0.9728, 0.8060, 0.8819,\n",
      "        0.8961, 0.9848, 0.8546, 0.9089, 0.8358, 0.9018, 0.9441])\n",
      "[ TRAIN ] epoch 8 lr 0.0000100 acc: 0.8971 loss:  0.8307: 100%|‚ñà| 2076/2076 [47:\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 524/524 [02:10<00:00,  4.01it/s]\n",
      "Valid Acc per class: tensor([0.5685, 0.9197, 0.8785, 0.7427, 0.6970, 0.6350, 0.8926, 0.6572, 0.6192,\n",
      "        0.7939, 0.9384, 0.6515, 0.6396, 0.6302, 0.5826, 0.8195])\n",
      "0.6771013873279637\n",
      "save model .....\n",
      "[ TRAIN ] epoch 9 lr 0.0000100 acc: 0.9117 loss:  0.8078:  24%|‚ñè| 499/2076 [12:0Epoch: 9 | Step: 500 | Train Acc per class: tensor([0.8137, 0.9758, 0.9843, 0.8921, 0.9481, 0.8371, 0.9777, 0.8228, 0.9080,\n",
      "        0.9046, 0.9889, 0.8815, 0.9255, 0.8541, 0.9186, 0.9543])\n",
      "[ TRAIN ] epoch 9 lr 0.0000100 acc: 0.9100 loss:  0.8104:  41%|‚ñç| 859/2076 [20:0\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ReadTimeout), entering retry loop.\n",
      "[ TRAIN ] epoch 9 lr 0.0000100 acc: 0.9096 loss:  0.8110:  48%|‚ñç| 999/2076 [23:1Epoch: 9 | Step: 1000 | Train Acc per class: tensor([0.8111, 0.9770, 0.9846, 0.8932, 0.9422, 0.8370, 0.9769, 0.8219, 0.9011,\n",
      "        0.9039, 0.9885, 0.8681, 0.9212, 0.8560, 0.9181, 0.9525])\n",
      "[ TRAIN ] epoch 9 lr 0.0000100 acc: 0.9096 loss:  0.8113:  72%|‚ñã| 1499/2076 [34:Epoch: 9 | Step: 1500 | Train Acc per class: tensor([0.8011, 0.9764, 0.9841, 0.8943, 0.9430, 0.8373, 0.9773, 0.8225, 0.9004,\n",
      "        0.9063, 0.9881, 0.8701, 0.9200, 0.8594, 0.9218, 0.9521])\n",
      "[ TRAIN ] epoch 9 lr 0.0000100 acc: 0.9093 loss:  0.8117:  96%|‚ñâ| 1999/2076 [45:Epoch: 9 | Step: 2000 | Train Acc per class: tensor([0.7998, 0.9765, 0.9829, 0.8944, 0.9436, 0.8373, 0.9773, 0.8225, 0.8999,\n",
      "        0.9041, 0.9877, 0.8716, 0.9222, 0.8565, 0.9195, 0.9520])\n",
      "[ TRAIN ] epoch 9 lr 0.0000100 acc: 0.9093 loss:  0.8118: 100%|‚ñà| 2076/2076 [47:\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 524/524 [02:10<00:00,  4.02it/s]\n",
      "Valid Acc per class: tensor([0.5705, 0.9197, 0.8775, 0.7420, 0.6937, 0.6351, 0.8921, 0.6547, 0.6156,\n",
      "        0.7924, 0.9362, 0.6507, 0.6376, 0.6359, 0.5830, 0.8185])\n",
      "0.6774677344325172\n",
      "save model .....\n",
      "save model .....\n",
      "0.6774677344325172\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 1181166... (success).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                      ValSWA_ACC#ALL ‚ñÅ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  ValSWA_ACC#Claim_B ‚ñÑ‚ñà‚ñà‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  ValSWA_ACC#Claim_I ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ValSWA_ACC#Concluding Statement_B ‚ñÉ‚ñÅ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñÜ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ValSWA_ACC#Concluding Statement_I ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           ValSWA_ACC#Counterclaim_B ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           ValSWA_ACC#Counterclaim_I ‚ñÅ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               ValSWA_ACC#Evidence_B ‚ñà‚ñÖ‚ñÅ‚ñÉ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               ValSWA_ACC#Evidence_I ‚ñà‚ñà‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   ValSWA_ACC#Lead_B ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   ValSWA_ACC#Lead_I ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     ValSWA_ACC#None ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               ValSWA_ACC#Position_B ‚ñÅ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               ValSWA_ACC#Position_I ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               ValSWA_ACC#Rebuttal_B ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               ValSWA_ACC#Rebuttal_I ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          ValSWA_A_B ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          ValSWA_A_I ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       ValSWA_A_MEAN ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     ValSWA_F1_Claim ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  ValSWA_F1_Evidence ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                      ValSWA_F1_Lead ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  ValSWA_F1_Position ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                      ValSWA_MacroF1 ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   ValSWA_Prec_Claim ‚ñÇ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                ValSWA_Prec_Evidence ‚ñÅ‚ñÑ‚ñà‚ñÑ‚ñÖ‚ñá‚ñÉ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                    ValSWA_Prec_Lead ‚ñÅ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                ValSWA_Prec_Position ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                    ValSWA_Rec_Claim ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 ValSWA_Rec_Evidence ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     ValSWA_Rec_Lead ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 ValSWA_Rec_Position ‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÜ‚ñá‚ñá‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                           ValSWA_ce ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                      ValSWA_ACC#ALL 0.81847\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  ValSWA_ACC#Claim_B 0.65466\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  ValSWA_ACC#Claim_I 0.61564\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ValSWA_ACC#Concluding Statement_B 0.79243\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ValSWA_ACC#Concluding Statement_I 0.93619\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           ValSWA_ACC#Counterclaim_B 0.65067\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           ValSWA_ACC#Counterclaim_I 0.6376\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               ValSWA_ACC#Evidence_B 0.63511\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               ValSWA_ACC#Evidence_I 0.89214\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   ValSWA_ACC#Lead_B 0.91966\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   ValSWA_ACC#Lead_I 0.87753\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     ValSWA_ACC#None 0.57053\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               ValSWA_ACC#Position_B 0.74204\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               ValSWA_ACC#Position_I 0.69373\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               ValSWA_ACC#Rebuttal_B 0.63594\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               ValSWA_ACC#Rebuttal_I 0.58301\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          ValSWA_A_B 0.71865\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          ValSWA_A_I 0.7258\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       ValSWA_A_MEAN 0.72246\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     ValSWA_F1_Claim 0.45668\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  ValSWA_F1_Evidence 0.55377\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                      ValSWA_F1_Lead 0.6987\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  ValSWA_F1_Position 0.63582\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                      ValSWA_MacroF1 0.67747\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   ValSWA_Prec_Claim 0.40951\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                ValSWA_Prec_Evidence 0.51717\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                    ValSWA_Prec_Lead 0.67848\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                ValSWA_Prec_Position 0.61636\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                    ValSWA_Rec_Claim 0.51613\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 ValSWA_Rec_Evidence 0.59596\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     ValSWA_Rec_Lead 0.72017\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 ValSWA_Rec_Position 0.65654\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                           ValSWA_ce 0.83536\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mmorning-cloud-93\u001b[0m: \u001b[34mhttps://wandb.ai/ducky/feedback_deberta_large/runs/etwt2tak\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: ./wandb/run-20220303_010104-etwt2tak/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n"
     ]
    }
   ],
   "source": [
    "!python train.py --device 2 --wandb_comment \"swa_batchsize6_plateau_nogradaccu_maxgrad1.0_amp\" --grad_acc_steps 1 --lr 1e-5 --swa --max_grad_norm 1.0 --batch_size 6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "282.242px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
