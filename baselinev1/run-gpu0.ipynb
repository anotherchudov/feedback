{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61afee34",
   "metadata": {},
   "source": [
    "# run training\n",
    "\n",
    "> notebook to run the `train.py` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f259f5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T02:58:00.112394Z",
     "start_time": "2022-02-26T02:58:00.108480Z"
    }
   },
   "outputs": [],
   "source": [
    "install_pytorch = False\n",
    "if install_pytorch:\n",
    "    !pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio===0.8.1 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c8c22e",
   "metadata": {},
   "source": [
    "## Single GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80571bec",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-03T02:21:54.754Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mducky\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfloral-moon-102\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ducky/feedback_deberta_large\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ducky/feedback_deberta_large/runs/360ykgiu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /home/feedback/working/feedback_ducky/baselinev1/wandb/run-20220303_022157-360ykgiu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
      "\n",
      "Namespace(batch_size=4, ce_weight=0.9, cnn1d=False, cycle_mult=1.0, data_prefix='', dataset_path='../../feedback-prize-2021', dataset_version=2, ddp=False, decay_bias=False, device=device(type='cuda', index=0), dropout_ratio=0.0, epochs=9, extra_dense=False, gamma=0.8, global_attn=False, grad_acc_steps=1, grad_checkpt=True, label_smoothing=0.1, local_rank=-1, lr=1e-05, max_grad_norm=1.0, min_len=0, min_lr=1e-06, model='microsoft/deberta-v3-large', momentum=0.9, nesterov=True, num_worker=8, print_acc=500, rank=-1, rce_weight=0.1, save_path='result', seed=0, start_eval_at=0, swa=True, swa_update_per_epoch=3, use_groupped_weights=False, val_fold=0, wandb_comment='swa_plateau_nogradaccu_maxgrad1.0_amp_with_relpos_1clamp', wandb_project='feedback_deberta_large', wandb_user='ducky', warmup_steps=500, weight_decay=0.01, weights_pow=0.1)\n",
      "Using Ducky Mofified DebertaV2\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[ TRAIN ] epoch 1 lr 0.0000100 acc: 0.3907 loss:  1.4344:  16%|‚ñè| 499/3114 [07:3Epoch: 1 | Step: 500 | Train Acc per class: tensor([0.3413, 0.4649, 0.6809, 0.2141, 0.4331, 0.2975, 0.9112, 0.3620, 0.4375,\n",
      "        0.3738, 0.8304, 0.0000, 0.1260, 0.0000, 0.0568, 0.7300])\n",
      "[ TRAIN ] epoch 1 lr 0.0000100 acc: 0.4853 loss:  1.3333:  32%|‚ñé| 999/3114 [14:4Epoch: 1 | Step: 1000 | Train Acc per class: tensor([0.3739, 0.6643, 0.7660, 0.4128, 0.5230, 0.4016, 0.9163, 0.4570, 0.4851,\n",
      "        0.5189, 0.8838, 0.0828, 0.3016, 0.0027, 0.2093, 0.7653])\n",
      "[ TRAIN ] epoch 1 lr 0.0000100 acc: 0.5274 loss:  1.2933:  48%|‚ñç| 1499/3114 [21:Epoch: 1 | Step: 1500 | Train Acc per class: tensor([0.3903, 0.7410, 0.7917, 0.4979, 0.5640, 0.4446, 0.9169, 0.4960, 0.5046,\n",
      "        0.5730, 0.8996, 0.1849, 0.3582, 0.0344, 0.2654, 0.7771])\n",
      "[ TRAIN ] epoch 1 lr 0.0000100 acc: 0.5571 loss:  1.2674:  64%|‚ñã| 1999/3114 [28:Epoch: 1 | Step: 2000 | Train Acc per class: tensor([0.4001, 0.7783, 0.8090, 0.5452, 0.5898, 0.4738, 0.9164, 0.5194, 0.5186,\n",
      "        0.6081, 0.9066, 0.2628, 0.3971, 0.0962, 0.3086, 0.7843])\n",
      "[ TRAIN ] epoch 1 lr 0.0000100 acc: 0.5821 loss:  1.2464:  80%|‚ñä| 2499/3114 [35:Epoch: 1 | Step: 2500 | Train Acc per class: tensor([0.4119, 0.8049, 0.8241, 0.5752, 0.6040, 0.4945, 0.9167, 0.5382, 0.5329,\n",
      "        0.6364, 0.9135, 0.3267, 0.4353, 0.1595, 0.3502, 0.7908])\n",
      "[ TRAIN ] epoch 1 lr 0.0000100 acc: 0.5977 loss:  1.2324:  96%|‚ñâ| 2999/3114 [42:Epoch: 1 | Step: 3000 | Train Acc per class: tensor([0.4174, 0.8192, 0.8295, 0.5913, 0.6145, 0.5095, 0.9169, 0.5496, 0.5419,\n",
      "        0.6539, 0.9166, 0.3684, 0.4597, 0.2095, 0.3730, 0.7947])\n",
      "[ TRAIN ] epoch 1 lr 0.0000100 acc: 0.6009 loss:  1.2297: 100%|‚ñà| 3114/3114 [44:\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 785/785 [02:06<00:00,  6.20it/s]\n",
      "Valid Acc per class: tensor([0.4686, 0.9288, 0.8271, 0.7417, 0.6946, 0.6229, 0.8884, 0.7023, 0.6955,\n",
      "        0.7748, 0.9379, 0.6254, 0.5823, 0.5300, 0.4918, 0.8132])\n",
      "0.6374599178639665\n",
      "save model .....\n",
      "[ TRAIN ] epoch 2 lr 0.0000100 acc: 0.7236 loss:  1.0984:  16%|‚ñè| 499/3114 [07:2Epoch: 2 | Step: 500 | Train Acc per class: tensor([0.4847, 0.9340, 0.9109, 0.7245, 0.7118, 0.6223, 0.9271, 0.6311, 0.6221,\n",
      "        0.7710, 0.9467, 0.6267, 0.6656, 0.5573, 0.6085, 0.8364])\n",
      "[ TRAIN ] epoch 2 lr 0.0000100 acc: 0.7174 loss:  1.1030:  32%|‚ñé| 999/3114 [14:2Epoch: 2 | Step: 1000 | Train Acc per class: tensor([0.4867, 0.9295, 0.9022, 0.7245, 0.7209, 0.6102, 0.9261, 0.6356, 0.6206,\n",
      "        0.7807, 0.9466, 0.6188, 0.6260, 0.5360, 0.5794, 0.8351])\n",
      "[ TRAIN ] epoch 2 lr 0.0000100 acc: 0.7161 loss:  1.1043:  48%|‚ñç| 1499/3114 [21:Epoch: 2 | Step: 1500 | Train Acc per class: tensor([0.4902, 0.9252, 0.9016, 0.7227, 0.7200, 0.6114, 0.9265, 0.6366, 0.6187,\n",
      "        0.7735, 0.9484, 0.6187, 0.6155, 0.5419, 0.5703, 0.8357])\n",
      "[ TRAIN ] epoch 2 lr 0.0000100 acc: 0.7165 loss:  1.1044:  64%|‚ñã| 1999/3114 [28:Epoch: 2 | Step: 2000 | Train Acc per class: tensor([0.4919, 0.9264, 0.9023, 0.7264, 0.7223, 0.6131, 0.9263, 0.6359, 0.6166,\n",
      "        0.7784, 0.9489, 0.6188, 0.6164, 0.5423, 0.5621, 0.8351])\n",
      "[ TRAIN ] epoch 2 lr 0.0000100 acc: 0.7179 loss:  1.1021:  80%|‚ñä| 2499/3114 [36:Epoch: 2 | Step: 2500 | Train Acc per class: tensor([0.4975, 0.9261, 0.9012, 0.7290, 0.7229, 0.6136, 0.9265, 0.6375, 0.6178,\n",
      "        0.7791, 0.9503, 0.6209, 0.6175, 0.5515, 0.5575, 0.8361])\n",
      "[ TRAIN ] epoch 2 lr 0.0000100 acc: 0.7185 loss:  1.1026:  96%|‚ñâ| 2999/3114 [43:Epoch: 2 | Step: 3000 | Train Acc per class: tensor([0.5021, 0.9260, 0.8995, 0.7278, 0.7194, 0.6167, 0.9259, 0.6376, 0.6179,\n",
      "        0.7819, 0.9505, 0.6228, 0.6184, 0.5537, 0.5600, 0.8360])\n",
      "[ TRAIN ] epoch 2 lr 0.0000100 acc: 0.7181 loss:  1.1023: 100%|‚ñà| 3114/3114 [45:\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 785/785 [02:06<00:00,  6.22it/s]\n",
      "Valid Acc per class: tensor([0.5187, 0.9170, 0.8590, 0.7317, 0.6940, 0.6320, 0.8979, 0.6785, 0.6504,\n",
      "        0.7884, 0.9585, 0.6414, 0.5937, 0.5899, 0.5498, 0.8220])\n",
      "0.6650329329777288\n",
      "save model .....\n",
      "[ TRAIN ] epoch 3 lr 0.0000100 acc: 0.7774 loss:  1.0244:  16%|‚ñè| 499/3114 [07:4Epoch: 3 | Step: 500 | Train Acc per class: tensor([0.5212, 0.9499, 0.9408, 0.7886, 0.8081, 0.6800, 0.9368, 0.6849, 0.6932,\n",
      "        0.8201, 0.9678, 0.7132, 0.7229, 0.6776, 0.6707, 0.8653])\n",
      "[ TRAIN ] epoch 3 lr 0.0000100 acc: 0.7726 loss:  1.0292:  32%|‚ñé| 999/3114 [14:4Epoch: 3 | Step: 1000 | Train Acc per class: tensor([0.5287, 0.9477, 0.9367, 0.7796, 0.8039, 0.6697, 0.9341, 0.6806, 0.6873,\n",
      "        0.8191, 0.9647, 0.7050, 0.7151, 0.6581, 0.6698, 0.8623])\n",
      "[ TRAIN ] epoch 3 lr 0.0000100 acc: 0.7717 loss:  1.0300:  48%|‚ñç| 1499/3114 [21:Epoch: 3 | Step: 1500 | Train Acc per class: tensor([0.5330, 0.9442, 0.9344, 0.7775, 0.7987, 0.6694, 0.9352, 0.6826, 0.6836,\n",
      "        0.8179, 0.9635, 0.6967, 0.7177, 0.6578, 0.6707, 0.8627])\n",
      "[ TRAIN ] epoch 3 lr 0.0000100 acc: 0.7712 loss:  1.0298:  64%|‚ñã| 1999/3114 [29:Epoch: 3 | Step: 2000 | Train Acc per class: tensor([0.5321, 0.9426, 0.9346, 0.7797, 0.7936, 0.6682, 0.9357, 0.6794, 0.6813,\n",
      "        0.8209, 0.9636, 0.7026, 0.7164, 0.6576, 0.6660, 0.8626])\n",
      "[ TRAIN ] epoch 3 lr 0.0000100 acc: 0.7709 loss:  1.0307:  80%|‚ñä| 2499/3114 [36:Epoch: 3 | Step: 2500 | Train Acc per class: tensor([0.5382, 0.9407, 0.9330, 0.7808, 0.7899, 0.6677, 0.9353, 0.6787, 0.6814,\n",
      "        0.8214, 0.9633, 0.7062, 0.7213, 0.6559, 0.6588, 0.8623])\n",
      "[ TRAIN ] epoch 3 lr 0.0000100 acc: 0.7698 loss:  1.0322:  96%|‚ñâ| 2999/3114 [43:Epoch: 3 | Step: 3000 | Train Acc per class: tensor([0.5395, 0.9414, 0.9323, 0.7789, 0.7884, 0.6648, 0.9347, 0.6779, 0.6790,\n",
      "        0.8234, 0.9634, 0.7021, 0.7156, 0.6532, 0.6602, 0.8616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ TRAIN ] epoch 3 lr 0.0000100 acc: 0.7695 loss:  1.0323: 100%|‚ñà| 3114/3114 [44:\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 785/785 [02:06<00:00,  6.22it/s]\n",
      "Valid Acc per class: tensor([0.5355, 0.9218, 0.8740, 0.7362, 0.6950, 0.6313, 0.9013, 0.6696, 0.6328,\n",
      "        0.7957, 0.9510, 0.6498, 0.6301, 0.6198, 0.5975, 0.8247])\n",
      "0.6727480811978551\n",
      "save model .....\n",
      "[ TRAIN ] epoch 4 lr 0.0000100 acc: 0.8183 loss:  0.9575:  16%|‚ñè| 499/3114 [07:1Epoch: 4 | Step: 500 | Train Acc per class: tensor([0.6083, 0.9478, 0.9516, 0.8170, 0.8477, 0.7149, 0.9478, 0.7175, 0.7546,\n",
      "        0.8432, 0.9712, 0.7629, 0.8083, 0.7371, 0.7760, 0.8903])\n",
      "[ TRAIN ] epoch 4 lr 0.0000100 acc: 0.8198 loss:  0.9567:  32%|‚ñé| 999/3114 [14:3Epoch: 4 | Step: 1000 | Train Acc per class: tensor([0.6097, 0.9541, 0.9523, 0.8235, 0.8452, 0.7189, 0.9473, 0.7202, 0.7532,\n",
      "        0.8491, 0.9736, 0.7746, 0.8032, 0.7372, 0.7634, 0.8911])\n",
      "[ TRAIN ] epoch 4 lr 0.0000100 acc: 0.8193 loss:  0.9607:  48%|‚ñç| 1499/3114 [21:Epoch: 4 | Step: 1500 | Train Acc per class: tensor([0.5964, 0.9551, 0.9528, 0.8230, 0.8431, 0.7168, 0.9461, 0.7230, 0.7549,\n",
      "        0.8528, 0.9743, 0.7773, 0.7976, 0.7361, 0.7687, 0.8896])\n",
      "[ TRAIN ] epoch 4 lr 0.0000100 acc: 0.8172 loss:  0.9649:  64%|‚ñã| 1999/3114 [29:Epoch: 4 | Step: 2000 | Train Acc per class: tensor([0.5923, 0.9560, 0.9524, 0.8192, 0.8394, 0.7157, 0.9457, 0.7206, 0.7504,\n",
      "        0.8543, 0.9736, 0.7737, 0.7942, 0.7347, 0.7647, 0.8882])\n",
      "[ TRAIN ] epoch 4 lr 0.0000100 acc: 0.8149 loss:  0.9673:  80%|‚ñä| 2499/3114 [36:Epoch: 4 | Step: 2500 | Train Acc per class: tensor([0.5876, 0.9569, 0.9523, 0.8159, 0.8362, 0.7137, 0.9456, 0.7197, 0.7461,\n",
      "        0.8517, 0.9723, 0.7692, 0.7958, 0.7297, 0.7594, 0.8871])\n",
      "[ TRAIN ] epoch 4 lr 0.0000100 acc: 0.8131 loss:  0.9678:  96%|‚ñâ| 2999/3114 [43:Epoch: 4 | Step: 3000 | Train Acc per class: tensor([0.5869, 0.9558, 0.9521, 0.8156, 0.8367, 0.7119, 0.9453, 0.7193, 0.7445,\n",
      "        0.8493, 0.9722, 0.7651, 0.7906, 0.7235, 0.7545, 0.8866])\n",
      "[ TRAIN ] epoch 4 lr 0.0000100 acc: 0.8130 loss:  0.9677: 100%|‚ñà| 3114/3114 [44:\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 785/785 [02:06<00:00,  6.22it/s]\n",
      "Valid Acc per class: tensor([0.5460, 0.9218, 0.8767, 0.7404, 0.6994, 0.6318, 0.8974, 0.6690, 0.6357,\n",
      "        0.7957, 0.9455, 0.6557, 0.6428, 0.6198, 0.6023, 0.8238])\n",
      "0.6759237074046922\n",
      "save model .....\n",
      "[ TRAIN ] epoch 5 lr 0.0000100 acc: 0.8495 loss:  0.9160:  16%|‚ñè| 499/3114 [07:2Epoch: 5 | Step: 500 | Train Acc per class: tensor([0.6585, 0.9668, 0.9673, 0.8524, 0.8782, 0.7567, 0.9557, 0.7597, 0.8065,\n",
      "        0.8626, 0.9806, 0.8135, 0.8289, 0.7768, 0.8232, 0.9102])\n",
      "[ TRAIN ] epoch 5 lr 0.0000100 acc: 0.8483 loss:  0.9165:  32%|‚ñé| 999/3114 [14:4Epoch: 5 | Step: 1000 | Train Acc per class: tensor([0.6523, 0.9669, 0.9663, 0.8489, 0.8806, 0.7517, 0.9556, 0.7572, 0.8064,\n",
      "        0.8675, 0.9795, 0.8124, 0.8421, 0.7604, 0.8161, 0.9100])\n",
      "[ TRAIN ] epoch 5 lr 0.0000100 acc: 0.8482 loss:  0.9139:  48%|‚ñç| 1499/3114 [21:Epoch: 5 | Step: 1500 | Train Acc per class: tensor([0.6586, 0.9640, 0.9660, 0.8451, 0.8775, 0.7505, 0.9555, 0.7562, 0.8039,\n",
      "        0.8637, 0.9780, 0.8108, 0.8430, 0.7654, 0.8218, 0.9098])\n",
      "[ TRAIN ] epoch 5 lr 0.0000100 acc: 0.8472 loss:  0.9152:  64%|‚ñã| 1999/3114 [28:Epoch: 5 | Step: 2000 | Train Acc per class: tensor([0.6537, 0.9647, 0.9641, 0.8446, 0.8789, 0.7521, 0.9552, 0.7539, 0.8011,\n",
      "        0.8653, 0.9783, 0.8109, 0.8403, 0.7636, 0.8196, 0.9088])\n",
      "[ TRAIN ] epoch 5 lr 0.0000100 acc: 0.8465 loss:  0.9155:  80%|‚ñä| 2499/3114 [35:Epoch: 5 | Step: 2500 | Train Acc per class: tensor([0.6540, 0.9639, 0.9629, 0.8437, 0.8769, 0.7536, 0.9556, 0.7541, 0.8012,\n",
      "        0.8655, 0.9773, 0.8020, 0.8414, 0.7665, 0.8176, 0.9088])\n",
      "[ TRAIN ] epoch 5 lr 0.0000100 acc: 0.8467 loss:  0.9151:  96%|‚ñâ| 2999/3114 [43:Epoch: 5 | Step: 3000 | Train Acc per class: tensor([0.6522, 0.9628, 0.9630, 0.8433, 0.8759, 0.7534, 0.9559, 0.7551, 0.8014,\n",
      "        0.8662, 0.9776, 0.8023, 0.8425, 0.7686, 0.8171, 0.9091])\n",
      "[ TRAIN ] epoch 5 lr 0.0000100 acc: 0.8466 loss:  0.9153: 100%|‚ñà| 3114/3114 [44:\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 785/785 [02:06<00:00,  6.22it/s]\n",
      "Valid Acc per class: tensor([0.5534, 0.9250, 0.8780, 0.7385, 0.7016, 0.6333, 0.8930, 0.6708, 0.6381,\n",
      "        0.7954, 0.9418, 0.6540, 0.6436, 0.6152, 0.6079, 0.8221])\n",
      "0.6767374972150363\n",
      "save model .....\n",
      "[ TRAIN ] epoch 6 lr 0.0000100 acc: 0.8803 loss:  0.8697:  16%|‚ñè| 499/3114 [07:4Epoch: 6 | Step: 500 | Train Acc per class: tensor([0.6998, 0.9722, 0.9757, 0.8638, 0.9189, 0.7902, 0.9667, 0.7911, 0.8494,\n",
      "        0.8801, 0.9817, 0.8566, 0.8927, 0.8330, 0.8829, 0.9295])\n",
      "[ TRAIN ] epoch 6 lr 0.0000100 acc: 0.8753 loss:  0.8741:  32%|‚ñé| 999/3114 [14:5Epoch: 6 | Step: 1000 | Train Acc per class: tensor([0.6967, 0.9675, 0.9738, 0.8666, 0.9116, 0.7876, 0.9656, 0.7838, 0.8453,\n",
      "        0.8789, 0.9819, 0.8386, 0.8881, 0.8183, 0.8725, 0.9274])\n",
      "[ TRAIN ] epoch 6 lr 0.0000100 acc: 0.8743 loss:  0.8732:  48%|‚ñç| 1499/3114 [22:Epoch: 6 | Step: 1500 | Train Acc per class: tensor([0.7035, 0.9682, 0.9720, 0.8665, 0.9093, 0.7895, 0.9657, 0.7862, 0.8461,\n",
      "        0.8834, 0.9819, 0.8344, 0.8780, 0.8115, 0.8657, 0.9274])\n",
      "[ TRAIN ] epoch 6 lr 0.0000100 acc: 0.8729 loss:  0.8723:  64%|‚ñã| 1999/3114 [29:Epoch: 6 | Step: 2000 | Train Acc per class: tensor([0.7036, 0.9679, 0.9721, 0.8656, 0.9071, 0.7880, 0.9655, 0.7851, 0.8460,\n",
      "        0.8817, 0.9820, 0.8302, 0.8774, 0.8080, 0.8586, 0.9272])\n",
      "[ TRAIN ] epoch 6 lr 0.0000100 acc: 0.8730 loss:  0.8735:  80%|‚ñä| 2499/3114 [36:Epoch: 6 | Step: 2500 | Train Acc per class: tensor([0.7003, 0.9686, 0.9723, 0.8626, 0.9060, 0.7867, 0.9651, 0.7851, 0.8456,\n",
      "        0.8825, 0.9820, 0.8346, 0.8811, 0.8110, 0.8582, 0.9267])\n",
      "[ TRAIN ] epoch 6 lr 0.0000100 acc: 0.8731 loss:  0.8730:  96%|‚ñâ| 2999/3114 [43:Epoch: 6 | Step: 3000 | Train Acc per class: tensor([0.7009, 0.9687, 0.9736, 0.8652, 0.9076, 0.7872, 0.9650, 0.7839, 0.8450,\n",
      "        0.8809, 0.9816, 0.8312, 0.8806, 0.8097, 0.8611, 0.9269])\n",
      "[ TRAIN ] epoch 6 lr 0.0000100 acc: 0.8731 loss:  0.8727: 100%|‚ñà| 3114/3114 [44:\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 785/785 [02:06<00:00,  6.22it/s]\n",
      "Valid Acc per class: tensor([0.5610, 0.9229, 0.8788, 0.7372, 0.6968, 0.6312, 0.8930, 0.6678, 0.6331,\n",
      "        0.7957, 0.9392, 0.6490, 0.6394, 0.6152, 0.6007, 0.8213])\n",
      "0.6779921003593046\n",
      "save model .....\n",
      "[ TRAIN ] epoch 7 lr 0.0000100 acc: 0.8920 loss:  0.8430:  16%|‚ñè| 499/3114 [07:3Epoch: 7 | Step: 500 | Train Acc per class: tensor([0.7555, 0.9810, 0.9759, 0.8794, 0.9281, 0.8153, 0.9706, 0.7983, 0.8790,\n",
      "        0.8796, 0.9846, 0.8692, 0.9015, 0.8248, 0.8926, 0.9392])\n",
      "[ TRAIN ] epoch 7 lr 0.0000100 acc: 0.8905 loss:  0.8435:  32%|‚ñé| 999/3114 [14:3Epoch: 7 | Step: 1000 | Train Acc per class: tensor([0.7531, 0.9771, 0.9793, 0.8791, 0.9271, 0.8174, 0.9704, 0.7948, 0.8795,\n",
      "        0.8780, 0.9839, 0.8618, 0.8937, 0.8233, 0.8902, 0.9394])\n",
      "[ TRAIN ] epoch 7 lr 0.0000100 acc: 0.8919 loss:  0.8435:  48%|‚ñç| 1499/3114 [21:Epoch: 7 | Step: 1500 | Train Acc per class: tensor([0.7519, 0.9771, 0.9790, 0.8792, 0.9280, 0.8168, 0.9708, 0.7996, 0.8779,\n",
      "        0.8842, 0.9835, 0.8621, 0.8942, 0.8329, 0.8930, 0.9397])\n",
      "[ TRAIN ] epoch 7 lr 0.0000100 acc: 0.8916 loss:  0.8422:  64%|‚ñã| 1999/3114 [28:Epoch: 7 | Step: 2000 | Train Acc per class: tensor([0.7496, 0.9746, 0.9785, 0.8794, 0.9262, 0.8160, 0.9713, 0.8019, 0.8772,\n",
      "        0.8870, 0.9842, 0.8586, 0.8944, 0.8303, 0.8949, 0.9400])\n",
      "[ TRAIN ] epoch 7 lr 0.0000100 acc: 0.8914 loss:  0.8423:  70%|‚ñã| 2186/3114 [31:"
     ]
    }
   ],
   "source": [
    "!python train.py --wandb_comment \"swa_plateau_nogradaccu_maxgrad1.0_amp_with_relpos_1clamp\" --grad_acc_steps 1 --lr 1e-5 --swa --max_grad_norm 1.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "282.242px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
