{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61afee34",
   "metadata": {},
   "source": [
    "# run training\n",
    "\n",
    "> notebook to run the `train.py` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f259f5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T02:58:00.112394Z",
     "start_time": "2022-02-26T02:58:00.108480Z"
    }
   },
   "outputs": [],
   "source": [
    "install_pytorch = False\n",
    "if install_pytorch:\n",
    "    !pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio===0.8.1 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c8c22e",
   "metadata": {},
   "source": [
    "## Single GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80571bec",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-02T00:47:15.789Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mducky\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfearless-grass-75\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ducky/feedback_deberta_large\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ducky/feedback_deberta_large/runs/3logkj0s\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /home/feedback/working/feedback_ducky/baselinev1/wandb/run-20220302_004717-3logkj0s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
      "\n",
      "Namespace(batch_size=4, ce_weight=0.9, cnn1d=False, cycle_mult=1.0, data_prefix='', dataset_path='../../feedback-prize-2021', dataset_version=2, ddp=False, decay_bias=False, device=device(type='cuda', index=0), dropout_ratio=0.0, epochs=9, extra_dense=False, gamma=0.8, global_attn=False, grad_acc_steps=1, grad_checkpt=True, label_smoothing=0.1, local_rank=-1, lr=1e-05, max_grad_norm=1.0, min_len=0, min_lr=1e-06, model='microsoft/deberta-v3-large', momentum=0.9, nesterov=True, num_worker=8, print_acc=500, rank=-1, rce_weight=0.1, save_path='result', seed=0, start_eval_at=0, swa=True, swa_update_per_epoch=3, use_groupped_weights=False, val_fold=0, wandb_comment='swa_plateau_no_grad_accumulation_maxgrad1.0', wandb_project='feedback_deberta_large', wandb_user='ducky', warmup_steps=500, weight_decay=0.01, weights_pow=0.1)\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[ TRAIN ] epoch 1 lr 0.0000100 acc: 0.3729 loss:  1.4509:  16%|‚ñè| 499/3114 [07:3Epoch: 1 | Step: 500 | Train Acc per class: tensor([0.3372, 0.3997, 0.6497, 0.2045, 0.4113, 0.2799, 0.9126, 0.3221, 0.4180,\n",
      "        0.3508, 0.8240, 0.0000, 0.0996, 0.0000, 0.0431, 0.7230])\n",
      "[ TRAIN ] epoch 1 lr 0.0000100 acc: 0.4723 loss:  1.3456:  32%|‚ñé| 999/3114 [14:3Epoch: 1 | Step: 1000 | Train Acc per class: tensor([3.7174e-01, 6.3403e-01, 7.5071e-01, 4.0571e-01, 5.1501e-01, 3.9289e-01,\n",
      "        9.1669e-01, 4.2831e-01, 4.7232e-01, 4.9352e-01, 8.7739e-01, 5.5631e-02,\n",
      "        2.8188e-01, 8.9206e-04, 1.9858e-01, 7.6068e-01])\n",
      "[ TRAIN ] epoch 1 lr 0.0000100 acc: 0.5176 loss:  1.3017:  48%|‚ñç| 1499/3114 [21:Epoch: 1 | Step: 1500 | Train Acc per class: tensor([0.3881, 0.7201, 0.7799, 0.4913, 0.5605, 0.4396, 0.9171, 0.4750, 0.4962,\n",
      "        0.5570, 0.8961, 0.1528, 0.3428, 0.0313, 0.2603, 0.7740])\n",
      "[ TRAIN ] epoch 1 lr 0.0000100 acc: 0.5497 loss:  1.2734:  64%|‚ñã| 1999/3114 [28:Epoch: 1 | Step: 2000 | Train Acc per class: tensor([0.3981, 0.7643, 0.8003, 0.5383, 0.5861, 0.4709, 0.9173, 0.5028, 0.5138,\n",
      "        0.5976, 0.9042, 0.2358, 0.3862, 0.0915, 0.3064, 0.7825])\n",
      "[ TRAIN ] epoch 1 lr 0.0000100 acc: 0.5761 loss:  1.2515:  80%|‚ñä| 2499/3114 [35:Epoch: 1 | Step: 2500 | Train Acc per class: tensor([0.4102, 0.7942, 0.8158, 0.5708, 0.6014, 0.4915, 0.9168, 0.5238, 0.5288,\n",
      "        0.6288, 0.9107, 0.3033, 0.4269, 0.1584, 0.3485, 0.7889])\n",
      "[ TRAIN ] epoch 1 lr 0.0000100 acc: 0.5925 loss:  1.2373:  96%|‚ñâ| 2999/3114 [42:Epoch: 1 | Step: 3000 | Train Acc per class: tensor([0.4165, 0.8089, 0.8225, 0.5879, 0.6116, 0.5064, 0.9170, 0.5365, 0.5381,\n",
      "        0.6477, 0.9151, 0.3473, 0.4512, 0.2101, 0.3709, 0.7930])\n",
      "[ TRAIN ] epoch 1 lr 0.0000100 acc: 0.5958 loss:  1.2346: 100%|‚ñà| 3114/3114 [44:\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 785/785 [02:06<00:00,  6.23it/s]\n",
      "Valid Acc per class: tensor([0.4752, 0.9320, 0.8389, 0.7266, 0.6821, 0.6351, 0.8882, 0.6925, 0.6892,\n",
      "        0.7796, 0.9451, 0.6019, 0.5833, 0.5392, 0.4828, 0.8138])\n",
      "0.6389638184868509\n",
      "save model .....\n",
      "[ TRAIN ] epoch 2 lr 0.0000100 acc: 0.7207 loss:  1.1007:  16%|‚ñè| 499/3114 [07:2Epoch: 2 | Step: 500 | Train Acc per class: tensor([0.4900, 0.9298, 0.9098, 0.7341, 0.7146, 0.6139, 0.9266, 0.6290, 0.6182,\n",
      "        0.7675, 0.9429, 0.6178, 0.6557, 0.5594, 0.5907, 0.8350])\n",
      "[ TRAIN ] epoch 2 lr 0.0000100 acc: 0.7161 loss:  1.1063:  32%|‚ñé| 999/3114 [14:1Epoch: 2 | Step: 1000 | Train Acc per class: tensor([0.4876, 0.9244, 0.8981, 0.7311, 0.7228, 0.6063, 0.9246, 0.6336, 0.6176,\n",
      "        0.7786, 0.9448, 0.6188, 0.6143, 0.5398, 0.5823, 0.8333])\n",
      "[ TRAIN ] epoch 2 lr 0.0000100 acc: 0.7142 loss:  1.1080:  48%|‚ñç| 1499/3114 [21:Epoch: 2 | Step: 1500 | Train Acc per class: tensor([0.4911, 0.9213, 0.8934, 0.7265, 0.7211, 0.6086, 0.9253, 0.6327, 0.6155,\n",
      "        0.7747, 0.9458, 0.6177, 0.6094, 0.5395, 0.5703, 0.8337])\n",
      "[ TRAIN ] epoch 2 lr 0.0000100 acc: 0.7147 loss:  1.1074:  64%|‚ñã| 1999/3114 [28:Epoch: 2 | Step: 2000 | Train Acc per class: tensor([0.4932, 0.9207, 0.8953, 0.7281, 0.7213, 0.6126, 0.9255, 0.6332, 0.6149,\n",
      "        0.7801, 0.9478, 0.6158, 0.6109, 0.5409, 0.5612, 0.8337])\n",
      "[ TRAIN ] epoch 2 lr 0.0000100 acc: 0.7162 loss:  1.1052:  80%|‚ñä| 2499/3114 [35:Epoch: 2 | Step: 2500 | Train Acc per class: tensor([0.4986, 0.9217, 0.8954, 0.7309, 0.7215, 0.6137, 0.9256, 0.6346, 0.6153,\n",
      "        0.7801, 0.9495, 0.6158, 0.6127, 0.5501, 0.5591, 0.8347])\n",
      "[ TRAIN ] epoch 2 lr 0.0000100 acc: 0.7166 loss:  1.1055:  96%|‚ñâ| 2999/3114 [42:Epoch: 2 | Step: 3000 | Train Acc per class: tensor([0.5024, 0.9221, 0.8948, 0.7285, 0.7173, 0.6172, 0.9253, 0.6357, 0.6160,\n",
      "        0.7846, 0.9492, 0.6156, 0.6134, 0.5507, 0.5576, 0.8347])\n",
      "[ TRAIN ] epoch 2 lr 0.0000100 acc: 0.7161 loss:  1.1053: 100%|‚ñà| 3114/3114 [44:\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 785/785 [02:05<00:00,  6.26it/s]\n",
      "Valid Acc per class: tensor([0.5285, 0.9186, 0.8602, 0.7266, 0.6881, 0.6313, 0.8986, 0.6654, 0.6369,\n",
      "        0.7961, 0.9567, 0.6271, 0.6054, 0.6071, 0.5713, 0.8216])\n",
      "0.6658277694459044\n",
      "save model .....\n",
      "[ TRAIN ] epoch 3 lr 0.0000100 acc: 0.7733 loss:  1.0277:  16%|‚ñè| 499/3114 [07:4Epoch: 3 | Step: 500 | Train Acc per class: tensor([0.5202, 0.9483, 0.9362, 0.7791, 0.8001, 0.6774, 0.9383, 0.6805, 0.6839,\n",
      "        0.8161, 0.9672, 0.7014, 0.7142, 0.6724, 0.6761, 0.8641])\n",
      "[ TRAIN ] epoch 3 lr 0.0000100 acc: 0.7703 loss:  1.0311:  32%|‚ñé| 999/3114 [14:3Epoch: 3 | Step: 1000 | Train Acc per class: tensor([0.5300, 0.9440, 0.9309, 0.7758, 0.7995, 0.6725, 0.9354, 0.6818, 0.6815,\n",
      "        0.8138, 0.9639, 0.6944, 0.7137, 0.6590, 0.6677, 0.8616])\n",
      "[ TRAIN ] epoch 3 lr 0.0000100 acc: 0.7694 loss:  1.0317:  48%|‚ñç| 1499/3114 [21:Epoch: 3 | Step: 1500 | Train Acc per class: tensor([0.5321, 0.9403, 0.9287, 0.7713, 0.7929, 0.6713, 0.9358, 0.6827, 0.6801,\n",
      "        0.8150, 0.9635, 0.6905, 0.7182, 0.6560, 0.6693, 0.8619])\n",
      "[ TRAIN ] epoch 3 lr 0.0000100 acc: 0.7687 loss:  1.0320:  64%|‚ñã| 1999/3114 [28:Epoch: 3 | Step: 2000 | Train Acc per class: tensor([0.5325, 0.9397, 0.9281, 0.7713, 0.7860, 0.6704, 0.9357, 0.6789, 0.6779,\n",
      "        0.8190, 0.9631, 0.6926, 0.7151, 0.6572, 0.6667, 0.8613])\n",
      "[ TRAIN ] epoch 3 lr 0.0000100 acc: 0.7682 loss:  1.0329:  80%|‚ñä| 2499/3114 [35:Epoch: 3 | Step: 2500 | Train Acc per class: tensor([0.5401, 0.9390, 0.9268, 0.7723, 0.7826, 0.6675, 0.9348, 0.6755, 0.6756,\n",
      "        0.8202, 0.9629, 0.6954, 0.7182, 0.6577, 0.6624, 0.8606])\n",
      "[ TRAIN ] epoch 3 lr 0.0000100 acc: 0.7671 loss:  1.0350:  96%|‚ñâ| 2999/3114 [42:Epoch: 3 | Step: 3000 | Train Acc per class: tensor([0.5404, 0.9378, 0.9250, 0.7715, 0.7819, 0.6645, 0.9340, 0.6753, 0.6733,\n",
      "        0.8224, 0.9621, 0.6951, 0.7142, 0.6538, 0.6623, 0.8596])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ TRAIN ] epoch 3 lr 0.0000100 acc: 0.7668 loss:  1.0353: 100%|‚ñà| 3114/3114 [44:\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 785/785 [02:05<00:00,  6.27it/s]\n",
      "Valid Acc per class: tensor([0.5451, 0.9202, 0.8715, 0.7308, 0.6905, 0.6308, 0.9003, 0.6595, 0.6161,\n",
      "        0.7998, 0.9538, 0.6524, 0.6460, 0.6244, 0.6169, 0.8233])\n",
      "0.6732712638596713\n",
      "save model .....\n",
      "[ TRAIN ] epoch 4 lr 0.0000100 acc: 0.8140 loss:  0.9616:  16%|‚ñè| 499/3114 [07:1Epoch: 4 | Step: 500 | Train Acc per class: tensor([0.6002, 0.9445, 0.9477, 0.8114, 0.8487, 0.7111, 0.9451, 0.7185, 0.7528,\n",
      "        0.8438, 0.9697, 0.7561, 0.7906, 0.7336, 0.7646, 0.8872])\n",
      "[ TRAIN ] epoch 4 lr 0.0000100 acc: 0.8142 loss:  0.9605:  32%|‚ñé| 999/3114 [14:2Epoch: 4 | Step: 1000 | Train Acc per class: tensor([0.6008, 0.9512, 0.9483, 0.8146, 0.8415, 0.7122, 0.9450, 0.7181, 0.7477,\n",
      "        0.8479, 0.9730, 0.7657, 0.7903, 0.7345, 0.7484, 0.8876])\n",
      "[ TRAIN ] epoch 4 lr 0.0000100 acc: 0.8146 loss:  0.9645:  48%|‚ñç| 1499/3114 [21:Epoch: 4 | Step: 1500 | Train Acc per class: tensor([0.5876, 0.9518, 0.9482, 0.8159, 0.8399, 0.7087, 0.9440, 0.7190, 0.7479,\n",
      "        0.8528, 0.9735, 0.7669, 0.7888, 0.7373, 0.7655, 0.8862])\n",
      "[ TRAIN ] epoch 4 lr 0.0000100 acc: 0.8134 loss:  0.9682:  64%|‚ñã| 1999/3114 [28:Epoch: 4 | Step: 2000 | Train Acc per class: tensor([0.5862, 0.9541, 0.9471, 0.8125, 0.8364, 0.7089, 0.9442, 0.7164, 0.7445,\n",
      "        0.8530, 0.9727, 0.7667, 0.7867, 0.7373, 0.7631, 0.8854])\n",
      "[ TRAIN ] epoch 4 lr 0.0000100 acc: 0.8115 loss:  0.9705:  80%|‚ñä| 2499/3114 [35:Epoch: 4 | Step: 2500 | Train Acc per class: tensor([0.5824, 0.9544, 0.9469, 0.8098, 0.8328, 0.7065, 0.9438, 0.7150, 0.7397,\n",
      "        0.8514, 0.9717, 0.7641, 0.7892, 0.7343, 0.7581, 0.8843])\n",
      "[ TRAIN ] epoch 4 lr 0.0000100 acc: 0.8093 loss:  0.9708:  96%|‚ñâ| 2999/3114 [42:Epoch: 4 | Step: 3000 | Train Acc per class: tensor([0.5835, 0.9522, 0.9470, 0.8097, 0.8323, 0.7052, 0.9437, 0.7149, 0.7387,\n",
      "        0.8486, 0.9714, 0.7582, 0.7816, 0.7274, 0.7510, 0.8839])\n",
      "[ TRAIN ] epoch 4 lr 0.0000100 acc: 0.8093 loss:  0.9709: 100%|‚ñà| 3114/3114 [44:\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 785/785 [02:05<00:00,  6.26it/s]\n",
      "Valid Acc per class: tensor([0.5469, 0.9197, 0.8743, 0.7388, 0.6992, 0.6298, 0.8996, 0.6640, 0.6247,\n",
      "        0.7968, 0.9474, 0.6481, 0.6423, 0.6267, 0.6118, 0.8238])\n",
      "0.6781374751245334\n",
      "save model .....\n",
      "[ TRAIN ] epoch 5 lr 0.0000100 acc: 0.8433 loss:  0.9155:  16%|‚ñè| 499/3114 [07:2Epoch: 5 | Step: 500 | Train Acc per class: tensor([0.6453, 0.9585, 0.9673, 0.8402, 0.8828, 0.7579, 0.9559, 0.7515, 0.7948,\n",
      "        0.8672, 0.9782, 0.7932, 0.8230, 0.7677, 0.8069, 0.9073])\n",
      "[ TRAIN ] epoch 5 lr 0.0000100 acc: 0.8442 loss:  0.9164:  32%|‚ñé| 999/3114 [14:4Epoch: 5 | Step: 1000 | Train Acc per class: tensor([0.6426, 0.9602, 0.9672, 0.8347, 0.8779, 0.7515, 0.9558, 0.7528, 0.7965,\n",
      "        0.8727, 0.9765, 0.7989, 0.8445, 0.7640, 0.8039, 0.9076])\n",
      "[ TRAIN ] epoch 5 lr 0.0000100 acc: 0.8470 loss:  0.9130:  48%|‚ñç| 1499/3114 [21:Epoch: 5 | Step: 1500 | Train Acc per class: tensor([0.6508, 0.9601, 0.9643, 0.8356, 0.8788, 0.7522, 0.9550, 0.7526, 0.7974,\n",
      "        0.8685, 0.9765, 0.8050, 0.8495, 0.7762, 0.8201, 0.9081])\n",
      "[ TRAIN ] epoch 5 lr 0.0000100 acc: 0.8458 loss:  0.9145:  64%|‚ñã| 1999/3114 [28:Epoch: 5 | Step: 2000 | Train Acc per class: tensor([0.6526, 0.9609, 0.9631, 0.8348, 0.8781, 0.7515, 0.9551, 0.7503, 0.7949,\n",
      "        0.8694, 0.9770, 0.8050, 0.8448, 0.7737, 0.8141, 0.9077])\n",
      "[ TRAIN ] epoch 5 lr 0.0000100 acc: 0.8449 loss:  0.9153:  80%|‚ñä| 2499/3114 [35:Epoch: 5 | Step: 2500 | Train Acc per class: tensor([0.6531, 0.9601, 0.9620, 0.8350, 0.8765, 0.7518, 0.9548, 0.7486, 0.7933,\n",
      "        0.8682, 0.9766, 0.7975, 0.8443, 0.7747, 0.8150, 0.9071])\n",
      "[ TRAIN ] epoch 5 lr 0.0000100 acc: 0.8445 loss:  0.9155:  96%|‚ñâ| 2999/3114 [43:Epoch: 5 | Step: 3000 | Train Acc per class: tensor([0.6508, 0.9601, 0.9619, 0.8370, 0.8733, 0.7512, 0.9548, 0.7499, 0.7944,\n",
      "        0.8695, 0.9764, 0.7979, 0.8420, 0.7722, 0.8133, 0.9071])\n",
      "[ TRAIN ] epoch 5 lr 0.0000100 acc: 0.8444 loss:  0.9158: 100%|‚ñà| 3114/3114 [44:\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 785/785 [02:05<00:00,  6.25it/s]\n",
      "Valid Acc per class: tensor([0.5553, 0.9218, 0.8731, 0.7440, 0.7053, 0.6332, 0.8960, 0.6637, 0.6253,\n",
      "        0.7998, 0.9413, 0.6473, 0.6470, 0.6302, 0.6217, 0.8223])\n",
      "0.6800393537455582\n",
      "save model .....\n",
      "[ TRAIN ] epoch 6 lr 0.0000100 acc: 0.8760 loss:  0.8689:  16%|‚ñè| 499/3114 [07:4Epoch: 6 | Step: 500 | Train Acc per class: tensor([0.6979, 0.9688, 0.9766, 0.8441, 0.9035, 0.7856, 0.9644, 0.7797, 0.8479,\n",
      "        0.8876, 0.9819, 0.8456, 0.8913, 0.8312, 0.8877, 0.9273])\n",
      "[ TRAIN ] epoch 6 lr 0.0000100 acc: 0.8728 loss:  0.8742:  32%|‚ñé| 999/3114 [14:5Epoch: 6 | Step: 1000 | Train Acc per class: tensor([0.6961, 0.9683, 0.9728, 0.8565, 0.9057, 0.7789, 0.9637, 0.7782, 0.8414,\n",
      "        0.8838, 0.9811, 0.8358, 0.8866, 0.8156, 0.8751, 0.9254])\n",
      "[ TRAIN ] epoch 6 lr 0.0000100 acc: 0.8713 loss:  0.8741:  48%|‚ñç| 1499/3114 [22:Epoch: 6 | Step: 1500 | Train Acc per class: tensor([0.7018, 0.9676, 0.9714, 0.8594, 0.9038, 0.7813, 0.9643, 0.7807, 0.8402,\n",
      "        0.8882, 0.9805, 0.8272, 0.8757, 0.8079, 0.8665, 0.9253])\n",
      "[ TRAIN ] epoch 6 lr 0.0000100 acc: 0.8702 loss:  0.8746:  64%|‚ñã| 1999/3114 [29:Epoch: 6 | Step: 2000 | Train Acc per class: tensor([0.7015, 0.9658, 0.9701, 0.8608, 0.9018, 0.7795, 0.9638, 0.7794, 0.8386,\n",
      "        0.8847, 0.9809, 0.8279, 0.8768, 0.8085, 0.8587, 0.9246])\n",
      "[ TRAIN ] epoch 6 lr 0.0000100 acc: 0.8704 loss:  0.8758:  80%|‚ñä| 2499/3114 [36:Epoch: 6 | Step: 2500 | Train Acc per class: tensor([0.6997, 0.9663, 0.9706, 0.8591, 0.8996, 0.7795, 0.9636, 0.7788, 0.8375,\n",
      "        0.8845, 0.9811, 0.8317, 0.8780, 0.8107, 0.8603, 0.9243])\n",
      "[ TRAIN ] epoch 6 lr 0.0000100 acc: 0.8698 loss:  0.8754:  96%|‚ñâ| 2999/3114 [43:Epoch: 6 | Step: 3000 | Train Acc per class: tensor([0.6996, 0.9679, 0.9719, 0.8609, 0.9013, 0.7809, 0.9636, 0.7775, 0.8366,\n",
      "        0.8832, 0.9804, 0.8247, 0.8755, 0.8077, 0.8602, 0.9243])\n",
      "[ TRAIN ] epoch 6 lr 0.0000100 acc: 0.8696 loss:  0.8752:  98%|‚ñâ| 3058/3114 [43:"
     ]
    }
   ],
   "source": [
    "!python train.py --wandb_comment \"swa_plateau_no_grad_accumulation_maxgrad1.0\" --grad_acc_steps 1 --lr 1e-5 --swa --max_grad_norm 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4b975d",
   "metadata": {},
   "source": [
    "## DDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecfd1d6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-02-25T16:24:15.710Z"
    }
   },
   "outputs": [],
   "source": [
    "!python -m torch.distributed.launch --nproc_per_node=4 train.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "282.242px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
