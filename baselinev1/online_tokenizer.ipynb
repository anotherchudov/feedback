{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d718a24",
   "metadata": {},
   "source": [
    "# Online Tokenizer\n",
    "\n",
    "> Literally, the title is all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97bb1d4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T07:31:31.098324Z",
     "start_time": "2022-03-03T07:31:29.503060Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import torch\n",
    "\n",
    "from module.utils import get_data_files\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "sys.path.insert(0, './codes/new_transformers_branch/transformers/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be6c3c80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T07:31:31.117765Z",
     "start_time": "2022-03-03T07:31:31.105477Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_config():\n",
    "    parser = argparse.ArgumentParser(description=\"use huggingface models\")\n",
    "    parser.add_argument(\"--dataset_path\", default='../../feedback-prize-2021', type=str)\n",
    "    parser.add_argument(\"--save_path\", default='result', type=str)\n",
    "    parser.add_argument(\"--seed\", default=0, type=int)\n",
    "    parser.add_argument(\"--min_len\", default=0, type=int)\n",
    "    parser.add_argument(\"--use_groupped_weights\", default=False, type=bool)\n",
    "    parser.add_argument(\"--global_attn\", default=False, type=int)\n",
    "    parser.add_argument(\"--epochs\", default=9, type=int)\n",
    "    parser.add_argument(\"--batch_size\", default=4, type=int)\n",
    "    parser.add_argument(\"--grad_acc_steps\", default=2, type=int)\n",
    "    parser.add_argument(\"--grad_checkpt\", default=True, type=bool)\n",
    "    parser.add_argument(\"--data_prefix\", default='', type=str)\n",
    "    parser.add_argument(\"--max_grad_norm\", default=10.0, type=float)\n",
    "    parser.add_argument(\"--start_eval_at\", default=0, type=int)\n",
    "    parser.add_argument(\"--weight_decay\", default=1e-2, type=float)\n",
    "    parser.add_argument(\"--weights_pow\", default=0.1, type=float)\n",
    "    parser.add_argument(\"--dataset_version\", default=2, type=int)\n",
    "    parser.add_argument(\"--decay_bias\", default=False, type=bool)\n",
    "    parser.add_argument(\"--val_fold\", default=0, type=int)\n",
    "    parser.add_argument(\"--num_worker\", default=8, type=int)\n",
    "    parser.add_argument(\"--local_rank\", type=int, default=-1, help=\"do not modify!\")\n",
    "    parser.add_argument(\"--device\", type=int, default=0, help=\"select the gpu device to train\")\n",
    "\n",
    "    # logging\n",
    "    parser.add_argument(\"--wandb_user\", default='ducky', type=str)\n",
    "    parser.add_argument(\"--wandb_project\", default='feedback_deberta_large', type=str)\n",
    "    parser.add_argument(\"--wandb_comment\", default=\"\", type=str, help=\"comment will be added at the back of wandb project name\")\n",
    "    parser.add_argument(\"--print_acc\", default=500, type=int, help=\"print accuracy of each class every `print_acc` steps\")\n",
    "\n",
    "    # optimizer\n",
    "    parser.add_argument(\"--label_smoothing\", default=0.1, type=float)\n",
    "    parser.add_argument(\"--rce_weight\", default=0.1, type=float)\n",
    "    parser.add_argument(\"--ce_weight\", default=0.9, type=float)\n",
    "    parser.add_argument(\"--nesterov\", default=True, type=bool, help=\"use nesterov for SGD\")\n",
    "    parser.add_argument(\"--momentum\", default=0.9, type=float, help=\"momentum for SGD\")\n",
    "\n",
    "    # scheduler\n",
    "    parser.add_argument(\"--lr\", default=3e-5, type=float)\n",
    "    parser.add_argument(\"--min_lr\", default=1e-6, type=float)\n",
    "    parser.add_argument(\"--warmup_steps\", default=500, type=int)\n",
    "    parser.add_argument(\"--gamma\", default=0.8, type=float, help=\"gamma for cosine annealing warmup restart scheduler\")\n",
    "    parser.add_argument(\"--cycle_mult\", default=1.0, type=float, help=\"cycle length adjustment for cosine annealing warmup restart scheduler\")\n",
    "\n",
    "    # model related arguments\n",
    "    parser.add_argument(\"--model\", default=\"microsoft/deberta-v3-large\", type=str)\n",
    "    parser.add_argument(\"--cnn1d\", default=False, type=bool)\n",
    "    parser.add_argument(\"--extra_dense\", default= False, type=bool)\n",
    "    parser.add_argument(\"--dropout_ratio\", default=0.0, type=float)\n",
    "\n",
    "    # swa\n",
    "    parser.add_argument(\"--swa\", action=\"store_true\", help=\"use stochastic weight averaging\")\n",
    "    parser.add_argument(\"--swa_update_per_epoch\", default=3, type=int)\n",
    "\n",
    "    args = parser.parse_args([])\n",
    "\n",
    "    if args.local_rank !=-1:\n",
    "        print('[ DDP ] local rank', args.local_rank)\n",
    "        torch.cuda.set_device(args.local_rank)\n",
    "        dist.init_process_group(backend='nccl')\n",
    "        args.device = torch.device(\"cuda\", args.local_rank)\n",
    "        args.rank = torch.distributed.get_rank()\n",
    "        args.world_size = torch.distributed.get_world_size()  \n",
    "\n",
    "        # checking settings for distributed training\n",
    "        assert args.batch_size % args.world_size == 0, f'--batch_size {args.batch_size} must be multiple of world size'\n",
    "        assert torch.cuda.device_count() > args.local_rank, 'insufficient CUDA devices for DDP command'\n",
    "\n",
    "        args.ddp = True\n",
    "    else:\n",
    "        args.device = torch.device(\"cuda\", args.device)\n",
    "        args.rank = -1\n",
    "        args.ddp = False\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3177934",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T07:31:31.959342Z",
     "start_time": "2022-03-03T07:31:31.118731Z"
    }
   },
   "outputs": [],
   "source": [
    "args = get_config()\n",
    "all_texts, token_weights, data, csv, train_ids, val_ids, train_text_ids, val_text_ids = get_data_files(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7eb2543",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T07:31:31.968351Z",
     "start_time": "2022-03-03T07:31:31.964345Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B72D0B4875B4'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_id = train_text_ids[0]\n",
    "text_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfcd571e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T07:31:31.986588Z",
     "start_time": "2022-03-03T07:31:31.969376Z"
    }
   },
   "outputs": [],
   "source": [
    "text = all_texts[text_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b6a329",
   "metadata": {},
   "source": [
    "## DebertaV3 Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c74ce312",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:21:36.822542Z",
     "start_time": "2022-03-03T08:21:36.819880Z"
    }
   },
   "outputs": [],
   "source": [
    "from new_transformers import DebertaV2TokenizerFast\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cca2eb6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T07:32:51.130444Z",
     "start_time": "2022-03-03T07:32:43.473405Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DebertaV2TokenizerFast.from_pretrained('microsoft/deberta-v3-large')\n",
    "tokenizer.model_max_length = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3653da92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:22:02.120162Z",
     "start_time": "2022-03-03T08:21:54.168792Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "auto_tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-large')\n",
    "auto_tokenizer.model_max_length = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b319b47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:18:02.951582Z",
     "start_time": "2022-03-03T08:18:02.947567Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[1, 266, 2], [1, 2165, 2]], 'token_type_ids': [[0, 0, 0], [0, 0, 0]], 'attention_mask': [[1, 1, 1], [1, 1, 1]]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(['a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4bdd59f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:18:15.372975Z",
     "start_time": "2022-03-03T08:18:15.370178Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 266, 507, 2], 'token_type_ids': [0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('a\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "499b95b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:22:12.839721Z",
     "start_time": "2022-03-03T08:22:12.836358Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 266, 2], 'token_type_ids': [0, 0, 0], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_tokenizer('a\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6cf17059",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:20:53.194014Z",
     "start_time": "2022-03-03T08:20:53.190471Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 266, 507, 2], 'token_type_ids': [0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('a\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfa741db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:18:22.206659Z",
     "start_time": "2022-03-03T08:18:22.203842Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 507, 2], 'token_type_ids': [0, 0, 0], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e784830d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:23:50.557485Z",
     "start_time": "2022-03-03T08:23:50.553461Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<0x08> <0x0C>'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode([12, 507, 16])\n",
    "decoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f3cd3277",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:24:23.230237Z",
     "start_time": "2022-03-03T08:24:23.226407Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<0x08> <0x0C>'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfa30bc",
   "metadata": {},
   "source": [
    "### newline (\\n) is removed by DebertaV3 Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375daa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_text = lambda x: x.replace('\\n', '‽')\n",
    "\n",
    "text = fix_text(f.read().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3629ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_outs = tokenizer(text, return_offsets_mapping=True)\n",
    "\n",
    "# token replacement ‽ -> [MASK]\n",
    "tokenizer_outs['input_ids'] = [x if x != 126861 else 128000 for x in tokenizer_outs['input_ids']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6c5eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_start = discourse_start\n",
    "char_end = discourse_end\n",
    "word_start = len(full_text[:char_start].split())\n",
    "word_end = word_start + len(full_text[char_start:char_end].split())\n",
    "word_end = min( word_end, len(full_text.split()) )\n",
    "predictionstring = \" \".join( [str(x) for x in range(word_start,word_end)] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd36fdec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T07:16:10.756800Z",
     "start_time": "2022-03-03T07:16:10.752888Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', 'a']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'  a'.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f50d7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "regexp = re.compile('[0-9a-zA-z]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a61c2dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T05:49:12.419474Z",
     "start_time": "2022-03-03T05:49:12.414987Z"
    }
   },
   "outputs": [],
   "source": [
    "class FeedbackDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self, text_ids, csv, all_texts, token_weights\n",
    "    ):\n",
    "        self.csv = csv\n",
    "        self.all_texts = all_texts\n",
    "        self.text_ids = text_ids\n",
    "        self.class_names = class_names\n",
    "        self.token_weights = token_weights\n",
    "        \n",
    "        self.space_regex = re.compile(\"[\\s\\n]\")\n",
    "        \n",
    "    def noise_injection(self, text):\n",
    "        \n",
    "    def preprocess_text(self, text):\n",
    "        text = text.strip()\n",
    "        \n",
    "        # newline is removed from debertav3 tokenizer\n",
    "        text = text.replace('\\n', '‽')\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def forward(self, idx):\n",
    "        text_id = self.text_ids[idx]\n",
    "        \n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_ids)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1b9018c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T14:36:03.462990Z",
     "start_time": "2022-03-03T14:36:03.448404Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>230.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>313.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>402.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>When people have phones, they know about certa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>759.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>Driving is one of the way how to get around. P...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144288</th>\n",
       "      <td>4C471936CD75</td>\n",
       "      <td>1.618153e+12</td>\n",
       "      <td>2234.0</td>\n",
       "      <td>3203.0</td>\n",
       "      <td>if I'm not sure what college I want to attend...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>386 387 388 389 390 391 392 393 394 395 396 39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144289</th>\n",
       "      <td>4C471936CD75</td>\n",
       "      <td>1.618153e+12</td>\n",
       "      <td>3221.0</td>\n",
       "      <td>4509.0</td>\n",
       "      <td>seeking multiple opinions before making a har...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 3</td>\n",
       "      <td>576 577 578 579 580 581 582 583 584 585 586 58...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144290</th>\n",
       "      <td>4C471936CD75</td>\n",
       "      <td>1.618025e+12</td>\n",
       "      <td>4510.0</td>\n",
       "      <td>4570.0</td>\n",
       "      <td>it is better to seek multiple opinions instead...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>828 829 830 831 832 833 834 835 836 837 838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144291</th>\n",
       "      <td>4C471936CD75</td>\n",
       "      <td>1.618025e+12</td>\n",
       "      <td>4570.0</td>\n",
       "      <td>4922.0</td>\n",
       "      <td>The impact of asking people to help you make a...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 4</td>\n",
       "      <td>839 840 841 842 843 844 845 846 847 848 849 85...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144292</th>\n",
       "      <td>4C471936CD75</td>\n",
       "      <td>1.618025e+12</td>\n",
       "      <td>4935.0</td>\n",
       "      <td>5825.0</td>\n",
       "      <td>there are many other reasons one might want to...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>Concluding Statement 1</td>\n",
       "      <td>905 906 907 908 909 910 911 912 913 914 915 91...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144293 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  discourse_id  discourse_start  discourse_end  \\\n",
       "0       423A1CA112E2  1.622628e+12              8.0          229.0   \n",
       "1       423A1CA112E2  1.622628e+12            230.0          312.0   \n",
       "2       423A1CA112E2  1.622628e+12            313.0          401.0   \n",
       "3       423A1CA112E2  1.622628e+12            402.0          758.0   \n",
       "4       423A1CA112E2  1.622628e+12            759.0          886.0   \n",
       "...              ...           ...              ...            ...   \n",
       "144288  4C471936CD75  1.618153e+12           2234.0         3203.0   \n",
       "144289  4C471936CD75  1.618153e+12           3221.0         4509.0   \n",
       "144290  4C471936CD75  1.618025e+12           4510.0         4570.0   \n",
       "144291  4C471936CD75  1.618025e+12           4570.0         4922.0   \n",
       "144292  4C471936CD75  1.618025e+12           4935.0         5825.0   \n",
       "\n",
       "                                           discourse_text  \\\n",
       "0       Modern humans today are always on their phone....   \n",
       "1       They are some really bad consequences when stu...   \n",
       "2       Some certain areas in the United States ban ph...   \n",
       "3       When people have phones, they know about certa...   \n",
       "4       Driving is one of the way how to get around. P...   \n",
       "...                                                   ...   \n",
       "144288   if I'm not sure what college I want to attend...   \n",
       "144289   seeking multiple opinions before making a har...   \n",
       "144290  it is better to seek multiple opinions instead...   \n",
       "144291  The impact of asking people to help you make a...   \n",
       "144292  there are many other reasons one might want to...   \n",
       "\n",
       "              discourse_type      discourse_type_num  \\\n",
       "0                       Lead                  Lead 1   \n",
       "1                   Position              Position 1   \n",
       "2                   Evidence              Evidence 1   \n",
       "3                   Evidence              Evidence 2   \n",
       "4                      Claim                 Claim 1   \n",
       "...                      ...                     ...   \n",
       "144288              Evidence              Evidence 2   \n",
       "144289              Evidence              Evidence 3   \n",
       "144290              Position              Position 1   \n",
       "144291              Evidence              Evidence 4   \n",
       "144292  Concluding Statement  Concluding Statement 1   \n",
       "\n",
       "                                         predictionstring  \n",
       "0       1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...  \n",
       "1            45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  \n",
       "2         60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  \n",
       "3       76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...  \n",
       "4       139 140 141 142 143 144 145 146 147 148 149 15...  \n",
       "...                                                   ...  \n",
       "144288  386 387 388 389 390 391 392 393 394 395 396 39...  \n",
       "144289  576 577 578 579 580 581 582 583 584 585 586 58...  \n",
       "144290        828 829 830 831 832 833 834 835 836 837 838  \n",
       "144291  839 840 841 842 843 844 845 846 847 848 849 85...  \n",
       "144292  905 906 907 908 909 910 911 912 913 914 915 91...  \n",
       "\n",
       "[144293 rows x 8 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245ae5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def __getitem__(self, idx):\n",
    "        i = self.ids[idx]\n",
    "\n",
    "        # load text data & text dataframe\n",
    "        text_id = self.val_text_ids[idx]\n",
    "        text = self.all_texts[text_id]\n",
    "        sample_df = self.csv.query(\"id == @text_id\")\n",
    "\n",
    "        # load ground truth prediction string for f1macro metric\n",
    "        gt_dict = {}\n",
    "        for class_i in range(1, 8):\n",
    "            class_name = self.class_names[class_i]\n",
    "            class_df = sample_df.query(\"discourse_type == @class_name\")\n",
    "            if len(class_df):\n",
    "                gt_dict[class_i] = [\n",
    "                    (x[0], x[1])\n",
    "                    for x in class_df.predictionstring.map(split_predstring)\n",
    "                ]\n",
    "\n",
    "        # load valid data\n",
    "        tokens = self.data[\"tokens\"][i]\n",
    "        attention_mask = self.data[\"attention_masks\"][i]\n",
    "        num_tokens = self.data[\"num_tokens\"][i, 0]\n",
    "        token_bounds = self.data[\"token_offsets\"][i]\n",
    "        cbio_labels = self.data[\"cbio_labels\"][i]\n",
    "\n",
    "        # class weight per token\n",
    "        class_weight = np.zeros_like(attention_mask)\n",
    "        argmax_labels = cbio_labels.argmax(-1)\n",
    "\n",
    "        for class_i in range(1, 15):\n",
    "            class_weight[argmax_labels == class_i] = self.token_weights[class_i]\n",
    "\n",
    "        class_none_index = argmax_labels == 0\n",
    "        class_none_index[num_tokens - 1 :] = False\n",
    "        class_weight[class_none_index] = self.token_weights[0]\n",
    "        class_weight[0] = 0\n",
    "\n",
    "        # ???\n",
    "        index_map = []\n",
    "        current_word = 0\n",
    "        blank = False\n",
    "        for char_ix in range(text.index(text.strip()[0]), len(text)):\n",
    "            if self.space_regex.match(text[char_ix]) is not None:\n",
    "                blank = True\n",
    "            elif blank:\n",
    "                current_word += 1\n",
    "                blank = False\n",
    "            index_map.append(current_word)\n",
    "\n",
    "        return (\n",
    "            tokens,\n",
    "            attention_mask,\n",
    "            cbio_labels,\n",
    "            class_weight,\n",
    "            token_bounds,\n",
    "            gt_dict,\n",
    "            index_map,\n",
    "            num_tokens,\n",
    "        )\n",
    "\n",
    "\n",
    "first_batch = True\n",
    "\n",
    "\n",
    "def train_collate_fn(ins):\n",
    "    global first_batch\n",
    "    if first_batch:\n",
    "        max_len = 2048\n",
    "        first_batch = False\n",
    "    else:\n",
    "        max_len = (max(x[-1] for x in ins) + 7) // 8 * 8\n",
    "\n",
    "    return tuple(\n",
    "        torch.from_numpy(\n",
    "            np.concatenate([ins[z][x][None, :max_len] for z in range(len(ins))])\n",
    "        )\n",
    "        for x in range(len(ins[0]) - 1)\n",
    "    )\n",
    "\n",
    "\n",
    "def val_collate_fn(ins):\n",
    "    max_len = (max(x[-1] for x in ins) + 7) // 8 * 8\n",
    "    return tuple(\n",
    "        torch.from_numpy(\n",
    "            np.concatenate([ins[z][x][None, :max_len] for z in range(len(ins))])\n",
    "        )\n",
    "        for x in range(len(ins[0]) - 3)\n",
    "    ) + (\n",
    "        [x[-3] for x in ins],\n",
    "        [x[-2] for x in ins],\n",
    "        np.array([x[-1] for x in ins]),\n",
    "    )\n",
    "\n",
    "\n",
    "def get_dataloader(\n",
    "    args,\n",
    "    train_ids,\n",
    "    val_ids,\n",
    "    data,\n",
    "    csv,\n",
    "    all_texts,\n",
    "    val_text_ids,\n",
    "    class_names,\n",
    "    token_weights,\n",
    "):\n",
    "    train_dataset = TrainDataset(\n",
    "        train_ids, data, args.label_smoothing, token_weights, args.data_prefix\n",
    "    )\n",
    "    val_dataset = ValDataset(\n",
    "        val_ids, data, csv, all_texts, val_text_ids, class_names, token_weights\n",
    "    )\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        collate_fn=train_collate_fn,\n",
    "        batch_size=args.batch_size,\n",
    "        num_workers=args.num_worker,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        collate_fn=val_collate_fn,\n",
    "        batch_size=args.batch_size,\n",
    "        num_workers=8,\n",
    "        persistent_workers=True,\n",
    "    )\n",
    "\n",
    "    return train_dataloader, val_dataloader"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
