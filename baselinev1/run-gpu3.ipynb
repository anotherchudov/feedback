{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61afee34",
   "metadata": {},
   "source": [
    "# run training\n",
    "\n",
    "> notebook to run the `train.py` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f259f5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T02:58:00.112394Z",
     "start_time": "2022-02-26T02:58:00.108480Z"
    }
   },
   "outputs": [],
   "source": [
    "install_pytorch = False\n",
    "if install_pytorch:\n",
    "    !pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio===0.8.1 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c8c22e",
   "metadata": {},
   "source": [
    "## Single GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80571bec",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-02T10:57:37.501Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mducky\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfine-dragon-88\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ducky/feedback_deberta_large\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ducky/feedback_deberta_large/runs/1zber0x2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /home/feedback/working/feedback_ducky/baselinev1/wandb/run-20220302_105739-1zber0x2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
      "\n",
      "Namespace(batch_size=8, ce_weight=0.9, cnn1d=False, cycle_mult=1.0, data_prefix='', dataset_path='../../feedback-prize-2021', dataset_version=2, ddp=False, decay_bias=False, device=device(type='cuda', index=3), dropout_ratio=0.0, epochs=9, extra_dense=False, gamma=0.8, global_attn=False, grad_acc_steps=2, grad_checkpt=True, label_smoothing=0.1, local_rank=-1, lr=8e-06, max_grad_norm=10.0, min_len=0, min_lr=1e-06, model='microsoft/deberta-v3-large', momentum=0.9, nesterov=True, num_worker=8, print_acc=2000, rank=-1, rce_weight=0.1, save_path='result', seed=0, start_eval_at=0, swa=False, swa_update_per_epoch=3, use_groupped_weights=False, val_fold=0, wandb_comment='original', wandb_project='feedback_deberta_large', wandb_user='ducky', warmup_steps=500, weight_decay=0.01, weights_pow=0.1)\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[ TRAIN ] epoch 1 lr 0.0000080 acc: 0.1648 loss:  1.9084:  16%|‚ñè| 1999/12454 [06Epoch: 1 | Step: 2000 | Train Acc per class: tensor([2.3572e-01, 1.6935e-03, 1.8070e-01, 7.0850e-03, 9.2506e-02, 1.2056e-02,\n",
      "        8.4652e-01, 1.3632e-01, 1.1265e-01, 2.0702e-02, 4.0297e-01, 2.6882e-03,\n",
      "        4.3125e-02, 0.0000e+00, 4.5298e-04, 5.4153e-01])\n",
      "[ TRAIN ] epoch 1 lr 0.0000080 acc: 0.2407 loss:  1.6842:  32%|‚ñé| 3999/12454 [13Epoch: 1 | Step: 4000 | Train Acc per class: tensor([2.8131e-01, 3.3193e-02, 4.7284e-01, 1.0111e-02, 2.2239e-01, 1.1147e-01,\n",
      "        8.7874e-01, 2.1978e-01, 2.6400e-01, 5.8451e-02, 6.3983e-01, 1.3569e-03,\n",
      "        2.1583e-02, 0.0000e+00, 2.3263e-04, 6.3539e-01])\n",
      "[ TRAIN ] epoch 1 lr 0.0000080 acc: 0.2950 loss:  1.5859:  48%|‚ñç| 5999/12454 [19Epoch: 1 | Step: 6000 | Train Acc per class: tensor([2.9904e-01, 2.1360e-01, 5.6967e-01, 5.4068e-02, 3.0924e-01, 1.9181e-01,\n",
      "        8.9237e-01, 2.7109e-01, 3.3287e-01, 1.6293e-01, 7.3342e-01, 9.1743e-04,\n",
      "        1.4610e-02, 0.0000e+00, 1.5888e-04, 6.7481e-01])\n",
      "[ TRAIN ] epoch 1 lr 0.0000079 acc: 0.3356 loss:  1.5275:  64%|‚ñã| 7999/12454 [26Epoch: 1 | Step: 8000 | Train Acc per class: tensor([3.0626e-01, 3.4025e-01, 6.2287e-01, 1.3555e-01, 3.6584e-01, 2.4690e-01,\n",
      "        8.9960e-01, 3.0857e-01, 3.7806e-01, 2.7363e-01, 7.8240e-01, 6.9061e-04,\n",
      "        1.0995e-02, 0.0000e+00, 1.1810e-04, 6.9756e-01])\n",
      "[ TRAIN ] epoch 1 lr 0.0000079 acc: 0.3662 loss:  1.4849:  80%|‚ñä| 9999/12454 [32Epoch: 1 | Step: 10000 | Train Acc per class: tensor([3.1370e-01, 4.2526e-01, 6.6512e-01, 2.0338e-01, 4.0574e-01, 2.9271e-01,\n",
      "        9.0355e-01, 3.4329e-01, 4.1355e-01, 3.4603e-01, 8.1146e-01, 5.4496e-04,\n",
      "        2.1440e-02, 0.0000e+00, 1.5451e-03, 7.1285e-01])\n",
      "[ TRAIN ] epoch 1 lr 0.0000078 acc: 0.3921 loss:  1.4528:  96%|‚ñâ| 11999/12454 [3Epoch: 1 | Step: 12000 | Train Acc per class: tensor([3.1847e-01, 4.8923e-01, 6.9516e-01, 2.5518e-01, 4.3506e-01, 3.2381e-01,\n",
      "        9.0455e-01, 3.6714e-01, 4.3390e-01, 3.9963e-01, 8.3387e-01, 4.4954e-04,\n",
      "        6.9401e-02, 0.0000e+00, 2.4429e-02, 7.2397e-01])\n",
      "[ TRAIN ] epoch 1 lr 0.0000078 acc: 0.3975 loss:  1.4462: 100%|‚ñà| 12454/12454 [4\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 785/785 [02:06<00:00,  6.21it/s]\n",
      "Valid Acc per class: tensor([0.4618, 0.8688, 0.8324, 0.5658, 0.5789, 0.4893, 0.9139, 0.5471, 0.5278,\n",
      "        0.6716, 0.9530, 0.0210, 0.3696, 0.0000, 0.0939, 0.7886])\n",
      "0.45570530336215137\n",
      "save model .....\n",
      "[ TRAIN ] epoch 2 lr 0.0000080 acc: 0.5476 loss:  1.2602:  16%|‚ñè| 1999/12454 [06Epoch: 2 | Step: 2000 | Train Acc per class: tensor([0.3720, 0.8446, 0.8586, 0.6104, 0.6114, 0.4934, 0.9156, 0.5201, 0.5516,\n",
      "        0.6704, 0.9334, 0.0296, 0.3729, 0.0000, 0.1890, 0.7897])\n",
      "[ TRAIN ] epoch 2 lr 0.0000080 acc: 0.5518 loss:  1.2543:  32%|‚ñé| 3999/12454 [12Epoch: 2 | Step: 4000 | Train Acc per class: tensor([0.3660, 0.8366, 0.8515, 0.6119, 0.6225, 0.4898, 0.9190, 0.5446, 0.5515,\n",
      "        0.6726, 0.9342, 0.0647, 0.3845, 0.0000, 0.1875, 0.7922])\n",
      "[ TRAIN ] epoch 2 lr 0.0000080 acc: 0.5584 loss:  1.2520:  48%|‚ñç| 5999/12454 [19Epoch: 2 | Step: 6000 | Train Acc per class: tensor([0.3772, 0.8432, 0.8520, 0.6158, 0.6217, 0.4882, 0.9193, 0.5513, 0.5438,\n",
      "        0.6689, 0.9251, 0.1129, 0.3985, 0.0000, 0.2242, 0.7925])\n",
      "[ TRAIN ] epoch 2 lr 0.0000079 acc: 0.5645 loss:  1.2492:  64%|‚ñã| 7999/12454 [25Epoch: 2 | Step: 8000 | Train Acc per class: tensor([0.3755, 0.8422, 0.8494, 0.6200, 0.6220, 0.4918, 0.9192, 0.5531, 0.5457,\n",
      "        0.6788, 0.9262, 0.1549, 0.4107, 0.0000, 0.2493, 0.7926])\n",
      "[ TRAIN ] epoch 2 lr 0.0000079 acc: 0.5727 loss:  1.2420:  80%|‚ñä| 9999/12454 [32Epoch: 2 | Step: 10000 | Train Acc per class: tensor([0.3839, 0.8500, 0.8517, 0.6240, 0.6242, 0.4992, 0.9184, 0.5600, 0.5491,\n",
      "        0.6837, 0.9298, 0.1981, 0.4243, 0.0000, 0.2712, 0.7950])\n",
      "[ TRAIN ] epoch 2 lr 0.0000078 acc: 0.5787 loss:  1.2392:  96%|‚ñâ| 11999/12454 [3Epoch: 2 | Step: 12000 | Train Acc per class: tensor([0.3892, 0.8591, 0.8550, 0.6266, 0.6225, 0.5047, 0.9160, 0.5618, 0.5494,\n",
      "        0.6901, 0.9306, 0.2239, 0.4323, 0.0024, 0.3007, 0.7951])\n",
      "[ TRAIN ] epoch 2 lr 0.0000078 acc: 0.5790 loss:  1.2383: 100%|‚ñà| 12454/12454 [4\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 785/785 [02:06<00:00,  6.22it/s]\n",
      "Valid Acc per class: tensor([0.3920, 0.8548, 0.7689, 0.6835, 0.6430, 0.5552, 0.9505, 0.5940, 0.5338,\n",
      "        0.7157, 0.8930, 0.3359, 0.3547, 0.0150, 0.1934, 0.7971])\n",
      "0.5163641075521633\n",
      "save model .....\n",
      "[ TRAIN ] epoch 3 lr 0.0000080 acc: 0.6234 loss:  1.1996:  16%|‚ñè| 1999/12454 [06Epoch: 3 | Step: 2000 | Train Acc per class: tensor([0.4255, 0.8908, 0.8717, 0.6774, 0.6679, 0.5422, 0.9209, 0.5499, 0.5372,\n",
      "        0.7189, 0.9497, 0.4694, 0.4889, 0.0172, 0.4414, 0.8073])\n",
      "[ TRAIN ] epoch 3 lr 0.0000080 acc: 0.6212 loss:  1.2055:  32%|‚ñé| 3999/12454 [13Epoch: 3 | Step: 4000 | Train Acc per class: tensor([0.4133, 0.8953, 0.8608, 0.6600, 0.6560, 0.5418, 0.9182, 0.5679, 0.5498,\n",
      "        0.7108, 0.9412, 0.4568, 0.4828, 0.0442, 0.4368, 0.8040])\n",
      "[ TRAIN ] epoch 3 lr 0.0000080 acc: 0.6260 loss:  1.2024:  48%|‚ñç| 5999/12454 [19Epoch: 3 | Step: 6000 | Train Acc per class: tensor([0.4062, 0.8856, 0.8518, 0.6644, 0.6602, 0.5434, 0.9196, 0.5754, 0.5554,\n",
      "        0.7099, 0.9391, 0.4766, 0.5164, 0.0658, 0.4402, 0.8057])\n",
      "[ TRAIN ] epoch 3 lr 0.0000079 acc: 0.6275 loss:  1.1994:  64%|‚ñã| 7999/12454 [26Epoch: 3 | Step: 8000 | Train Acc per class: tensor([0.4086, 0.8867, 0.8579, 0.6691, 0.6666, 0.5487, 0.9191, 0.5774, 0.5580,\n",
      "        0.7136, 0.9401, 0.4615, 0.4969, 0.0908, 0.4372, 0.8067])\n",
      "[ TRAIN ] epoch 3 lr 0.0000079 acc: 0.6301 loss:  1.1997:  80%|‚ñä| 9999/12454 [32Epoch: 3 | Step: 10000 | Train Acc per class: tensor([0.4181, 0.8883, 0.8616, 0.6659, 0.6596, 0.5479, 0.9161, 0.5775, 0.5589,\n",
      "        0.7143, 0.9375, 0.4690, 0.5072, 0.1239, 0.4309, 0.8055])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ TRAIN ] epoch 3 lr 0.0000078 acc: 0.6316 loss:  1.1985:  96%|‚ñâ| 11999/12454 [3Epoch: 3 | Step: 12000 | Train Acc per class: tensor([0.4240, 0.8881, 0.8598, 0.6673, 0.6601, 0.5418, 0.9145, 0.5798, 0.5605,\n",
      "        0.7158, 0.9380, 0.4763, 0.5111, 0.1323, 0.4303, 0.8053])\n",
      "[ TRAIN ] epoch 3 lr 0.0000078 acc: 0.6318 loss:  1.1975: 100%|‚ñà| 12454/12454 [4\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 785/785 [02:06<00:00,  6.21it/s]\n",
      "Valid Acc per class: tensor([0.4422, 0.8939, 0.8352, 0.6742, 0.6245, 0.5775, 0.8367, 0.6467, 0.6451,\n",
      "        0.7483, 0.9130, 0.6322, 0.7291, 0.4228, 0.7975, 0.7807])\n",
      "0.5954385409503101\n",
      "save model .....\n",
      "[ TRAIN ] epoch 4 lr 0.0000080 acc: 0.6657 loss:  1.1685:  16%|‚ñè| 1999/12454 [06Epoch: 4 | Step: 2000 | Train Acc per class: tensor([0.4771, 0.8882, 0.8466, 0.6618, 0.6720, 0.5575, 0.9047, 0.5877, 0.5989,\n",
      "        0.7367, 0.9441, 0.5298, 0.5718, 0.3037, 0.5598, 0.8110])\n",
      "[ TRAIN ] epoch 4 lr 0.0000080 acc: 0.6685 loss:  1.1699:  32%|‚ñé| 3999/12454 [12Epoch: 4 | Step: 4000 | Train Acc per class: tensor([0.4707, 0.8864, 0.8588, 0.6753, 0.6815, 0.5505, 0.9067, 0.5928, 0.5804,\n",
      "        0.7445, 0.9438, 0.5637, 0.5887, 0.3403, 0.4988, 0.8115])\n",
      "[ TRAIN ] epoch 4 lr 0.0000080 acc: 0.6660 loss:  1.1774:  48%|‚ñç| 5999/12454 [19Epoch: 4 | Step: 6000 | Train Acc per class: tensor([0.4521, 0.8860, 0.8626, 0.6860, 0.6859, 0.5561, 0.9068, 0.5991, 0.5845,\n",
      "        0.7585, 0.9482, 0.5420, 0.5521, 0.3544, 0.4713, 0.8101])\n",
      "[ TRAIN ] epoch 4 lr 0.0000079 acc: 0.6640 loss:  1.1797:  64%|‚ñã| 7999/12454 [26Epoch: 4 | Step: 8000 | Train Acc per class: tensor([0.4452, 0.8955, 0.8715, 0.6822, 0.6803, 0.5607, 0.9100, 0.5952, 0.5845,\n",
      "        0.7505, 0.9404, 0.5323, 0.5370, 0.3640, 0.4635, 0.8104])\n",
      "[ TRAIN ] epoch 4 lr 0.0000079 acc: 0.6644 loss:  1.1794:  80%|‚ñä| 9999/12454 [32Epoch: 4 | Step: 10000 | Train Acc per class: tensor([0.4453, 0.9031, 0.8774, 0.6819, 0.6773, 0.5620, 0.9117, 0.5905, 0.5775,\n",
      "        0.7473, 0.9358, 0.5298, 0.5392, 0.3757, 0.4654, 0.8106])\n",
      "[ TRAIN ] epoch 4 lr 0.0000078 acc: 0.6657 loss:  1.1779:  96%|‚ñâ| 11999/12454 [3Epoch: 4 | Step: 12000 | Train Acc per class: tensor([0.4479, 0.9065, 0.8805, 0.6828, 0.6766, 0.5628, 0.9110, 0.5917, 0.5796,\n",
      "        0.7433, 0.9365, 0.5334, 0.5367, 0.3867, 0.4644, 0.8110])\n",
      "[ TRAIN ] epoch 4 lr 0.0000078 acc: 0.6662 loss:  1.1777: 100%|‚ñà| 12454/12454 [4\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 785/785 [02:06<00:00,  6.19it/s]\n",
      "Valid Acc per class: tensor([0.5340, 0.9041, 0.8496, 0.7022, 0.6871, 0.5592, 0.8936, 0.5944, 0.5287,\n",
      "        0.7818, 0.9755, 0.5109, 0.5350, 0.4804, 0.4750, 0.8034])\n",
      "0.622874626855572\n",
      "save model .....\n",
      "[ TRAIN ] epoch 5 lr 0.0000080 acc: 0.6772 loss:  1.1655:  16%|‚ñè| 1999/12454 [06Epoch: 5 | Step: 2000 | Train Acc per class: tensor([0.4497, 0.8897, 0.8617, 0.7012, 0.6902, 0.5921, 0.9126, 0.5962, 0.5787,\n",
      "        0.7644, 0.9467, 0.5716, 0.5905, 0.4338, 0.4435, 0.8124])\n",
      "[ TRAIN ] epoch 5 lr 0.0000080 acc: 0.6738 loss:  1.1702:  32%|‚ñé| 3999/12454 [12Epoch: 5 | Step: 4000 | Train Acc per class: tensor([0.4512, 0.8991, 0.8753, 0.6994, 0.6888, 0.5808, 0.9136, 0.5988, 0.5804,\n",
      "        0.7558, 0.9377, 0.5609, 0.5661, 0.4259, 0.4319, 0.8128])\n",
      "[ TRAIN ] epoch 5 lr 0.0000080 acc: 0.6770 loss:  1.1652:  48%|‚ñç| 5999/12454 [19Epoch: 5 | Step: 6000 | Train Acc per class: tensor([0.4600, 0.9044, 0.8787, 0.6977, 0.6839, 0.5754, 0.9149, 0.6006, 0.5819,\n",
      "        0.7519, 0.9409, 0.5739, 0.5623, 0.4397, 0.4502, 0.8150])\n",
      "[ TRAIN ] epoch 5 lr 0.0000079 acc: 0.6795 loss:  1.1660:  53%|‚ñå| 6654/12454 [21"
     ]
    }
   ],
   "source": [
    "!python train.py --device 3 --wandb_comment \"original\" --print_acc 2000 --lr 8e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590018ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "282.255px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
