{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e687b39e",
   "metadata": {},
   "source": [
    "# CV Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf186f2b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-10T05:15:38.061Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "DATASET_PATH = ('../../../feedback-prize-2021')\n",
    "\n",
    "sys.path.insert(0, '../codes/new_transformers_branch/transformers/src')\n",
    "sys.path.append('../codes')\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f10550",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-10T05:15:38.407Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import re\n",
    "import pickle\n",
    "import random\n",
    "import easydict\n",
    "\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from new_transformers import DebertaV2TokenizerFast\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.autograd.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98f2ee3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-10T05:15:38.792Z"
    }
   },
   "outputs": [],
   "source": [
    "from module.metric import calc_acc, process_sample, make_match_dict\n",
    "\n",
    "from module.utils import get_data_files\n",
    "from module.dataset import get_dataloader\n",
    "from module.loss import get_criterion\n",
    "from module.optimizer import get_optimizer\n",
    "from module.scheduler import get_scheduler\n",
    "from model.model import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad64fdaa",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-10T05:15:39.124Z"
    }
   },
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({'model': 'microsoft/deberta-v3-large-ducky',\n",
    "                          'grad_checkpt': True,\n",
    "                          'cnn1d': False,\n",
    "                          'extra_dense': False,\n",
    "                          'device': 0,\n",
    "                          'ddp': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265bf1ef",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-10T05:15:39.444Z"
    }
   },
   "outputs": [],
   "source": [
    "model = get_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ca53ed",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-10T05:15:39.747Z"
    }
   },
   "outputs": [],
   "source": [
    "osp.join(DATASET_PATH, '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1036ab8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-10T05:15:40.064Z"
    }
   },
   "outputs": [],
   "source": [
    "fix_text = lambda x: x.replace('\\n', 'â€½')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c42837d",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70210f14",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-10T05:15:40.806Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class ValDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, files):\n",
    "        tokenizer = DebertaV2TokenizerFast.from_pretrained('microsoft/deberta-v3-large')\n",
    "        tokenizer.model_max_length = 2048\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        self.texts = {}\n",
    "        self.raw_texts = {}\n",
    "        \n",
    "        for file in files:\n",
    "            file_name = osp.join(DATASET_PATH, 'train', file + '.txt')\n",
    "            with open(file_name) as f:\n",
    "                text = f.read().strip()\n",
    "                self.texts[file] = fix_text(text)\n",
    "                self.raw_texts[file] = text\n",
    "                \n",
    "        self.text_ids = list(self.texts.keys())\n",
    "        self.space_regex = re.compile('[\\s\\n]')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text_ids)\n",
    "    \n",
    "    def __getitem__(self, ix):\n",
    "        tokens_array = np.zeros(2048, 'i8')\n",
    "        mask_array = np.zeros(2048, 'f4')\n",
    "        offsets_array = np.zeros((2048, 2), 'i4')\n",
    "        \n",
    "        text = self.texts[self.text_ids[ix]]\n",
    "        raw_text = self.raw_texts[self.text_ids[ix]]\n",
    "        text_id = self.text_ids[ix]\n",
    "        \n",
    "        tokenizer_outs = self.tokenizer(text, return_offsets_mapping=True)\n",
    "        tokenizer_outs['input_ids'] = [x if x != 126861 else 128000 for x in tokenizer_outs['input_ids']]\n",
    "        \n",
    "        tokens = np.array(tokenizer_outs['input_ids'], 'i8')\n",
    "        mask = np.array(tokenizer_outs['attention_mask'], 'f4')\n",
    "        offsets = np.vstack(tokenizer_outs['offset_mapping']).astype('i4')\n",
    "        \n",
    "        tokens_array[:len(tokens)] = tokens\n",
    "        tokens_array[len(tokens):] = 0\n",
    "        mask_array[:len(tokens)] = mask\n",
    "        mask_array[len(tokens):] = 0\n",
    "        offsets_array[:len(tokens)] = offsets\n",
    "        offsets_array[len(tokens):] = 0\n",
    "        \n",
    "        index_map = []\n",
    "        current_word = 0\n",
    "        blank = False\n",
    "        for char_ix in range(raw_text.index(raw_text.strip()[0]), len(raw_text)):\n",
    "            if self.space_regex.match(raw_text[char_ix]) is not None:\n",
    "                blank = True\n",
    "            elif blank:\n",
    "                current_word += 1\n",
    "                blank = False\n",
    "            index_map.append(current_word)\n",
    "        \n",
    "        return tokens_array, mask_array, offsets_array, index_map, text_id, len(tokens)\n",
    "    \n",
    "def collate_fn(ins):\n",
    "    max_len = (max(x[-1] for x in ins) + 7) // 8 * 8\n",
    "    return tuple(torch.from_numpy(np.concatenate([ins[z][x][None, :max_len] for z in range(len(ins))])) \n",
    "                 for x in range(len(ins[0]) - 3)) \\\n",
    "                 + ([x[-3] for x in ins], [x[-2] for x in ins], np.array([x[-1] for x in ins]),)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f7ba71",
   "metadata": {},
   "source": [
    "## Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4d42cd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-10T05:15:41.245Z"
    },
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "START_WITH_I = True\n",
    "LOOK_AHEAD = True\n",
    "\n",
    "def extract_entities(ps, n, return_score=False):\n",
    "    max_ps = ps.max(-1)\n",
    "    \n",
    "    ps = ps.argsort(-1)[...,::-1]\n",
    "    # argmax\n",
    "    cat_ps = ps[:, 0]\n",
    "    # argmax2\n",
    "    cat_ps2 = ps[:, 1]\n",
    "    \n",
    "    all_entities = {}\n",
    "    new_entity = True\n",
    "    current_cat = current_start = current_end = None\n",
    "    \n",
    "    # except for special tokens\n",
    "    for ix in range(1, n - 1):\n",
    "\n",
    "        # logic on new entity\n",
    "        if new_entity:\n",
    "            # Background - ignore\n",
    "            if cat_ps[ix] == 0:\n",
    "                pass\n",
    "\n",
    "            # B-LABEL(1,3,5,7,...) - start entity\n",
    "            elif cat_ps[ix] % 2 == 1:\n",
    "                current_cat = (cat_ps[ix] + 1) // 2\n",
    "                current_start = current_end = ix\n",
    "                new_entity = False\n",
    "                \n",
    "                if current_cat in [6, 7]:\n",
    "                    LOOK_AHEAD = False\n",
    "                else:\n",
    "                    LOOK_AHEAD = True\n",
    "\n",
    "            # I-LABEL(2,4,6,8,...) - conditional start\n",
    "            elif cat_ps[ix] % 2 == 0:\n",
    "                if START_WITH_I:\n",
    "                    # Condition: I-LABEL in argmax with B-LABEL in argmax2\n",
    "                    if cat_ps[ix] == (cat_ps2[ix]+1):\n",
    "                        current_cat = cat_ps[ix] // 2\n",
    "                        current_start = current_end = ix\n",
    "                        new_entity = False\n",
    "                        \n",
    "                        if current_cat in [6, 7]:\n",
    "                            LOOK_AHEAD = False\n",
    "                        else:\n",
    "                            LOOK_AHEAD = True\n",
    "        \n",
    "        # logic on ongoing entity\n",
    "        else:\n",
    "            # Background - save current entity and init current\n",
    "            if cat_ps[ix] == 0:\n",
    "                if LOOK_AHEAD:\n",
    "                    if (cat_ps[ix+1] == current_cat*2) and (cat_ps2[ix] == current_cat*2):\n",
    "                        current_end = ix\n",
    "                    else:\n",
    "                        # update current\n",
    "                        if current_cat not in all_entities:\n",
    "                            all_entities[current_cat] = []\n",
    "                        all_entities[current_cat].append((current_start, current_end))\n",
    "\n",
    "                        # init current for new start\n",
    "                        new_entity = True\n",
    "                        current_cat = current_start = current_end = None\n",
    "                \n",
    "                else:\n",
    "                    # update current\n",
    "                    if current_cat not in all_entities:\n",
    "                        all_entities[current_cat] = []\n",
    "                    all_entities[current_cat].append((current_start, current_end))\n",
    "\n",
    "                    # init current for new start\n",
    "                    new_entity = True\n",
    "                    current_cat = current_start = current_end = None\n",
    "\n",
    "            # B-LABEL(1,3,5,7,...) - save current entity and start new\n",
    "            elif cat_ps[ix] % 2 == 1:\n",
    "                if cat_ps[ix] == (current_cat*2-1):\n",
    "                    # update current\n",
    "                    if current_cat not in all_entities:\n",
    "                        all_entities[current_cat] = []\n",
    "                    all_entities[current_cat].append((current_start, current_end))\n",
    "\n",
    "                    # start new current\n",
    "                    current_cat = (cat_ps[ix] + 1) // 2\n",
    "                    current_start = current_end = ix\n",
    "                    new_entity = False\n",
    "                    \n",
    "                    if current_cat in [6, 7]:\n",
    "                        LOOK_AHEAD = False\n",
    "                    else:\n",
    "                        LOOK_AHEAD = True\n",
    "                \n",
    "                else:\n",
    "                    if LOOK_AHEAD:\n",
    "                        if (cat_ps[ix+1] == current_cat*2) and (cat_ps2[ix] == current_cat*2):\n",
    "                            current_end = ix\n",
    "                        else:\n",
    "                            # update current\n",
    "                            if current_cat not in all_entities:\n",
    "                                all_entities[current_cat] = []\n",
    "                            all_entities[current_cat].append((current_start, current_end))\n",
    "\n",
    "                            # start new current\n",
    "                            current_cat = (cat_ps[ix] + 1) // 2\n",
    "                            current_start = current_end = ix\n",
    "                            new_entity = False\n",
    "                        \n",
    "                            if current_cat in [6, 7]:\n",
    "                                LOOK_AHEAD = False\n",
    "                            else:\n",
    "                                LOOK_AHEAD = True\n",
    "                            \n",
    "                    else:\n",
    "                        # update current\n",
    "                        if current_cat not in all_entities:\n",
    "                            all_entities[current_cat] = []\n",
    "                        all_entities[current_cat].append((current_start, current_end))\n",
    "\n",
    "                        # start new current\n",
    "                        current_cat = (cat_ps[ix] + 1) // 2\n",
    "                        current_start = current_end = ix\n",
    "                        new_entity = False\n",
    "                        \n",
    "                        if current_cat in [6, 7]:\n",
    "                            LOOK_AHEAD = False\n",
    "                        else:\n",
    "                            LOOK_AHEAD = True\n",
    "                \n",
    "            # I-LABEL(2,4,6,8,...) - conditional continue\n",
    "            elif cat_ps[ix] % 2 == 0:\n",
    "                # B-LABEL0, I-LABEL0 - continue\n",
    "                if cat_ps[ix] == current_cat*2:\n",
    "                    current_end = ix\n",
    "                # B-LBAEL0, I-LABEL1 - conditional finish current entity\n",
    "                else:\n",
    "                    if LOOK_AHEAD:\n",
    "                        if (cat_ps[ix+1] == current_cat*2) and (cat_ps2[ix] == current_cat*2):\n",
    "                            current_end = ix\n",
    "                        else:\n",
    "                            # update current\n",
    "                            if current_cat not in all_entities:\n",
    "                                all_entities[current_cat] = []\n",
    "                            all_entities[current_cat].append((current_start, current_end))\n",
    "\n",
    "                            # init current\n",
    "                            new_entity = True\n",
    "                            current_cat = current_start = current_end = None\n",
    "                    else:\n",
    "                        # update current\n",
    "                        if current_cat not in all_entities:\n",
    "                            all_entities[current_cat] = []\n",
    "                        all_entities[current_cat].append((current_start, current_end))\n",
    "\n",
    "                        # init current\n",
    "                        new_entity = True\n",
    "                        current_cat = current_start = current_end = None\n",
    "    \n",
    "    # last entity\n",
    "    if not new_entity:\n",
    "        # update current\n",
    "        if current_cat not in all_entities:\n",
    "            all_entities[current_cat] = []\n",
    "        all_entities[current_cat].append((current_start, current_end))\n",
    "    \n",
    "    return all_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c53766",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-10T05:15:41.418Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def filter_ps(all_entities, ps):\n",
    "    \n",
    "    len_filters = [5, 2, 15, 2, 8, 7, 7]\n",
    "    score_filters = [0.55, 0.50, 0.55, 0.45, 0.50, 0.45, 0.50]\n",
    "    \n",
    "    for cat_ix, min_num_tokens, min_score in zip(range(1, 8), len_filters, score_filters):\n",
    "        \n",
    "        if cat_ix in all_entities:\n",
    "            possible_entities = [entity for entity in all_entities[cat_ix] \n",
    "                                 if entity[1] - entity[0] + 1 >= min_num_tokens\n",
    "                                 and calc_entity_score(entity, ps, cat_ix) * (entity[1] - entity[0])**.2 > min_score]\n",
    "    \n",
    "            if cat_ix in (1, 2, 5):\n",
    "                if len(possible_entities) > 1:\n",
    "                    max_score = -9999\n",
    "                    for possible_entity in possible_entities:\n",
    "                        entity_score = calc_entity_score(possible_entity, ps, cat_ix)\n",
    "                        if entity_score > max_score:\n",
    "                            max_score = entity_score\n",
    "                            biggest_entity = possible_entity\n",
    "                    possible_entities = [biggest_entity]\n",
    "            \n",
    "            all_entities[cat_ix] = possible_entities\n",
    "    \n",
    "    return all_entities.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c667bc",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-10T05:15:41.597Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def calc_entity_score(span, ps, c):\n",
    "    s, e = span\n",
    "    score = (ps[s, c * 2 - 1] + ps[s + 1 : e + 1, c * 2].sum()) / (e - s + 1)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c702513",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-10T05:15:41.783Z"
    }
   },
   "outputs": [],
   "source": [
    "def map_span_to_word_indices(span, index_map, bounds):\n",
    "    return (index_map[bounds[span[0], 0]], index_map[bounds[span[1], 1] - 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7e790d",
   "metadata": {},
   "source": [
    "## F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47247f69",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-10T05:15:42.607Z"
    },
    "code_folding": [
     0,
     17,
     71
    ]
   },
   "outputs": [],
   "source": [
    "def calc_overlap2(set_pred, set_gt):\n",
    "    \"\"\"\n",
    "    Calculates the overlap between prediction and\n",
    "    ground truth and overlap percentages used for determining\n",
    "    true positives.\n",
    "    \"\"\"\n",
    "    # Length of each and intersection\n",
    "    try:\n",
    "        len_gt = len(set_gt)\n",
    "        len_pred = len(set_pred)\n",
    "        inter = len(set_gt & set_pred)\n",
    "        overlap_1 = inter / len_gt\n",
    "        overlap_2 = inter/ len_pred\n",
    "        return (overlap_1, overlap_2)\n",
    "    except:  # at least one of the input is NaN\n",
    "        return (0, 0)\n",
    "\n",
    "def score_feedback_comp_micro2(pred_df, gt_df, discourse_type):\n",
    "    \"\"\"\n",
    "    A function that scores for the kaggle\n",
    "        Student Writing Competition\n",
    "        \n",
    "    Uses the steps in the evaluation page here:\n",
    "        https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n",
    "    \"\"\"\n",
    "    gt_df = gt_df.loc[gt_df['discourse_type'] == discourse_type, \n",
    "                      ['id', 'predictionstring']].reset_index(drop=True)\n",
    "    pred_df = pred_df.loc[pred_df['class'] == discourse_type,\n",
    "                      ['id', 'predictionstring']].reset_index(drop=True)\n",
    "    pred_df['pred_id'] = pred_df.index\n",
    "    gt_df['gt_id'] = gt_df.index\n",
    "    pred_df['predictionstring'] = [set(pred.split(' ')) for pred in pred_df['predictionstring']]\n",
    "    gt_df['predictionstring'] = [set(pred.split(' ')) for pred in gt_df['predictionstring']]\n",
    "    \n",
    "    # Step 1. all ground truths and predictions for a given class are compared.\n",
    "    joined = pred_df.merge(gt_df,\n",
    "                           left_on='id',\n",
    "                           right_on='id',\n",
    "                           how='outer',\n",
    "                           suffixes=('_pred','_gt')\n",
    "                          )\n",
    "    overlaps = [calc_overlap2(*args) for args in zip(joined.predictionstring_pred, \n",
    "                                                     joined.predictionstring_gt)]\n",
    "    \n",
    "    # 2. If the overlap between the ground truth and prediction is >= 0.5, \n",
    "    # and the overlap between the prediction and the ground truth >= 0.5,\n",
    "    # the prediction is a match and considered a true positive.\n",
    "    # If multiple matches exist, the match with the highest pair of overlaps is taken.\n",
    "    joined['potential_TP'] = [(overlap[0] >= 0.5 and overlap[1] >= 0.5) \\\n",
    "                              for overlap in overlaps]\n",
    "    joined['max_overlap'] = [max(*overlap) for overlap in overlaps]\n",
    "    joined_tp = joined.query('potential_TP').reset_index(drop=True)\n",
    "    tp_pred_ids = joined_tp\\\n",
    "        .sort_values('max_overlap', ascending=False) \\\n",
    "        .groupby(['id','gt_id'])['pred_id'].first()\n",
    "\n",
    "    # 3. Any unmatched ground truths are false negatives\n",
    "    # and any unmatched predictions are false positives.\n",
    "    fp_pred_ids = set(joined['pred_id'].unique()) - set(tp_pred_ids)\n",
    "\n",
    "    matched_gt_ids = joined_tp['gt_id'].unique()\n",
    "    unmatched_gt_ids = set(joined['gt_id'].unique()) -  set(matched_gt_ids)\n",
    "\n",
    "    # Get numbers of each type\n",
    "    TP = len(tp_pred_ids)\n",
    "    FP = len(fp_pred_ids)\n",
    "    FN = len(unmatched_gt_ids)\n",
    "    #calc microf1\n",
    "    my_f1_score = TP / (TP + 0.5*(FP+FN))\n",
    "    return my_f1_score\n",
    "\n",
    "def score_feedback_comp2(pred_df, gt_df, return_class_scores=False):\n",
    "    class_scores = {}\n",
    "    for discourse_type in gt_df.discourse_type.unique():\n",
    "        class_score = score_feedback_comp_micro2(pred_df, gt_df, discourse_type)\n",
    "        class_scores[discourse_type] = class_score\n",
    "    f1 = np.mean([v for v in class_scores.values()])\n",
    "    if return_class_scores:\n",
    "        return f1, class_scores\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08daaba4",
   "metadata": {},
   "source": [
    "## CV Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7878e30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T03:53:39.919678Z",
     "start_time": "2022-03-10T03:53:39.878717Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../data_file/id_to_ix_map.pickle', 'rb') as f:\n",
    "    id_to_ix_map = {x.split('/')[-1].split('.')[0]: y for x, y in pickle.load(f).items()}\n",
    "with open('../data_file/data_splits.pickle', 'rb') as f:\n",
    "    data_splits = pickle.load(f)\n",
    "\n",
    "val_files_all = []\n",
    "val_ids_all = []\n",
    "\n",
    "seed = 0\n",
    "for val_fold in range(5):\n",
    "    val_files = data_splits[seed][250]['normed'][val_fold]\n",
    "    val_ids = [id_to_ix_map[x] for x in val_files]\n",
    "    \n",
    "    val_files_all.append(val_files)\n",
    "    val_ids_all.append(val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d81b2921",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T04:56:36.104165Z",
     "start_time": "2022-03-10T04:41:41.647062Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3121 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3139 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3096 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3098 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_names = [\n",
    "    \"None\",\n",
    "    \"Lead\",\n",
    "    \"Position\",\n",
    "    \"Evidence\",\n",
    "    \"Claim\",\n",
    "    \"Concluding Statement\",\n",
    "    \"Counterclaim\",\n",
    "    \"Rebuttal\",\n",
    "]\n",
    "\n",
    "outs_f = []\n",
    "bounds_f = []\n",
    "token_nums_f = []\n",
    "word_indices_f = []\n",
    "sample_ids_f = []\n",
    "\n",
    "cv_n = 5\n",
    "checkpoints = os.listdir('../result/random_deletion_0.1')\n",
    "checkpoints = sorted(checkpoints, key=lambda checkpoint: checkpoint[checkpoint.index('fold') + 4])\n",
    "checkpoints = [osp.join('../result/random_deletion_0.1', checkpoint) for checkpoint in checkpoints]\n",
    "\n",
    "for val_fold in range(cv_n):\n",
    "    val_files = val_files_all[val_fold]\n",
    "    dataset = ValDataset(val_files)\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset, collate_fn=collate_fn, batch_size=1, num_workers=2, shuffle=False\n",
    "    )\n",
    "\n",
    "    model.eval().cuda()\n",
    "\n",
    "    all_outs = np.zeros((len(val_files), 2048, 15), \"f4\")\n",
    "    all_bounds = np.zeros((len(val_files), 2048, 2), \"i4\")\n",
    "    all_token_nums = np.zeros(len(val_files), \"i4\")\n",
    "    all_word_indices = []\n",
    "    all_sample_ids = []\n",
    "\n",
    "    model.load_state_dict(torch.load(checkpoints[val_fold]))\n",
    "    ix = 0\n",
    "    for batch in tqdm(dataloader, leave=False):\n",
    "        tokens, mask, bounds, word_indices, sample_ids, num_tokens = batch\n",
    "        batch_size, batch_len = tokens.shape[:2]\n",
    "        outs = torch.softmax(model(tokens.cuda(), mask.cuda()), -1)\n",
    "\n",
    "        all_outs[ix : ix + batch_size, :batch_len] += outs.cpu().numpy()\n",
    "        all_bounds[ix : ix + batch_size, :batch_len] = bounds\n",
    "        all_token_nums[ix : ix + batch_size] = num_tokens\n",
    "        all_word_indices.extend(word_indices)\n",
    "        all_sample_ids.extend(sample_ids)\n",
    "\n",
    "        ix += batch_size\n",
    "\n",
    "    outs_f.append(all_outs)\n",
    "    bounds_f.append(all_bounds)\n",
    "    token_nums_f.append(all_token_nums)\n",
    "    word_indices_f += all_word_indices\n",
    "    sample_ids_f += all_sample_ids\n",
    "\n",
    "all_outs = np.concatenate(outs_f)\n",
    "all_bounds = np.concatenate(bounds_f)\n",
    "all_token_nums = np.concatenate(token_nums_f)\n",
    "all_word_indices = word_indices_f\n",
    "all_sample_ids = sample_ids_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c68beaf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T04:56:41.343381Z",
     "start_time": "2022-03-10T04:56:41.112495Z"
    }
   },
   "outputs": [],
   "source": [
    "all_texts = {}\n",
    "for sample_id in all_sample_ids:\n",
    "    file_name = os.path.join(DATASET_PATH, \"train\", sample_id + \".txt\")\n",
    "    with open(file_name) as f:\n",
    "        all_texts[sample_id] = f.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3d69a86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T04:56:41.908447Z",
     "start_time": "2022-03-10T04:56:41.744164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.866e+03, 5.162e+03, 3.629e+03, 1.672e+03, 7.500e+02, 3.620e+02,\n",
       "        1.220e+02, 2.200e+01, 7.000e+00, 2.000e+00]),\n",
       " array([ 159.,  328.,  497.,  666.,  835., 1004., 1173., 1342., 1511.,\n",
       "        1680., 1849.]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(all_token_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd293661",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T04:56:46.504909Z",
     "start_time": "2022-03-10T04:56:46.500730Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15594, 2048, 15)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_outs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dcbbe1b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T04:56:47.475258Z",
     "start_time": "2022-03-10T04:56:47.470326Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "       8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_outs[0].argmax(-1)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe5a907f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T04:57:12.625997Z",
     "start_time": "2022-03-10T04:56:54.032405Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub_sample_ids = []\n",
    "sub_cat_names = []\n",
    "sub_spans = []\n",
    "sub_scores = []\n",
    "\n",
    "for sample_ix in tqdm(range(len(all_token_nums)), leave=False):\n",
    "    predicted_spans = {\n",
    "        x: {\n",
    "            \"entity\": [\n",
    "                map_span_to_word_indices(\n",
    "                    span, all_word_indices[sample_ix], all_bounds[sample_ix]\n",
    "                )\n",
    "                for span in y\n",
    "            ],\n",
    "            \"scores\": [calc_entity_score(span, all_outs[sample_ix], x) for span in y],\n",
    "        }\n",
    "        for x, y in filter_ps(\n",
    "            extract_entities(all_outs[sample_ix], all_token_nums[sample_ix]),\n",
    "            all_outs[sample_ix],\n",
    "        )\n",
    "    }\n",
    "    for cat_ix in predicted_spans:\n",
    "        for entity in predicted_spans[cat_ix][\"entity\"]:\n",
    "            sub_sample_ids.append(all_sample_ids[sample_ix])\n",
    "            sub_cat_names.append(label_names[cat_ix])\n",
    "            sub_spans.append(\" \".join(str(x) for x in range(entity[0], entity[1] + 1)))\n",
    "\n",
    "        for scores in predicted_spans[cat_ix][\"scores\"]:\n",
    "            sub_scores.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb14370d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T04:59:25.647267Z",
     "start_time": "2022-03-10T04:59:25.601349Z"
    }
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(\n",
    "    {\n",
    "        \"id\": sub_sample_ids,\n",
    "        \"class\": sub_cat_names,\n",
    "        \"predictionstring\": sub_spans,\n",
    "        \"scores\": sub_scores,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e4793a2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T04:59:25.974049Z",
     "start_time": "2022-03-10T04:59:25.960483Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4BB5ADD5A1FE</td>\n",
       "      <td>Lead</td>\n",
       "      <td>3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20...</td>\n",
       "      <td>0.911319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4BB5ADD5A1FE</td>\n",
       "      <td>Position</td>\n",
       "      <td>22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 3...</td>\n",
       "      <td>0.690047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4BB5ADD5A1FE</td>\n",
       "      <td>Claim</td>\n",
       "      <td>58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 7...</td>\n",
       "      <td>0.802341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4BB5ADD5A1FE</td>\n",
       "      <td>Claim</td>\n",
       "      <td>74 75 76 77 78 79 80 81 82 83 84</td>\n",
       "      <td>0.895073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4BB5ADD5A1FE</td>\n",
       "      <td>Claim</td>\n",
       "      <td>85 86 87</td>\n",
       "      <td>0.795256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141977</th>\n",
       "      <td>B9B45507DDF8</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "      <td>0.916623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141978</th>\n",
       "      <td>B9B45507DDF8</td>\n",
       "      <td>Position</td>\n",
       "      <td>58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 7...</td>\n",
       "      <td>0.897485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141979</th>\n",
       "      <td>B9B45507DDF8</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 9...</td>\n",
       "      <td>0.851508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141980</th>\n",
       "      <td>B9B45507DDF8</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>205 206 207 208 209 210 211 212 213 214 215 21...</td>\n",
       "      <td>0.759791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141981</th>\n",
       "      <td>B9B45507DDF8</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>260 261 262 263 264 265 266 267 268 269 270 27...</td>\n",
       "      <td>0.901663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141982 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                 class  \\\n",
       "0       4BB5ADD5A1FE                  Lead   \n",
       "1       4BB5ADD5A1FE              Position   \n",
       "2       4BB5ADD5A1FE                 Claim   \n",
       "3       4BB5ADD5A1FE                 Claim   \n",
       "4       4BB5ADD5A1FE                 Claim   \n",
       "...              ...                   ...   \n",
       "141977  B9B45507DDF8                  Lead   \n",
       "141978  B9B45507DDF8              Position   \n",
       "141979  B9B45507DDF8              Evidence   \n",
       "141980  B9B45507DDF8              Evidence   \n",
       "141981  B9B45507DDF8  Concluding Statement   \n",
       "\n",
       "                                         predictionstring    scores  \n",
       "0       3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20...  0.911319  \n",
       "1       22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 3...  0.690047  \n",
       "2       58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 7...  0.802341  \n",
       "3                        74 75 76 77 78 79 80 81 82 83 84  0.895073  \n",
       "4                                                85 86 87  0.795256  \n",
       "...                                                   ...       ...  \n",
       "141977  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...  0.916623  \n",
       "141978  58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 7...  0.897485  \n",
       "141979  78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 9...  0.851508  \n",
       "141980  205 206 207 208 209 210 211 212 213 214 215 21...  0.759791  \n",
       "141981  260 261 262 263 264 265 266 267 268 269 270 27...  0.901663  \n",
       "\n",
       "[141982 rows x 4 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8606bc9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T05:00:24.063849Z",
     "start_time": "2022-03-10T04:59:49.282001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7031898851110315, {'Lead': 0.8367390378884632, 'Position': 0.7256742464304601, 'Evidence': 0.7579283901762858, 'Claim': 0.6665331704679709, 'Concluding Statement': 0.8624940206792509, 'Counterclaim': 0.5801320020308005, 'Rebuttal': 0.49282832810398924})\n"
     ]
    }
   ],
   "source": [
    "sub = pd.DataFrame(\n",
    "    {\n",
    "        \"id\": sub_sample_ids,\n",
    "        \"class\": sub_cat_names,\n",
    "        \"predictionstring\": sub_spans,\n",
    "        \"scores\": sub_scores,\n",
    "    }\n",
    ")\n",
    "\n",
    "df = pd.read_csv(osp.join(DATASET_PATH, \"train.csv\"))\n",
    "\n",
    "val_df = df[[\"id\", \"discourse_type\", \"predictionstring\"]].reset_index(drop=True)\n",
    "val_df.shape\n",
    "\n",
    "print(score_feedback_comp2(sub, val_df, return_class_scores=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e5bfea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T06:53:18.956457Z",
     "start_time": "2022-03-04T06:53:18.954173Z"
    }
   },
   "outputs": [],
   "source": [
    "STOP!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec8fb03",
   "metadata": {},
   "source": [
    "## Understanding the process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fca0445",
   "metadata": {},
   "source": [
    "## Extract Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b70fbae4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T06:21:17.747728Z",
     "start_time": "2022-03-04T06:21:17.745763Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_ix = 241\n",
    "out, token_n = all_outs[sample_ix], all_token_nums[sample_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c05d76d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T07:33:02.035049Z",
     "start_time": "2022-03-05T07:33:02.033273Z"
    }
   },
   "outputs": [],
   "source": [
    "index_map, bounds = all_word_indices[sample_ix], all_bounds[sample_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "368f98b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T06:21:36.693931Z",
     "start_time": "2022-03-04T06:21:36.690551Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2048, 15), 437)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape, token_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "07119454",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T07:33:05.286459Z",
     "start_time": "2022-03-05T07:33:05.283424Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 2],\n",
       "       [2, 7],\n",
       "       ...,\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f15a1a41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T06:20:29.753595Z",
     "start_time": "2022-03-05T06:20:29.747578Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def extract_entities(preds, token_n):\n",
    "    class_preds = preds.argmax(-1)\n",
    "    all_entities = {}\n",
    "    current_class = None\n",
    "    current_start = None\n",
    "    for ix in range(1, token_n - 1):\n",
    "#         print('pred cat', class_preds[ix], 'current cat', current_class)\n",
    "        if class_preds[ix] % 2 == 1:\n",
    "            if current_class is not None:\n",
    "                if current_class not in all_entities:\n",
    "                    all_entities[current_class] = []\n",
    "#                 print(f'added class {current_class}!')\n",
    "                all_entities[current_class].append((current_start, ix - 1))\n",
    "            current_class = (class_preds[ix] + 1) // 2\n",
    "            current_start = ix        \n",
    "        \n",
    "    if current_class is not None:\n",
    "        if current_class not in all_entities:\n",
    "            all_entities[current_class] = []\n",
    "        all_entities[current_class].append((current_start, ix))\n",
    "    \n",
    "    return all_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2280a464",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T07:12:29.217660Z",
     "start_time": "2022-03-05T07:12:29.212396Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [(1, 24)],\n",
       " 2: [(25, 33)],\n",
       " 4: [(34, 116), (117, 131), (223, 231), (314, 326)],\n",
       " 3: [(132, 142), (143, 222), (232, 313), (327, 386)],\n",
       " 5: [(387, 435)]}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_out = extract_entities(out, token_n)\n",
    "extract_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e0b2e6",
   "metadata": {},
   "source": [
    "### map span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a11c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_span_to_word_indices(span, index_map, bounds):\n",
    "    return (index_map[bounds[span[0], 0]], index_map[bounds[span[1], 1] - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "759c325c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T07:35:34.320441Z",
     "start_time": "2022-03-05T07:35:34.318221Z"
    }
   },
   "outputs": [],
   "source": [
    "span = (1, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "39da9533",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T07:37:16.945242Z",
     "start_time": "2022-03-05T07:37:16.942159Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 103)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first token's start index\n",
    "# last tokens's end index\n",
    "bounds[span[0], 0], bounds[span[1], 1] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ba56eaf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T07:38:53.458113Z",
     "start_time": "2022-03-05T07:38:53.454260Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 19)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the word index\n",
    "index_map[bounds[span[0], 0]], index_map[bounds[span[1], 1] - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "04d8caf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T07:33:08.947493Z",
     "start_time": "2022-03-05T07:33:08.945311Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted_spans = {x: [map_span_to_word_indices(span, index_map, bounds) for span in y]\n",
    "                   for x, y in extract_out.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ff869526",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T07:33:11.342062Z",
     "start_time": "2022-03-05T07:33:11.339083Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [(0, 19)],\n",
       " 2: [(19, 26)],\n",
       " 4: [(26, 97), (98, 107), (187, 192), (265, 277)],\n",
       " 3: [(107, 117), (117, 186), (192, 264), (277, 328)],\n",
       " 5: [(329, 375)]}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_spans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abdd31f",
   "metadata": {},
   "source": [
    "### function split_predstrig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "89bec96f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T06:37:15.306403Z",
     "start_time": "2022-03-04T06:37:15.303593Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_predstring(predstring):\n",
    "    vals = predstring.split()\n",
    "    return int(vals[0]), int(vals[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6218f56a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T06:37:40.117914Z",
     "start_time": "2022-03-04T06:37:40.114215Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 44)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_predstring(val_df.predictionstring[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
