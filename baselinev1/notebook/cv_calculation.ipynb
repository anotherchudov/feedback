{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e687b39e",
   "metadata": {},
   "source": [
    "# CV Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf186f2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T03:05:03.311503Z",
     "start_time": "2022-03-04T03:05:03.308089Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "DATASET_PATH = ('../../../feedback-prize-2021')\n",
    "\n",
    "sys.path.insert(0, '../codes/new_transformers_branch/transformers/src')\n",
    "sys.path.append('../codes')\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "46f10550",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T04:15:08.619916Z",
     "start_time": "2022-03-04T04:15:08.612923Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f2b7f189ed0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import re\n",
    "import pickle\n",
    "import random\n",
    "import easydict\n",
    "\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from new_transformers import DebertaV2TokenizerFast\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.autograd.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c98f2ee3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T01:59:29.069687Z",
     "start_time": "2022-03-04T01:59:29.004710Z"
    }
   },
   "outputs": [],
   "source": [
    "from module.metric import calc_acc, process_sample, make_match_dict\n",
    "\n",
    "from module.utils import get_data_files\n",
    "from module.dataset import get_dataloader\n",
    "from module.loss import get_criterion\n",
    "from module.optimizer import get_optimizer\n",
    "from module.scheduler import get_scheduler\n",
    "from model.model import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ad64fdaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T03:24:54.497970Z",
     "start_time": "2022-03-04T03:24:54.494595Z"
    }
   },
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({'model': 'microsoft/deberta-v3-large-ducky',\n",
    "                          'grad_checkpt': True,\n",
    "                          'cnn1d': False,\n",
    "                          'extra_dense': False,\n",
    "                          'device': 0,\n",
    "                          'ddp': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "265bf1ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T03:24:59.833073Z",
     "start_time": "2022-03-04T03:24:54.700871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Ducky Modified DebertaV2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.bias', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = get_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55ca53ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T02:03:16.427748Z",
     "start_time": "2022-03-04T02:03:16.424663Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../feedback-prize-2021/1'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osp.join(DATASET_PATH, '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1036ab8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T03:06:12.856798Z",
     "start_time": "2022-03-04T03:06:12.854046Z"
    }
   },
   "outputs": [],
   "source": [
    "fix_text = lambda x: x.replace('\\n', '‽')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c42837d",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "70210f14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T03:26:28.402384Z",
     "start_time": "2022-03-04T03:26:28.391815Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class ValDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, files):\n",
    "        tokenizer = DebertaV2TokenizerFast.from_pretrained('microsoft/deberta-v3-large')\n",
    "        tokenizer.model_max_length = 2048\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        self.texts = {}\n",
    "        self.raw_texts = {}\n",
    "        \n",
    "        for file in files:\n",
    "            file_name = osp.join(DATASET_PATH, 'train', file + '.txt')\n",
    "            with open(file_name) as f:\n",
    "                text = f.read().strip()\n",
    "                self.texts[file] = fix_text(text)\n",
    "                self.raw_texts[file] = text\n",
    "                \n",
    "        self.text_ids = list(self.texts.keys())\n",
    "        self.space_regex = re.compile('[\\s\\n]')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text_ids)\n",
    "    \n",
    "    def __getitem__(self, ix):\n",
    "        tokens_array = np.zeros(2048, 'i8')\n",
    "        mask_array = np.zeros(2048, 'f4')\n",
    "        offsets_array = np.zeros((2048, 2), 'i4')\n",
    "        \n",
    "        text = self.texts[self.text_ids[ix]]\n",
    "        raw_text = self.raw_texts[self.text_ids[ix]]\n",
    "        text_id = self.text_ids[ix]\n",
    "        \n",
    "        tokenizer_outs = self.tokenizer(text, return_offsets_mapping=True)\n",
    "        tokenizer_outs['input_ids'] = [x if x != 126861 else 128000 for x in tokenizer_outs['input_ids']]\n",
    "        \n",
    "        tokens = np.array(tokenizer_outs['input_ids'], 'i8')\n",
    "        mask = np.array(tokenizer_outs['attention_mask'], 'f4')\n",
    "        offsets = np.vstack(tokenizer_outs['offset_mapping']).astype('i4')\n",
    "        \n",
    "        tokens_array[:len(tokens)] = tokens\n",
    "        tokens_array[len(tokens):] = 0\n",
    "        mask_array[:len(tokens)] = mask\n",
    "        mask_array[len(tokens):] = 0\n",
    "        offsets_array[:len(tokens)] = offsets\n",
    "        offsets_array[len(tokens):] = 0\n",
    "        \n",
    "        index_map = []\n",
    "        current_word = 0\n",
    "        blank = False\n",
    "        for char_ix in range(raw_text.index(raw_text.strip()[0]), len(raw_text)):\n",
    "            if self.space_regex.match(raw_text[char_ix]) is not None:\n",
    "                blank = True\n",
    "            elif blank:\n",
    "                current_word += 1\n",
    "                blank = False\n",
    "            index_map.append(current_word)\n",
    "        \n",
    "        return tokens_array, mask_array, offsets_array, index_map, text_id, len(tokens)\n",
    "    \n",
    "def collate_fn(ins):\n",
    "    max_len = (max(x[-1] for x in ins) + 7) // 8 * 8\n",
    "    return tuple(torch.from_numpy(np.concatenate([ins[z][x][None, :max_len] for z in range(len(ins))])) \n",
    "                 for x in range(len(ins[0]) - 3)) \\\n",
    "                 + ([x[-3] for x in ins], [x[-2] for x in ins], np.array([x[-1] for x in ins]),)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f7ba71",
   "metadata": {},
   "source": [
    "## Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf4d42cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T03:20:27.395469Z",
     "start_time": "2022-03-04T03:20:27.381603Z"
    },
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "START_WITH_I = True\n",
    "LOOK_AHEAD = True\n",
    "\n",
    "def extract_entities(ps, n, return_score=False):\n",
    "    max_ps = ps.max(-1)\n",
    "    \n",
    "    ps = ps.argsort(-1)[...,::-1]\n",
    "    # argmax\n",
    "    cat_ps = ps[:, 0]\n",
    "    # argmax2\n",
    "    cat_ps2 = ps[:, 1]\n",
    "    \n",
    "    all_entities = {}\n",
    "    new_entity = True\n",
    "    current_cat = current_start = current_end = None\n",
    "    \n",
    "    # except for special tokens\n",
    "    for ix in range(1, n - 1):\n",
    "\n",
    "        # logic on new entity\n",
    "        if new_entity:\n",
    "            # Background - ignore\n",
    "            if cat_ps[ix] == 0:\n",
    "                pass\n",
    "\n",
    "            # B-LABEL(1,3,5,7,...) - start entity\n",
    "            elif cat_ps[ix] % 2 == 1:\n",
    "                current_cat = (cat_ps[ix] + 1) // 2\n",
    "                current_start = current_end = ix\n",
    "                new_entity = False\n",
    "                \n",
    "                if current_cat in [6, 7]:\n",
    "                    LOOK_AHEAD = False\n",
    "                else:\n",
    "                    LOOK_AHEAD = True\n",
    "\n",
    "            # I-LABEL(2,4,6,8,...) - conditional start\n",
    "            elif cat_ps[ix] % 2 == 0:\n",
    "                if START_WITH_I:\n",
    "                    # Condition: I-LABEL in argmax with B-LABEL in argmax2\n",
    "                    if cat_ps[ix] == (cat_ps2[ix]+1):\n",
    "                        current_cat = cat_ps[ix] // 2\n",
    "                        current_start = current_end = ix\n",
    "                        new_entity = False\n",
    "                        \n",
    "                        if current_cat in [6, 7]:\n",
    "                            LOOK_AHEAD = False\n",
    "                        else:\n",
    "                            LOOK_AHEAD = True\n",
    "        \n",
    "        # logic on ongoing entity\n",
    "        else:\n",
    "            # Background - save current entity and init current\n",
    "            if cat_ps[ix] == 0:\n",
    "                if LOOK_AHEAD:\n",
    "                    if (cat_ps[ix+1] == current_cat*2) and (cat_ps2[ix] == current_cat*2):\n",
    "                        current_end = ix\n",
    "                    else:\n",
    "                        # update current\n",
    "                        if current_cat not in all_entities:\n",
    "                            all_entities[current_cat] = []\n",
    "                        all_entities[current_cat].append((current_start, current_end))\n",
    "\n",
    "                        # init current for new start\n",
    "                        new_entity = True\n",
    "                        current_cat = current_start = current_end = None\n",
    "                \n",
    "                else:\n",
    "                    # update current\n",
    "                    if current_cat not in all_entities:\n",
    "                        all_entities[current_cat] = []\n",
    "                    all_entities[current_cat].append((current_start, current_end))\n",
    "\n",
    "                    # init current for new start\n",
    "                    new_entity = True\n",
    "                    current_cat = current_start = current_end = None\n",
    "\n",
    "            # B-LABEL(1,3,5,7,...) - save current entity and start new\n",
    "            elif cat_ps[ix] % 2 == 1:\n",
    "                if cat_ps[ix] == (current_cat*2-1):\n",
    "                    # update current\n",
    "                    if current_cat not in all_entities:\n",
    "                        all_entities[current_cat] = []\n",
    "                    all_entities[current_cat].append((current_start, current_end))\n",
    "\n",
    "                    # start new current\n",
    "                    current_cat = (cat_ps[ix] + 1) // 2\n",
    "                    current_start = current_end = ix\n",
    "                    new_entity = False\n",
    "                    \n",
    "                    if current_cat in [6, 7]:\n",
    "                        LOOK_AHEAD = False\n",
    "                    else:\n",
    "                        LOOK_AHEAD = True\n",
    "                \n",
    "                else:\n",
    "                    if LOOK_AHEAD:\n",
    "                        if (cat_ps[ix+1] == current_cat*2) and (cat_ps2[ix] == current_cat*2):\n",
    "                            current_end = ix\n",
    "                        else:\n",
    "                            # update current\n",
    "                            if current_cat not in all_entities:\n",
    "                                all_entities[current_cat] = []\n",
    "                            all_entities[current_cat].append((current_start, current_end))\n",
    "\n",
    "                            # start new current\n",
    "                            current_cat = (cat_ps[ix] + 1) // 2\n",
    "                            current_start = current_end = ix\n",
    "                            new_entity = False\n",
    "                        \n",
    "                            if current_cat in [6, 7]:\n",
    "                                LOOK_AHEAD = False\n",
    "                            else:\n",
    "                                LOOK_AHEAD = True\n",
    "                            \n",
    "                    else:\n",
    "                        # update current\n",
    "                        if current_cat not in all_entities:\n",
    "                            all_entities[current_cat] = []\n",
    "                        all_entities[current_cat].append((current_start, current_end))\n",
    "\n",
    "                        # start new current\n",
    "                        current_cat = (cat_ps[ix] + 1) // 2\n",
    "                        current_start = current_end = ix\n",
    "                        new_entity = False\n",
    "                        \n",
    "                        if current_cat in [6, 7]:\n",
    "                            LOOK_AHEAD = False\n",
    "                        else:\n",
    "                            LOOK_AHEAD = True\n",
    "                \n",
    "            # I-LABEL(2,4,6,8,...) - conditional continue\n",
    "            elif cat_ps[ix] % 2 == 0:\n",
    "                # B-LABEL0, I-LABEL0 - continue\n",
    "                if cat_ps[ix] == current_cat*2:\n",
    "                    current_end = ix\n",
    "                # B-LBAEL0, I-LABEL1 - conditional finish current entity\n",
    "                else:\n",
    "                    if LOOK_AHEAD:\n",
    "                        if (cat_ps[ix+1] == current_cat*2) and (cat_ps2[ix] == current_cat*2):\n",
    "                            current_end = ix\n",
    "                        else:\n",
    "                            # update current\n",
    "                            if current_cat not in all_entities:\n",
    "                                all_entities[current_cat] = []\n",
    "                            all_entities[current_cat].append((current_start, current_end))\n",
    "\n",
    "                            # init current\n",
    "                            new_entity = True\n",
    "                            current_cat = current_start = current_end = None\n",
    "                    else:\n",
    "                        # update current\n",
    "                        if current_cat not in all_entities:\n",
    "                            all_entities[current_cat] = []\n",
    "                        all_entities[current_cat].append((current_start, current_end))\n",
    "\n",
    "                        # init current\n",
    "                        new_entity = True\n",
    "                        current_cat = current_start = current_end = None\n",
    "    \n",
    "    # last entity\n",
    "    if not new_entity:\n",
    "        # update current\n",
    "        if current_cat not in all_entities:\n",
    "            all_entities[current_cat] = []\n",
    "        all_entities[current_cat].append((current_start, current_end))\n",
    "    \n",
    "    return all_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "67c53766",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T03:20:27.748791Z",
     "start_time": "2022-03-04T03:20:27.741747Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def filter_ps(all_entities, ps):\n",
    "    \n",
    "    token_len_filters = [7, 2, 16, 0, 7, 7, 7]\n",
    "    score_filters = [2.14832197, 2.35317, 3.40350222, 2.21235943, 1.25163358, 1.79241061, 1.37411479]\n",
    "    \n",
    "    for cat_ix, min_num_tokens, min_score in zip(range(1, 8), token_len_filters, score_filters):\n",
    "        \n",
    "        if cat_ix in all_entities:\n",
    "            possible_entities = [entity for entity in all_entities[cat_ix] \n",
    "                                 if entity[1] - entity[0] + 1 >= min_num_tokens\n",
    "                                 and calc_entity_score(entity, ps, cat_ix) * (entity[1] - entity[0])**.2 > min_score]\n",
    "    \n",
    "            if cat_ix in (1, 2, 5):\n",
    "                if len(possible_entities) > 1:\n",
    "                    max_score = -9999\n",
    "                    for possible_entity in possible_entities:\n",
    "                        entity_score = calc_entity_score(possible_entity, ps, cat_ix)\n",
    "                        if entity_score > max_score:\n",
    "                            max_score = entity_score\n",
    "                            biggest_entity = possible_entity\n",
    "                    possible_entities = [biggest_entity]\n",
    "            \n",
    "            all_entities[cat_ix] = possible_entities\n",
    "    \n",
    "    return all_entities.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f3c667bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T04:25:17.873586Z",
     "start_time": "2022-03-04T04:25:17.869116Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_entity_score(span, ps, c):\n",
    "    s, e = span\n",
    "    score = (ps[s, c * 2 - 1] + ps[s + 1 : e + 1, c * 2].sum()) / (e - s + 1)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8c702513",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T04:25:18.344053Z",
     "start_time": "2022-03-04T04:25:18.340881Z"
    }
   },
   "outputs": [],
   "source": [
    "def map_span_to_word_indices(span, index_map, bounds):\n",
    "    return (index_map[bounds[span[0], 0]], index_map[bounds[span[1], 1] - 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7e790d",
   "metadata": {},
   "source": [
    "## F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "47247f69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T04:26:00.856507Z",
     "start_time": "2022-03-04T04:26:00.846140Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_overlap2(set_pred, set_gt):\n",
    "    \"\"\"\n",
    "    Calculates the overlap between prediction and\n",
    "    ground truth and overlap percentages used for determining\n",
    "    true positives.\n",
    "    \"\"\"\n",
    "    # Length of each and intersection\n",
    "    try:\n",
    "        len_gt = len(set_gt)\n",
    "        len_pred = len(set_pred)\n",
    "        inter = len(set_gt & set_pred)\n",
    "        overlap_1 = inter / len_gt\n",
    "        overlap_2 = inter/ len_pred\n",
    "        return (overlap_1, overlap_2)\n",
    "    except:  # at least one of the input is NaN\n",
    "        return (0, 0)\n",
    "\n",
    "def score_feedback_comp_micro2(pred_df, gt_df, discourse_type):\n",
    "    \"\"\"\n",
    "    A function that scores for the kaggle\n",
    "        Student Writing Competition\n",
    "        \n",
    "    Uses the steps in the evaluation page here:\n",
    "        https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n",
    "    \"\"\"\n",
    "    gt_df = gt_df.loc[gt_df['discourse_type'] == discourse_type, \n",
    "                      ['id', 'predictionstring']].reset_index(drop=True)\n",
    "    pred_df = pred_df.loc[pred_df['class'] == discourse_type,\n",
    "                      ['id', 'predictionstring']].reset_index(drop=True)\n",
    "    pred_df['pred_id'] = pred_df.index\n",
    "    gt_df['gt_id'] = gt_df.index\n",
    "    pred_df['predictionstring'] = [set(pred.split(' ')) for pred in pred_df['predictionstring']]\n",
    "    gt_df['predictionstring'] = [set(pred.split(' ')) for pred in gt_df['predictionstring']]\n",
    "    \n",
    "    # Step 1. all ground truths and predictions for a given class are compared.\n",
    "    joined = pred_df.merge(gt_df,\n",
    "                           left_on='id',\n",
    "                           right_on='id',\n",
    "                           how='outer',\n",
    "                           suffixes=('_pred','_gt')\n",
    "                          )\n",
    "    overlaps = [calc_overlap2(*args) for args in zip(joined.predictionstring_pred, \n",
    "                                                     joined.predictionstring_gt)]\n",
    "    \n",
    "    # 2. If the overlap between the ground truth and prediction is >= 0.5, \n",
    "    # and the overlap between the prediction and the ground truth >= 0.5,\n",
    "    # the prediction is a match and considered a true positive.\n",
    "    # If multiple matches exist, the match with the highest pair of overlaps is taken.\n",
    "    joined['potential_TP'] = [(overlap[0] >= 0.5 and overlap[1] >= 0.5) \\\n",
    "                              for overlap in overlaps]\n",
    "    joined['max_overlap'] = [max(*overlap) for overlap in overlaps]\n",
    "    joined_tp = joined.query('potential_TP').reset_index(drop=True)\n",
    "    tp_pred_ids = joined_tp\\\n",
    "        .sort_values('max_overlap', ascending=False) \\\n",
    "        .groupby(['id','gt_id'])['pred_id'].first()\n",
    "\n",
    "    # 3. Any unmatched ground truths are false negatives\n",
    "    # and any unmatched predictions are false positives.\n",
    "    fp_pred_ids = set(joined['pred_id'].unique()) - set(tp_pred_ids)\n",
    "\n",
    "    matched_gt_ids = joined_tp['gt_id'].unique()\n",
    "    unmatched_gt_ids = set(joined['gt_id'].unique()) -  set(matched_gt_ids)\n",
    "\n",
    "    # Get numbers of each type\n",
    "    TP = len(tp_pred_ids)\n",
    "    FP = len(fp_pred_ids)\n",
    "    FN = len(unmatched_gt_ids)\n",
    "    #calc microf1\n",
    "    my_f1_score = TP / (TP + 0.5*(FP+FN))\n",
    "    return my_f1_score\n",
    "\n",
    "def score_feedback_comp2(pred_df, gt_df, return_class_scores=False):\n",
    "    class_scores = {}\n",
    "    for discourse_type in gt_df.discourse_type.unique():\n",
    "        class_score = score_feedback_comp_micro2(pred_df, gt_df, discourse_type)\n",
    "        class_scores[discourse_type] = class_score\n",
    "    f1 = np.mean([v for v in class_scores.values()])\n",
    "    if return_class_scores:\n",
    "        return f1, class_scores\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08daaba4",
   "metadata": {},
   "source": [
    "## CV Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b7878e30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T03:20:29.092783Z",
     "start_time": "2022-03-04T03:20:29.055729Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../data_file/id_to_ix_map.pickle', 'rb') as f:\n",
    "    id_to_ix_map = {x.split('/')[-1].split('.')[0]: y for x, y in pickle.load(f).items()}\n",
    "with open('../data_file/data_splits.pickle', 'rb') as f:\n",
    "    data_splits = pickle.load(f)\n",
    "\n",
    "val_files_all = []\n",
    "val_ids_all = []\n",
    "\n",
    "seed = 0\n",
    "for val_fold in range(5):\n",
    "    val_files = data_splits[seed][250]['normed'][val_fold]\n",
    "    val_ids = [id_to_ix_map[x] for x in val_files]\n",
    "    \n",
    "    val_files_all.append(val_files)\n",
    "    val_ids_all.append(val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3c63b3e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T04:29:28.714507Z",
     "start_time": "2022-03-04T04:29:28.710675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3140"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d81b2921",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T03:31:56.251298Z",
     "start_time": "2022-03-04T03:26:35.569471Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_names = [\n",
    "    \"None\",\n",
    "    \"Lead\",\n",
    "    \"Position\",\n",
    "    \"Evidence\",\n",
    "    \"Claim\",\n",
    "    \"Concluding Statement\",\n",
    "    \"Counterclaim\",\n",
    "    \"Rebuttal\",\n",
    "]\n",
    "\n",
    "outs_f = []\n",
    "bounds_f = []\n",
    "token_nums_f = []\n",
    "word_indices_f = []\n",
    "sample_ids_f = []\n",
    "\n",
    "cv_n = 1\n",
    "checkpoints = [f\"../result/debertav3_fold0_f10.7006.pth\" for i in range(cv_n)]\n",
    "\n",
    "\n",
    "for val_fold in range(cv_n):\n",
    "    val_files = val_files_all[val_fold]\n",
    "    dataset = ValDataset(val_files)\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset, collate_fn=collate_fn, batch_size=1, num_workers=2, shuffle=False\n",
    "    )\n",
    "\n",
    "    model.eval().cuda()\n",
    "\n",
    "    all_outs = np.zeros((len(val_files), 2048, 15), \"f4\")\n",
    "    all_bounds = np.zeros((len(val_files), 2048, 2), \"i4\")\n",
    "    all_token_nums = np.zeros(len(val_files), \"i4\")\n",
    "    all_word_indices = []\n",
    "    all_sample_ids = []\n",
    "\n",
    "    model.load_state_dict(torch.load(checkpoints[val_fold]))\n",
    "    ix = 0\n",
    "    for batch in tqdm(dataloader, leave=False):\n",
    "        tokens, mask, bounds, word_indices, sample_ids, num_tokens = batch\n",
    "        batch_size, batch_len = tokens.shape[:2]\n",
    "        outs = torch.softmax(model(tokens.cuda(), mask.cuda()), -1)\n",
    "\n",
    "        all_outs[ix : ix + batch_size, :batch_len] += outs.cpu().numpy()\n",
    "        all_bounds[ix : ix + batch_size, :batch_len] = bounds\n",
    "        all_token_nums[ix : ix + batch_size] = num_tokens\n",
    "        all_word_indices.extend(word_indices)\n",
    "        all_sample_ids.extend(sample_ids)\n",
    "\n",
    "        ix += batch_size\n",
    "\n",
    "    outs_f.append(all_outs)\n",
    "    bounds_f.append(all_bounds)\n",
    "    token_nums_f.append(all_token_nums)\n",
    "    word_indices_f += all_word_indices\n",
    "    sample_ids_f += all_sample_ids\n",
    "\n",
    "all_outs = np.concatenate(outs_f)\n",
    "all_bounds = np.concatenate(bounds_f)\n",
    "all_token_nums = np.concatenate(token_nums_f)\n",
    "all_word_indices = word_indices_f\n",
    "all_sample_ids = sample_ids_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c68beaf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T03:31:56.300534Z",
     "start_time": "2022-03-04T03:31:56.252753Z"
    }
   },
   "outputs": [],
   "source": [
    "all_texts = {}\n",
    "for sample_id in all_sample_ids:\n",
    "    file_name = os.path.join(DATASET_PATH, \"train\", sample_id + \".txt\")\n",
    "    with open(file_name) as f:\n",
    "        all_texts[sample_id] = f.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c3d69a86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T04:15:18.632333Z",
     "start_time": "2022-03-04T04:15:18.476731Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([538., 781., 756., 507., 269., 152.,  68.,  51.,  13.,   5.]),\n",
       " array([ 159. ,  287.7,  416.4,  545.1,  673.8,  802.5,  931.2, 1059.9,\n",
       "        1188.6, 1317.3, 1446. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(all_token_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dd293661",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T05:32:06.318895Z",
     "start_time": "2022-03-04T05:32:06.314949Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3140, 2048, 15)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_outs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fe5a907f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T04:25:24.940617Z",
     "start_time": "2022-03-04T04:25:21.633244Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub_sample_ids = []\n",
    "sub_cat_names = []\n",
    "sub_spans = []\n",
    "sub_scores = []\n",
    "for sample_ix in tqdm(range(len(all_token_nums)), leave=False):\n",
    "    predicted_spans = {\n",
    "        x: {\n",
    "            \"entity\": [\n",
    "                map_span_to_word_indices(\n",
    "                    span, all_word_indices[sample_ix], all_bounds[sample_ix]\n",
    "                )\n",
    "                for span in y\n",
    "            ],\n",
    "            \"scores\": [calc_entity_score(span, all_outs[sample_ix], x) for span in y],\n",
    "        }\n",
    "        for x, y in filter_ps(\n",
    "            extract_entities(all_outs[sample_ix], all_token_nums[sample_ix]),\n",
    "            all_outs[sample_ix],\n",
    "        )\n",
    "    }\n",
    "\n",
    "    for cat_ix in predicted_spans:\n",
    "        for entity in predicted_spans[cat_ix][\"entity\"]:\n",
    "            sub_sample_ids.append(all_sample_ids[sample_ix])\n",
    "            sub_cat_names.append(label_names[cat_ix])\n",
    "            sub_spans.append(\" \".join(str(x) for x in range(entity[0], entity[1] + 1)))\n",
    "\n",
    "        for scores in predicted_spans[cat_ix][\"scores\"]:\n",
    "            sub_scores.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e4793a2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T06:27:10.745518Z",
     "start_time": "2022-03-04T06:27:10.735986Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4BB5ADD5A1FE</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>452 453 454 455 456 457 458 459 460 461 462 46...</td>\n",
       "      <td>0.915185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F789157CB6E6</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>283 284 285 286 287 288 289 290 291 292 293 29...</td>\n",
       "      <td>0.881351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86BB3D5BA612</td>\n",
       "      <td>Rebuttal</td>\n",
       "      <td>415 416 417 418 419 420 421 422 423 424 425 42...</td>\n",
       "      <td>0.794262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86BB3D5BA612</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>640 641 642 643 644 645 646 647 648 649 650 65...</td>\n",
       "      <td>0.894495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>738E215A237A</td>\n",
       "      <td>Rebuttal</td>\n",
       "      <td>322 323 324 325 326 327 328 329 330 331 332 33...</td>\n",
       "      <td>0.851713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3915</th>\n",
       "      <td>674EBED0C821</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>219 220 221 222 223 224 225 226 227 228 229 23...</td>\n",
       "      <td>0.824070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3916</th>\n",
       "      <td>960BA7EF10B0</td>\n",
       "      <td>Rebuttal</td>\n",
       "      <td>87 88 89 90 91 92 93 94 95 96 97 98 99 100 101...</td>\n",
       "      <td>0.738240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3917</th>\n",
       "      <td>B5CAA2329C07</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>275 276 277 278 279 280 281 282 283 284 285 28...</td>\n",
       "      <td>0.917904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3918</th>\n",
       "      <td>F296C5CF54D7</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>621 622 623 624 625 626 627 628 629 630 631 63...</td>\n",
       "      <td>0.871677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3919</th>\n",
       "      <td>9378439A9F12</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>295 296 297 298 299 300 301 302 303 304 305 30...</td>\n",
       "      <td>0.819428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3920 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                 class  \\\n",
       "0     4BB5ADD5A1FE  Concluding Statement   \n",
       "1     F789157CB6E6  Concluding Statement   \n",
       "2     86BB3D5BA612              Rebuttal   \n",
       "3     86BB3D5BA612  Concluding Statement   \n",
       "4     738E215A237A              Rebuttal   \n",
       "...            ...                   ...   \n",
       "3915  674EBED0C821  Concluding Statement   \n",
       "3916  960BA7EF10B0              Rebuttal   \n",
       "3917  B5CAA2329C07  Concluding Statement   \n",
       "3918  F296C5CF54D7  Concluding Statement   \n",
       "3919  9378439A9F12  Concluding Statement   \n",
       "\n",
       "                                       predictionstring    scores  \n",
       "0     452 453 454 455 456 457 458 459 460 461 462 46...  0.915185  \n",
       "1     283 284 285 286 287 288 289 290 291 292 293 29...  0.881351  \n",
       "2     415 416 417 418 419 420 421 422 423 424 425 42...  0.794262  \n",
       "3     640 641 642 643 644 645 646 647 648 649 650 65...  0.894495  \n",
       "4     322 323 324 325 326 327 328 329 330 331 332 33...  0.851713  \n",
       "...                                                 ...       ...  \n",
       "3915  219 220 221 222 223 224 225 226 227 228 229 23...  0.824070  \n",
       "3916  87 88 89 90 91 92 93 94 95 96 97 98 99 100 101...  0.738240  \n",
       "3917  275 276 277 278 279 280 281 282 283 284 285 28...  0.917904  \n",
       "3918  621 622 623 624 625 626 627 628 629 630 631 63...  0.871677  \n",
       "3919  295 296 297 298 299 300 301 302 303 304 305 30...  0.819428  \n",
       "\n",
       "[3920 rows x 4 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8a582eea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T04:27:38.710847Z",
     "start_time": "2022-03-04T04:27:38.703341Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>Lead</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>Position</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>Claim</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144288</th>\n",
       "      <td>4C471936CD75</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>386 387 388 389 390 391 392 393 394 395 396 39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144289</th>\n",
       "      <td>4C471936CD75</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>576 577 578 579 580 581 582 583 584 585 586 58...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144290</th>\n",
       "      <td>4C471936CD75</td>\n",
       "      <td>Position</td>\n",
       "      <td>828 829 830 831 832 833 834 835 836 837 838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144291</th>\n",
       "      <td>4C471936CD75</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>839 840 841 842 843 844 845 846 847 848 849 85...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144292</th>\n",
       "      <td>4C471936CD75</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>905 906 907 908 909 910 911 912 913 914 915 91...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144293 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id        discourse_type  \\\n",
       "0       423A1CA112E2                  Lead   \n",
       "1       423A1CA112E2              Position   \n",
       "2       423A1CA112E2              Evidence   \n",
       "3       423A1CA112E2              Evidence   \n",
       "4       423A1CA112E2                 Claim   \n",
       "...              ...                   ...   \n",
       "144288  4C471936CD75              Evidence   \n",
       "144289  4C471936CD75              Evidence   \n",
       "144290  4C471936CD75              Position   \n",
       "144291  4C471936CD75              Evidence   \n",
       "144292  4C471936CD75  Concluding Statement   \n",
       "\n",
       "                                         predictionstring  \n",
       "0       1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...  \n",
       "1            45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  \n",
       "2         60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  \n",
       "3       76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...  \n",
       "4       139 140 141 142 143 144 145 146 147 148 149 15...  \n",
       "...                                                   ...  \n",
       "144288  386 387 388 389 390 391 392 393 394 395 396 39...  \n",
       "144289  576 577 578 579 580 581 582 583 584 585 586 58...  \n",
       "144290        828 829 830 831 832 833 834 835 836 837 838  \n",
       "144291  839 840 841 842 843 844 845 846 847 848 849 85...  \n",
       "144292  905 906 907 908 909 910 911 912 913 914 915 91...  \n",
       "\n",
       "[144293 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8606bc9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T04:26:25.654452Z",
     "start_time": "2022-03-04T04:26:03.314350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.08154630947334403, {'Lead': 0.08428175945862812, 'Position': 0.0, 'Evidence': 0.0, 'Claim': 0.0, 'Concluding Statement': 0.2920446830833796, 'Counterclaim': 0.050974512743628186, 'Rebuttal': 0.14352321102777216})\n"
     ]
    }
   ],
   "source": [
    "sub = pd.DataFrame(\n",
    "    {\n",
    "        \"id\": sub_sample_ids,\n",
    "        \"class\": sub_cat_names,\n",
    "        \"predictionstring\": sub_spans,\n",
    "        \"scores\": sub_scores,\n",
    "    }\n",
    ")\n",
    "\n",
    "df = pd.read_csv(osp.join(DATASET_PATH, \"train.csv\"))\n",
    "\n",
    "val_df = df[[\"id\", \"discourse_type\", \"predictionstring\"]].reset_index(drop=True)\n",
    "val_df.shape\n",
    "\n",
    "print(score_feedback_comp2(sub, val_df, return_class_scores=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e5bfea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T06:53:18.956457Z",
     "start_time": "2022-03-04T06:53:18.954173Z"
    }
   },
   "outputs": [],
   "source": [
    "STOP!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec8fb03",
   "metadata": {},
   "source": [
    "## Understanding the process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fca0445",
   "metadata": {},
   "source": [
    "## Extract Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b70fbae4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T06:21:17.747728Z",
     "start_time": "2022-03-04T06:21:17.745763Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_ix = 241\n",
    "out, token_n = all_outs[sample_ix], all_token_nums[sample_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "23171c82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T07:15:12.783658Z",
     "start_time": "2022-03-05T07:15:12.781136Z"
    }
   },
   "outputs": [],
   "source": [
    "index_map, bound = all_word_indices[sample_ix], all_bounds[sample_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3103936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "368f98b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T06:21:36.693931Z",
     "start_time": "2022-03-04T06:21:36.690551Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2048, 15), 437)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape, token_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f15a1a41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T06:20:29.753595Z",
     "start_time": "2022-03-05T06:20:29.747578Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def extract_entities(preds, token_n):\n",
    "    class_preds = preds.argmax(-1)\n",
    "    all_entities = {}\n",
    "    current_class = None\n",
    "    current_start = None\n",
    "    for ix in range(1, token_n - 1):\n",
    "#         print('pred cat', class_preds[ix], 'current cat', current_class)\n",
    "        if class_preds[ix] % 2 == 1:\n",
    "            if current_class is not None:\n",
    "                if current_class not in all_entities:\n",
    "                    all_entities[current_class] = []\n",
    "#                 print(f'added class {current_class}!')\n",
    "                all_entities[current_class].append((current_start, ix - 1))\n",
    "            current_class = (class_preds[ix] + 1) // 2\n",
    "            current_start = ix        \n",
    "        \n",
    "    if current_class is not None:\n",
    "        if current_class not in all_entities:\n",
    "            all_entities[current_class] = []\n",
    "        all_entities[current_class].append((current_start, ix))\n",
    "    \n",
    "    return all_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2280a464",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T07:12:29.217660Z",
     "start_time": "2022-03-05T07:12:29.212396Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [(1, 24)],\n",
       " 2: [(25, 33)],\n",
       " 4: [(34, 116), (117, 131), (223, 231), (314, 326)],\n",
       " 3: [(132, 142), (143, 222), (232, 313), (327, 386)],\n",
       " 5: [(387, 435)]}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_out = extract_entities(out, token_n)\n",
    "extract_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501b7228",
   "metadata": {},
   "source": [
    "### map span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6b4633",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_span_to_word_indices(\n",
    "                    span, \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c294ad5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T07:13:01.011064Z",
     "start_time": "2022-03-05T07:13:00.981316Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1774894/953492374.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredicted_spans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmap_span_to_word_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mspan\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextract_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1774894/953492374.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredicted_spans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmap_span_to_word_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mspan\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextract_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1774894/953492374.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredicted_spans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmap_span_to_word_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mspan\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextract_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1774894/3130710118.py\u001b[0m in \u001b[0;36mmap_span_to_word_indices\u001b[0;34m(span, index_map, bounds)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmap_span_to_word_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindex_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "predicted_spans = {x: [map_span_to_word_indices(span, index_map, bounds) for span in y]\n",
    "                   for x, y in extract_out.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abdd31f",
   "metadata": {},
   "source": [
    "### function split_predstrig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "89bec96f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T06:37:15.306403Z",
     "start_time": "2022-03-04T06:37:15.303593Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_predstring(predstring):\n",
    "    vals = predstring.split()\n",
    "    return int(vals[0]), int(vals[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6218f56a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T06:37:40.117914Z",
     "start_time": "2022-03-04T06:37:40.114215Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 44)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_predstring(val_df.predictionstring[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
