{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e687b39e",
   "metadata": {},
   "source": [
    "# CV Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf186f2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T03:05:03.311503Z",
     "start_time": "2022-03-04T03:05:03.308089Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "DATASET_PATH = ('../../../feedback-prize-2021')\n",
    "\n",
    "sys.path.insert(0, '../codes/new_transformers_branch/transformers/src')\n",
    "sys.path.append('../codes')\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "46f10550",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T04:15:08.619916Z",
     "start_time": "2022-03-04T04:15:08.612923Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f2b7f189ed0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import re\n",
    "import pickle\n",
    "import random\n",
    "import easydict\n",
    "\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from new_transformers import DebertaV2TokenizerFast\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.autograd.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c98f2ee3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T01:59:29.069687Z",
     "start_time": "2022-03-04T01:59:29.004710Z"
    }
   },
   "outputs": [],
   "source": [
    "from module.metric import calc_acc, process_sample, make_match_dict\n",
    "\n",
    "from module.utils import get_data_files\n",
    "from module.dataset import get_dataloader\n",
    "from module.loss import get_criterion\n",
    "from module.optimizer import get_optimizer\n",
    "from module.scheduler import get_scheduler\n",
    "from model.model import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ad64fdaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T03:24:54.497970Z",
     "start_time": "2022-03-04T03:24:54.494595Z"
    }
   },
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({'model': 'microsoft/deberta-v3-large-ducky',\n",
    "                          'grad_checkpt': True,\n",
    "                          'cnn1d': False,\n",
    "                          'extra_dense': False,\n",
    "                          'device': 0,\n",
    "                          'ddp': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "265bf1ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T07:54:05.199023Z",
     "start_time": "2022-03-05T07:53:59.822086Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Ducky Modified DebertaV2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.bias', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = get_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55ca53ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T02:03:16.427748Z",
     "start_time": "2022-03-04T02:03:16.424663Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../feedback-prize-2021/1'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osp.join(DATASET_PATH, '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1036ab8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T03:06:12.856798Z",
     "start_time": "2022-03-04T03:06:12.854046Z"
    }
   },
   "outputs": [],
   "source": [
    "fix_text = lambda x: x.replace('\\n', 'â€½')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c42837d",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "70210f14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T03:26:28.402384Z",
     "start_time": "2022-03-04T03:26:28.391815Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class ValDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, files):\n",
    "        tokenizer = DebertaV2TokenizerFast.from_pretrained('microsoft/deberta-v3-large')\n",
    "        tokenizer.model_max_length = 2048\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        self.texts = {}\n",
    "        self.raw_texts = {}\n",
    "        \n",
    "        for file in files:\n",
    "            file_name = osp.join(DATASET_PATH, 'train', file + '.txt')\n",
    "            with open(file_name) as f:\n",
    "                text = f.read().strip()\n",
    "                self.texts[file] = fix_text(text)\n",
    "                self.raw_texts[file] = text\n",
    "                \n",
    "        self.text_ids = list(self.texts.keys())\n",
    "        self.space_regex = re.compile('[\\s\\n]')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text_ids)\n",
    "    \n",
    "    def __getitem__(self, ix):\n",
    "        tokens_array = np.zeros(2048, 'i8')\n",
    "        mask_array = np.zeros(2048, 'f4')\n",
    "        offsets_array = np.zeros((2048, 2), 'i4')\n",
    "        \n",
    "        text = self.texts[self.text_ids[ix]]\n",
    "        raw_text = self.raw_texts[self.text_ids[ix]]\n",
    "        text_id = self.text_ids[ix]\n",
    "        \n",
    "        tokenizer_outs = self.tokenizer(text, return_offsets_mapping=True)\n",
    "        tokenizer_outs['input_ids'] = [x if x != 126861 else 128000 for x in tokenizer_outs['input_ids']]\n",
    "        \n",
    "        tokens = np.array(tokenizer_outs['input_ids'], 'i8')\n",
    "        mask = np.array(tokenizer_outs['attention_mask'], 'f4')\n",
    "        offsets = np.vstack(tokenizer_outs['offset_mapping']).astype('i4')\n",
    "        \n",
    "        tokens_array[:len(tokens)] = tokens\n",
    "        tokens_array[len(tokens):] = 0\n",
    "        mask_array[:len(tokens)] = mask\n",
    "        mask_array[len(tokens):] = 0\n",
    "        offsets_array[:len(tokens)] = offsets\n",
    "        offsets_array[len(tokens):] = 0\n",
    "        \n",
    "        index_map = []\n",
    "        current_word = 0\n",
    "        blank = False\n",
    "        for char_ix in range(raw_text.index(raw_text.strip()[0]), len(raw_text)):\n",
    "            if self.space_regex.match(raw_text[char_ix]) is not None:\n",
    "                blank = True\n",
    "            elif blank:\n",
    "                current_word += 1\n",
    "                blank = False\n",
    "            index_map.append(current_word)\n",
    "        \n",
    "        return tokens_array, mask_array, offsets_array, index_map, text_id, len(tokens)\n",
    "    \n",
    "def collate_fn(ins):\n",
    "    max_len = (max(x[-1] for x in ins) + 7) // 8 * 8\n",
    "    return tuple(torch.from_numpy(np.concatenate([ins[z][x][None, :max_len] for z in range(len(ins))])) \n",
    "                 for x in range(len(ins[0]) - 3)) \\\n",
    "                 + ([x[-3] for x in ins], [x[-2] for x in ins], np.array([x[-1] for x in ins]),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "cb6d0d86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T09:11:15.499957Z",
     "start_time": "2022-03-05T09:11:07.916438Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DebertaV2TokenizerFast.from_pretrained('microsoft/deberta-v3-large')\n",
    "tokenizer.model_max_length = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "87e4d136",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T09:13:19.964507Z",
     "start_time": "2022-03-05T09:13:19.959822Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 263, 296, 273, 391, 339, 268, 446, 277, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'offset_mapping': [(0, 0), (0, 3), (3, 8), (8, 10), (10, 15), (15, 20), (20, 21), (21, 27), (27, 30), (0, 0)]}"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_outs = tokenizer('and will I know whats going on', return_offsets_mapping=True)\n",
    "tokenizer_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "abcc6c0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T09:13:30.167764Z",
     "start_time": "2022-03-05T09:13:30.164177Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 263, 296, 273, 391, 2976, 6407, 297, 268, 446, 277, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'offset_mapping': [(0, 0), (0, 3), (3, 8), (8, 10), (10, 15), (15, 17), (17, 19), (19, 20), (20, 21), (21, 27), (27, 30), (0, 0)]}"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_outs = tokenizer('and will I know wzats going on', return_offsets_mapping=True)\n",
    "tokenizer_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "a01f56c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T09:14:45.080950Z",
     "start_time": "2022-03-05T09:14:45.076896Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wzats going on[SEP]'"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer_outs['input_ids'][-7:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "e98cdff2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T09:20:17.998602Z",
     "start_time": "2022-03-05T09:20:17.983446Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (12) into shape (5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1774894/1298775721.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m263\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m296\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m273\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m391\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2976\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6407\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m297\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m268\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m446\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m277\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (12) into shape (5)"
     ]
    }
   ],
   "source": [
    "a = np.zeros(5)\n",
    "a[:5] = np.array([1, 263, 296, 273, 391, 2976, 6407, 297, 268, 446, 277, 2])\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f7ba71",
   "metadata": {},
   "source": [
    "## Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "bf4d42cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T12:02:10.426521Z",
     "start_time": "2022-03-05T12:02:10.405986Z"
    },
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "START_WITH_I = True\n",
    "LOOK_AHEAD = True\n",
    "\n",
    "def extract_entities(ps, n, return_score=False):\n",
    "    max_ps = ps.max(-1)\n",
    "    \n",
    "    ps = ps.argsort(-1)[...,::-1]\n",
    "    # argmax\n",
    "    cat_ps = ps[:, 0]\n",
    "    # argmax2\n",
    "    cat_ps2 = ps[:, 1]\n",
    "    \n",
    "    all_entities = {}\n",
    "    new_entity = True\n",
    "    current_cat = current_start = current_end = None\n",
    "    \n",
    "    # except for special tokens\n",
    "    for ix in range(1, n - 1):\n",
    "\n",
    "        # logic on new entity\n",
    "        if new_entity:\n",
    "            # Background - ignore\n",
    "            if cat_ps[ix] == 0:\n",
    "                pass\n",
    "\n",
    "            # B-LABEL(1,3,5,7,...) - start entity\n",
    "            elif cat_ps[ix] % 2 == 1:\n",
    "                current_cat = (cat_ps[ix] + 1) // 2\n",
    "                current_start = current_end = ix\n",
    "                new_entity = False\n",
    "                \n",
    "                if current_cat in [6, 7]:\n",
    "                    LOOK_AHEAD = False\n",
    "                else:\n",
    "                    LOOK_AHEAD = True\n",
    "\n",
    "            # I-LABEL(2,4,6,8,...) - conditional start\n",
    "            elif cat_ps[ix] % 2 == 0:\n",
    "                if START_WITH_I:\n",
    "                    # Condition: I-LABEL in argmax with B-LABEL in argmax2\n",
    "                    if cat_ps[ix] == (cat_ps2[ix]+1):\n",
    "                        current_cat = cat_ps[ix] // 2\n",
    "                        current_start = current_end = ix\n",
    "                        new_entity = False\n",
    "                        \n",
    "                        if current_cat in [6, 7]:\n",
    "                            LOOK_AHEAD = False\n",
    "                        else:\n",
    "                            LOOK_AHEAD = True\n",
    "        \n",
    "        # logic on ongoing entity\n",
    "        else:\n",
    "            # Background - save current entity and init current\n",
    "            if cat_ps[ix] == 0:\n",
    "                if LOOK_AHEAD:\n",
    "                    if (cat_ps[ix+1] == current_cat*2) and (cat_ps2[ix] == current_cat*2):\n",
    "                        current_end = ix\n",
    "                    else:\n",
    "                        # update current\n",
    "                        if current_cat not in all_entities:\n",
    "                            all_entities[current_cat] = []\n",
    "                        all_entities[current_cat].append((current_start, current_end))\n",
    "\n",
    "                        # init current for new start\n",
    "                        new_entity = True\n",
    "                        current_cat = current_start = current_end = None\n",
    "                \n",
    "                else:\n",
    "                    # update current\n",
    "                    if current_cat not in all_entities:\n",
    "                        all_entities[current_cat] = []\n",
    "                    all_entities[current_cat].append((current_start, current_end))\n",
    "\n",
    "                    # init current for new start\n",
    "                    new_entity = True\n",
    "                    current_cat = current_start = current_end = None\n",
    "\n",
    "            # B-LABEL(1,3,5,7,...) - save current entity and start new\n",
    "            elif cat_ps[ix] % 2 == 1:\n",
    "                if cat_ps[ix] == (current_cat*2-1):\n",
    "                    # update current\n",
    "                    if current_cat not in all_entities:\n",
    "                        all_entities[current_cat] = []\n",
    "                    all_entities[current_cat].append((current_start, current_end))\n",
    "\n",
    "                    # start new current\n",
    "                    current_cat = (cat_ps[ix] + 1) // 2\n",
    "                    current_start = current_end = ix\n",
    "                    new_entity = False\n",
    "                    \n",
    "                    if current_cat in [6, 7]:\n",
    "                        LOOK_AHEAD = False\n",
    "                    else:\n",
    "                        LOOK_AHEAD = True\n",
    "                \n",
    "                else:\n",
    "                    if LOOK_AHEAD:\n",
    "                        if (cat_ps[ix+1] == current_cat*2) and (cat_ps2[ix] == current_cat*2):\n",
    "                            current_end = ix\n",
    "                        else:\n",
    "                            # update current\n",
    "                            if current_cat not in all_entities:\n",
    "                                all_entities[current_cat] = []\n",
    "                            all_entities[current_cat].append((current_start, current_end))\n",
    "\n",
    "                            # start new current\n",
    "                            current_cat = (cat_ps[ix] + 1) // 2\n",
    "                            current_start = current_end = ix\n",
    "                            new_entity = False\n",
    "                        \n",
    "                            if current_cat in [6, 7]:\n",
    "                                LOOK_AHEAD = False\n",
    "                            else:\n",
    "                                LOOK_AHEAD = True\n",
    "                            \n",
    "                    else:\n",
    "                        # update current\n",
    "                        if current_cat not in all_entities:\n",
    "                            all_entities[current_cat] = []\n",
    "                        all_entities[current_cat].append((current_start, current_end))\n",
    "\n",
    "                        # start new current\n",
    "                        current_cat = (cat_ps[ix] + 1) // 2\n",
    "                        current_start = current_end = ix\n",
    "                        new_entity = False\n",
    "                        \n",
    "                        if current_cat in [6, 7]:\n",
    "                            LOOK_AHEAD = False\n",
    "                        else:\n",
    "                            LOOK_AHEAD = True\n",
    "                \n",
    "            # I-LABEL(2,4,6,8,...) - conditional continue\n",
    "            elif cat_ps[ix] % 2 == 0:\n",
    "                # B-LABEL0, I-LABEL0 - continue\n",
    "                if cat_ps[ix] == current_cat*2:\n",
    "                    current_end = ix\n",
    "                # B-LBAEL0, I-LABEL1 - conditional finish current entity\n",
    "                else:\n",
    "                    if LOOK_AHEAD:\n",
    "                        if (cat_ps[ix+1] == current_cat*2) and (cat_ps2[ix] == current_cat*2):\n",
    "                            current_end = ix\n",
    "                        else:\n",
    "                            # update current\n",
    "                            if current_cat not in all_entities:\n",
    "                                all_entities[current_cat] = []\n",
    "                            all_entities[current_cat].append((current_start, current_end))\n",
    "\n",
    "                            # init current\n",
    "                            new_entity = True\n",
    "                            current_cat = current_start = current_end = None\n",
    "                    else:\n",
    "                        # update current\n",
    "                        if current_cat not in all_entities:\n",
    "                            all_entities[current_cat] = []\n",
    "                        all_entities[current_cat].append((current_start, current_end))\n",
    "\n",
    "                        # init current\n",
    "                        new_entity = True\n",
    "                        current_cat = current_start = current_end = None\n",
    "    \n",
    "    # last entity\n",
    "    if not new_entity:\n",
    "        # update current\n",
    "        if current_cat not in all_entities:\n",
    "            all_entities[current_cat] = []\n",
    "        all_entities[current_cat].append((current_start, current_end))\n",
    "    \n",
    "    return all_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "67c53766",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T12:04:31.765971Z",
     "start_time": "2022-03-05T12:04:31.758421Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def filter_ps(all_entities, ps):\n",
    "    \n",
    "    len_filters = [5, 2, 15, 2, 8, 7, 7]\n",
    "    score_filters = [0.55, 0.50, 0.55, 0.45, 0.50, 0.45, 0.50]\n",
    "    \n",
    "    for cat_ix, min_num_tokens, min_score in zip(range(1, 8), len_filters, score_filters):\n",
    "        \n",
    "        if cat_ix in all_entities:\n",
    "            possible_entities = [entity for entity in all_entities[cat_ix] \n",
    "                                 if entity[1] - entity[0] + 1 >= min_num_tokens\n",
    "                                 and calc_entity_score(entity, ps, cat_ix) * (entity[1] - entity[0])**.2 > min_score]\n",
    "    \n",
    "            if cat_ix in (1, 2, 5):\n",
    "                if len(possible_entities) > 1:\n",
    "                    max_score = -9999\n",
    "                    for possible_entity in possible_entities:\n",
    "                        entity_score = calc_entity_score(possible_entity, ps, cat_ix)\n",
    "                        if entity_score > max_score:\n",
    "                            max_score = entity_score\n",
    "                            biggest_entity = possible_entity\n",
    "                    possible_entities = [biggest_entity]\n",
    "            \n",
    "            all_entities[cat_ix] = possible_entities\n",
    "    \n",
    "    return all_entities.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "f3c667bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T12:02:10.860318Z",
     "start_time": "2022-03-05T12:02:10.857547Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def calc_entity_score(span, ps, c):\n",
    "    s, e = span\n",
    "    score = (ps[s, c * 2 - 1] + ps[s + 1 : e + 1, c * 2].sum()) / (e - s + 1)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "8c702513",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T12:02:11.072046Z",
     "start_time": "2022-03-05T12:02:11.069509Z"
    }
   },
   "outputs": [],
   "source": [
    "def map_span_to_word_indices(span, index_map, bounds):\n",
    "    return (index_map[bounds[span[0], 0]], index_map[bounds[span[1], 1] - 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7e790d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "47247f69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T04:26:00.856507Z",
     "start_time": "2022-03-04T04:26:00.846140Z"
    },
    "code_folding": [
     0,
     17,
     71
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def calc_overlap2(set_pred, set_gt):\n",
    "    \"\"\"\n",
    "    Calculates the overlap between prediction and\n",
    "    ground truth and overlap percentages used for determining\n",
    "    true positives.\n",
    "    \"\"\"\n",
    "    # Length of each and intersection\n",
    "    try:\n",
    "        len_gt = len(set_gt)\n",
    "        len_pred = len(set_pred)\n",
    "        inter = len(set_gt & set_pred)\n",
    "        overlap_1 = inter / len_gt\n",
    "        overlap_2 = inter/ len_pred\n",
    "        return (overlap_1, overlap_2)\n",
    "    except:  # at least one of the input is NaN\n",
    "        return (0, 0)\n",
    "\n",
    "def score_feedback_comp_micro2(pred_df, gt_df, discourse_type):\n",
    "    \"\"\"\n",
    "    A function that scores for the kaggle\n",
    "        Student Writing Competition\n",
    "        \n",
    "    Uses the steps in the evaluation page here:\n",
    "        https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n",
    "    \"\"\"\n",
    "    gt_df = gt_df.loc[gt_df['discourse_type'] == discourse_type, \n",
    "                      ['id', 'predictionstring']].reset_index(drop=True)\n",
    "    pred_df = pred_df.loc[pred_df['class'] == discourse_type,\n",
    "                      ['id', 'predictionstring']].reset_index(drop=True)\n",
    "    pred_df['pred_id'] = pred_df.index\n",
    "    gt_df['gt_id'] = gt_df.index\n",
    "    pred_df['predictionstring'] = [set(pred.split(' ')) for pred in pred_df['predictionstring']]\n",
    "    gt_df['predictionstring'] = [set(pred.split(' ')) for pred in gt_df['predictionstring']]\n",
    "    \n",
    "    # Step 1. all ground truths and predictions for a given class are compared.\n",
    "    joined = pred_df.merge(gt_df,\n",
    "                           left_on='id',\n",
    "                           right_on='id',\n",
    "                           how='outer',\n",
    "                           suffixes=('_pred','_gt')\n",
    "                          )\n",
    "    overlaps = [calc_overlap2(*args) for args in zip(joined.predictionstring_pred, \n",
    "                                                     joined.predictionstring_gt)]\n",
    "    \n",
    "    # 2. If the overlap between the ground truth and prediction is >= 0.5, \n",
    "    # and the overlap between the prediction and the ground truth >= 0.5,\n",
    "    # the prediction is a match and considered a true positive.\n",
    "    # If multiple matches exist, the match with the highest pair of overlaps is taken.\n",
    "    joined['potential_TP'] = [(overlap[0] >= 0.5 and overlap[1] >= 0.5) \\\n",
    "                              for overlap in overlaps]\n",
    "    joined['max_overlap'] = [max(*overlap) for overlap in overlaps]\n",
    "    joined_tp = joined.query('potential_TP').reset_index(drop=True)\n",
    "    tp_pred_ids = joined_tp\\\n",
    "        .sort_values('max_overlap', ascending=False) \\\n",
    "        .groupby(['id','gt_id'])['pred_id'].first()\n",
    "\n",
    "    # 3. Any unmatched ground truths are false negatives\n",
    "    # and any unmatched predictions are false positives.\n",
    "    fp_pred_ids = set(joined['pred_id'].unique()) - set(tp_pred_ids)\n",
    "\n",
    "    matched_gt_ids = joined_tp['gt_id'].unique()\n",
    "    unmatched_gt_ids = set(joined['gt_id'].unique()) -  set(matched_gt_ids)\n",
    "\n",
    "    # Get numbers of each type\n",
    "    TP = len(tp_pred_ids)\n",
    "    FP = len(fp_pred_ids)\n",
    "    FN = len(unmatched_gt_ids)\n",
    "    #calc microf1\n",
    "    my_f1_score = TP / (TP + 0.5*(FP+FN))\n",
    "    return my_f1_score\n",
    "\n",
    "def score_feedback_comp2(pred_df, gt_df, return_class_scores=False):\n",
    "    class_scores = {}\n",
    "    for discourse_type in gt_df.discourse_type.unique():\n",
    "        class_score = score_feedback_comp_micro2(pred_df, gt_df, discourse_type)\n",
    "        class_scores[discourse_type] = class_score\n",
    "    f1 = np.mean([v for v in class_scores.values()])\n",
    "    if return_class_scores:\n",
    "        return f1, class_scores\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08daaba4",
   "metadata": {},
   "source": [
    "## CV Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b7878e30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T03:20:29.092783Z",
     "start_time": "2022-03-04T03:20:29.055729Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../data_file/id_to_ix_map.pickle', 'rb') as f:\n",
    "    id_to_ix_map = {x.split('/')[-1].split('.')[0]: y for x, y in pickle.load(f).items()}\n",
    "with open('../data_file/data_splits.pickle', 'rb') as f:\n",
    "    data_splits = pickle.load(f)\n",
    "\n",
    "val_files_all = []\n",
    "val_ids_all = []\n",
    "\n",
    "seed = 0\n",
    "for val_fold in range(5):\n",
    "    val_files = data_splits[seed][250]['normed'][val_fold]\n",
    "    val_ids = [id_to_ix_map[x] for x in val_files]\n",
    "    \n",
    "    val_files_all.append(val_files)\n",
    "    val_ids_all.append(val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3c63b3e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T04:29:28.714507Z",
     "start_time": "2022-03-04T04:29:28.710675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3140"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "d81b2921",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T08:03:04.566552Z",
     "start_time": "2022-03-05T08:00:11.122579Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_names = [\n",
    "    \"None\",\n",
    "    \"Lead\",\n",
    "    \"Position\",\n",
    "    \"Evidence\",\n",
    "    \"Claim\",\n",
    "    \"Concluding Statement\",\n",
    "    \"Counterclaim\",\n",
    "    \"Rebuttal\",\n",
    "]\n",
    "\n",
    "outs_f = []\n",
    "bounds_f = []\n",
    "token_nums_f = []\n",
    "word_indices_f = []\n",
    "sample_ids_f = []\n",
    "\n",
    "cv_n = 1\n",
    "checkpoints = [f\"../result/debertav3_fold0_f10.7006.pth\" for i in range(cv_n)]\n",
    "\n",
    "\n",
    "for val_fold in range(cv_n):\n",
    "    val_files = val_files_all[val_fold]\n",
    "    dataset = ValDataset(val_files)\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset, collate_fn=collate_fn, batch_size=1, num_workers=2, shuffle=False\n",
    "    )\n",
    "\n",
    "    model.eval().cuda()\n",
    "\n",
    "    all_outs = np.zeros((len(val_files), 2048, 15), \"f4\")\n",
    "    all_bounds = np.zeros((len(val_files), 2048, 2), \"i4\")\n",
    "    all_token_nums = np.zeros(len(val_files), \"i4\")\n",
    "    all_word_indices = []\n",
    "    all_sample_ids = []\n",
    "\n",
    "    model.load_state_dict(torch.load(checkpoints[val_fold]))\n",
    "    ix = 0\n",
    "    for batch in tqdm(dataloader, leave=False):\n",
    "        tokens, mask, bounds, word_indices, sample_ids, num_tokens = batch\n",
    "        batch_size, batch_len = tokens.shape[:2]\n",
    "        outs = torch.softmax(model(tokens.cuda(), mask.cuda()), -1)\n",
    "\n",
    "        all_outs[ix : ix + batch_size, :batch_len] += outs.cpu().numpy()\n",
    "        all_bounds[ix : ix + batch_size, :batch_len] = bounds\n",
    "        all_token_nums[ix : ix + batch_size] = num_tokens\n",
    "        all_word_indices.extend(word_indices)\n",
    "        all_sample_ids.extend(sample_ids)\n",
    "\n",
    "        ix += batch_size\n",
    "\n",
    "    outs_f.append(all_outs)\n",
    "    bounds_f.append(all_bounds)\n",
    "    token_nums_f.append(all_token_nums)\n",
    "    word_indices_f += all_word_indices\n",
    "    sample_ids_f += all_sample_ids\n",
    "\n",
    "all_outs = np.concatenate(outs_f)\n",
    "all_bounds = np.concatenate(bounds_f)\n",
    "all_token_nums = np.concatenate(token_nums_f)\n",
    "all_word_indices = word_indices_f\n",
    "all_sample_ids = sample_ids_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c68beaf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T08:03:16.796021Z",
     "start_time": "2022-03-05T08:03:16.744923Z"
    }
   },
   "outputs": [],
   "source": [
    "all_texts = {}\n",
    "for sample_id in all_sample_ids:\n",
    "    file_name = os.path.join(DATASET_PATH, \"train\", sample_id + \".txt\")\n",
    "    with open(file_name) as f:\n",
    "        all_texts[sample_id] = f.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "c3d69a86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T08:03:17.385976Z",
     "start_time": "2022-03-05T08:03:17.222201Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([538., 781., 756., 507., 269., 152.,  68.,  51.,  13.,   5.]),\n",
       " array([ 159. ,  287.7,  416.4,  545.1,  673.8,  802.5,  931.2, 1059.9,\n",
       "        1188.6, 1317.3, 1446. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(all_token_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "dd293661",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T08:03:20.605102Z",
     "start_time": "2022-03-05T08:03:20.602170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3140, 2048, 15)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_outs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "dcbbe1b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T11:48:30.864886Z",
     "start_time": "2022-03-05T11:48:30.861184Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 8, 4, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "       8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "       8, 8, 8, 8, 0, 7, 8, 8, 8, 8, 8, 8])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_outs[0].argmax(-1)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "3a6b9c58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T11:49:18.345339Z",
     "start_time": "2022-03-05T11:49:18.342595Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "642"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_token_nums[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "a208eb99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T12:02:54.611978Z",
     "start_time": "2022-03-05T12:02:54.606924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(1, []), (2, []), (4, []), (3, []), (6, []), (7, []), (5, [(557, 640)])])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_ps(\n",
    "            extract_entities(all_outs[sample_ix], all_token_nums[sample_ix]),\n",
    "            all_outs[sample_ix],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "fe5a907f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T12:05:14.826679Z",
     "start_time": "2022-03-05T12:05:11.058750Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub_sample_ids = []\n",
    "sub_cat_names = []\n",
    "sub_spans = []\n",
    "sub_scores = []\n",
    "\n",
    "for sample_ix in tqdm(range(len(all_token_nums)), leave=False):\n",
    "    predicted_spans = {\n",
    "        x: {\n",
    "            \"entity\": [\n",
    "                map_span_to_word_indices(\n",
    "                    span, all_word_indices[sample_ix], all_bounds[sample_ix]\n",
    "                )\n",
    "                for span in y\n",
    "            ],\n",
    "            \"scores\": [calc_entity_score(span, all_outs[sample_ix], x) for span in y],\n",
    "        }\n",
    "        for x, y in filter_ps(\n",
    "            extract_entities(all_outs[sample_ix], all_token_nums[sample_ix]),\n",
    "            all_outs[sample_ix],\n",
    "        )\n",
    "    }\n",
    "    for cat_ix in predicted_spans:\n",
    "        for entity in predicted_spans[cat_ix][\"entity\"]:\n",
    "            sub_sample_ids.append(all_sample_ids[sample_ix])\n",
    "            sub_cat_names.append(label_names[cat_ix])\n",
    "            sub_spans.append(\" \".join(str(x) for x in range(entity[0], entity[1] + 1)))\n",
    "\n",
    "        for scores in predicted_spans[cat_ix][\"scores\"]:\n",
    "            sub_scores.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "cb14370d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T12:05:22.476477Z",
     "start_time": "2022-03-05T12:05:22.463521Z"
    }
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(\n",
    "    {\n",
    "        \"id\": sub_sample_ids,\n",
    "        \"class\": sub_cat_names,\n",
    "        \"predictionstring\": sub_spans,\n",
    "        \"scores\": sub_scores,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "e4793a2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T12:05:22.905157Z",
     "start_time": "2022-03-05T12:05:22.893099Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4BB5ADD5A1FE</td>\n",
       "      <td>Lead</td>\n",
       "      <td>3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20...</td>\n",
       "      <td>0.908804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4BB5ADD5A1FE</td>\n",
       "      <td>Position</td>\n",
       "      <td>22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 3...</td>\n",
       "      <td>0.921207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4BB5ADD5A1FE</td>\n",
       "      <td>Claim</td>\n",
       "      <td>40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 5...</td>\n",
       "      <td>0.395155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4BB5ADD5A1FE</td>\n",
       "      <td>Claim</td>\n",
       "      <td>58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73</td>\n",
       "      <td>0.839744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4BB5ADD5A1FE</td>\n",
       "      <td>Claim</td>\n",
       "      <td>74 75 76 77 78 79 80 81 82 83 84</td>\n",
       "      <td>0.895257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29619</th>\n",
       "      <td>D753B3C6BDDA</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>18 19 20 21 22 23 24 25 26 27</td>\n",
       "      <td>0.464281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29620</th>\n",
       "      <td>D753B3C6BDDA</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>101 102 103 104 105 106 107 108 109 110 111 11...</td>\n",
       "      <td>0.763377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29621</th>\n",
       "      <td>D753B3C6BDDA</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>140 141 142 143 144 145 146 147 148 149 150 15...</td>\n",
       "      <td>0.726966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29622</th>\n",
       "      <td>D753B3C6BDDA</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>433 434 435 436 437 438 439 440 441 442 443 44...</td>\n",
       "      <td>0.882594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29623</th>\n",
       "      <td>D753B3C6BDDA</td>\n",
       "      <td>Claim</td>\n",
       "      <td>28 29 30 31 32 33 34 35 36 37 38 39 40 41</td>\n",
       "      <td>0.468140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29624 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     class  \\\n",
       "0      4BB5ADD5A1FE      Lead   \n",
       "1      4BB5ADD5A1FE  Position   \n",
       "2      4BB5ADD5A1FE     Claim   \n",
       "3      4BB5ADD5A1FE     Claim   \n",
       "4      4BB5ADD5A1FE     Claim   \n",
       "...             ...       ...   \n",
       "29619  D753B3C6BDDA  Evidence   \n",
       "29620  D753B3C6BDDA  Evidence   \n",
       "29621  D753B3C6BDDA  Evidence   \n",
       "29622  D753B3C6BDDA  Evidence   \n",
       "29623  D753B3C6BDDA     Claim   \n",
       "\n",
       "                                        predictionstring    scores  \n",
       "0      3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20...  0.908804  \n",
       "1      22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 3...  0.921207  \n",
       "2      40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 5...  0.395155  \n",
       "3        58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73  0.839744  \n",
       "4                       74 75 76 77 78 79 80 81 82 83 84  0.895257  \n",
       "...                                                  ...       ...  \n",
       "29619                      18 19 20 21 22 23 24 25 26 27  0.464281  \n",
       "29620  101 102 103 104 105 106 107 108 109 110 111 11...  0.763377  \n",
       "29621  140 141 142 143 144 145 146 147 148 149 150 15...  0.726966  \n",
       "29622  433 434 435 436 437 438 439 440 441 442 443 44...  0.882594  \n",
       "29623          28 29 30 31 32 33 34 35 36 37 38 39 40 41  0.468140  \n",
       "\n",
       "[29624 rows x 4 columns]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "8cd0a31d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T12:05:27.276156Z",
     "start_time": "2022-03-05T12:05:27.249217Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48D3F4243F0F</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48D3F4243F0F</td>\n",
       "      <td>Position</td>\n",
       "      <td>120 121 122 123 124 125 126 127 128 129 130 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48D3F4243F0F</td>\n",
       "      <td>Claim</td>\n",
       "      <td>154 155 156 157 158 159 160 161 162 163 164 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48D3F4243F0F</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>174 175 176 177 178 179 180 181 182 183 184 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48D3F4243F0F</td>\n",
       "      <td>Claim</td>\n",
       "      <td>211 212 213 214 215 216 217 218 219 220 221 22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29059</th>\n",
       "      <td>0814426B27DF</td>\n",
       "      <td>Claim</td>\n",
       "      <td>290 291 292 293 294 295 296 297 298 299 300 30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29060</th>\n",
       "      <td>0814426B27DF</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>315 316 317 318 319 320 321 322 323 324 325 32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29061</th>\n",
       "      <td>0814426B27DF</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>391 392 393 394 395 396 397 398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29062</th>\n",
       "      <td>0814426B27DF</td>\n",
       "      <td>Rebuttal</td>\n",
       "      <td>399 400 401 402 403 404 405 406 407 408 409 41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29063</th>\n",
       "      <td>0814426B27DF</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>413 414 415 416 417 418 419 420 421 422 423 42...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29064 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id        discourse_type  \\\n",
       "0      48D3F4243F0F                  Lead   \n",
       "1      48D3F4243F0F              Position   \n",
       "2      48D3F4243F0F                 Claim   \n",
       "3      48D3F4243F0F              Evidence   \n",
       "4      48D3F4243F0F                 Claim   \n",
       "...             ...                   ...   \n",
       "29059  0814426B27DF                 Claim   \n",
       "29060  0814426B27DF              Evidence   \n",
       "29061  0814426B27DF          Counterclaim   \n",
       "29062  0814426B27DF              Rebuttal   \n",
       "29063  0814426B27DF  Concluding Statement   \n",
       "\n",
       "                                        predictionstring  \n",
       "0      0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...  \n",
       "1      120 121 122 123 124 125 126 127 128 129 130 13...  \n",
       "2      154 155 156 157 158 159 160 161 162 163 164 16...  \n",
       "3      174 175 176 177 178 179 180 181 182 183 184 18...  \n",
       "4      211 212 213 214 215 216 217 218 219 220 221 22...  \n",
       "...                                                  ...  \n",
       "29059  290 291 292 293 294 295 296 297 298 299 300 30...  \n",
       "29060  315 316 317 318 319 320 321 322 323 324 325 32...  \n",
       "29061                    391 392 393 394 395 396 397 398  \n",
       "29062  399 400 401 402 403 404 405 406 407 408 409 41...  \n",
       "29063  413 414 415 416 417 418 419 420 421 422 423 42...  \n",
       "\n",
       "[29064 rows x 3 columns]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_fold_df = val_df.query('id in @sub.id.unique()').reset_index(drop=True)\n",
    "val_fold_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "75cc5df4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T12:05:36.471359Z",
     "start_time": "2022-03-05T12:05:36.465383Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29064, 3)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_fold_df = val_fold_df[[\"id\", \"discourse_type\", \"predictionstring\"]].reset_index(drop=True)\n",
    "val_fold_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "d0f85bd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T12:05:39.440784Z",
     "start_time": "2022-03-05T12:05:38.307404Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7009666655212109, {'Lead': 0.841688654353562, 'Position': 0.7271544715447155, 'Claim': 0.6623762858953732, 'Evidence': 0.7555579596473198, 'Counterclaim': 0.5732952225398121, 'Concluding Statement': 0.8640494365685205, 'Rebuttal': 0.4826446280991736})\n"
     ]
    }
   ],
   "source": [
    "print(score_feedback_comp2(sub, val_fold_df, return_class_scores=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8606bc9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T04:26:25.654452Z",
     "start_time": "2022-03-04T04:26:03.314350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.08154630947334403, {'Lead': 0.08428175945862812, 'Position': 0.0, 'Evidence': 0.0, 'Claim': 0.0, 'Concluding Statement': 0.2920446830833796, 'Counterclaim': 0.050974512743628186, 'Rebuttal': 0.14352321102777216})\n"
     ]
    }
   ],
   "source": [
    "sub = pd.DataFrame(\n",
    "    {\n",
    "        \"id\": sub_sample_ids,\n",
    "        \"class\": sub_cat_names,\n",
    "        \"predictionstring\": sub_spans,\n",
    "        \"scores\": sub_scores,\n",
    "    }\n",
    ")\n",
    "\n",
    "df = pd.read_csv(osp.join(DATASET_PATH, \"train.csv\"))\n",
    "\n",
    "val_df = df[[\"id\", \"discourse_type\", \"predictionstring\"]].reset_index(drop=True)\n",
    "val_df.shape\n",
    "\n",
    "print(score_feedback_comp2(sub, val_df, return_class_scores=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e5bfea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T06:53:18.956457Z",
     "start_time": "2022-03-04T06:53:18.954173Z"
    }
   },
   "outputs": [],
   "source": [
    "STOP!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec8fb03",
   "metadata": {},
   "source": [
    "## Understanding the process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fca0445",
   "metadata": {},
   "source": [
    "## Extract Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b70fbae4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T06:21:17.747728Z",
     "start_time": "2022-03-04T06:21:17.745763Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_ix = 241\n",
    "out, token_n = all_outs[sample_ix], all_token_nums[sample_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c05d76d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T07:33:02.035049Z",
     "start_time": "2022-03-05T07:33:02.033273Z"
    }
   },
   "outputs": [],
   "source": [
    "index_map, bounds = all_word_indices[sample_ix], all_bounds[sample_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "368f98b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T06:21:36.693931Z",
     "start_time": "2022-03-04T06:21:36.690551Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2048, 15), 437)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape, token_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "07119454",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T07:33:05.286459Z",
     "start_time": "2022-03-05T07:33:05.283424Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 2],\n",
       "       [2, 7],\n",
       "       ...,\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f15a1a41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T06:20:29.753595Z",
     "start_time": "2022-03-05T06:20:29.747578Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def extract_entities(preds, token_n):\n",
    "    class_preds = preds.argmax(-1)\n",
    "    all_entities = {}\n",
    "    current_class = None\n",
    "    current_start = None\n",
    "    for ix in range(1, token_n - 1):\n",
    "#         print('pred cat', class_preds[ix], 'current cat', current_class)\n",
    "        if class_preds[ix] % 2 == 1:\n",
    "            if current_class is not None:\n",
    "                if current_class not in all_entities:\n",
    "                    all_entities[current_class] = []\n",
    "#                 print(f'added class {current_class}!')\n",
    "                all_entities[current_class].append((current_start, ix - 1))\n",
    "            current_class = (class_preds[ix] + 1) // 2\n",
    "            current_start = ix        \n",
    "        \n",
    "    if current_class is not None:\n",
    "        if current_class not in all_entities:\n",
    "            all_entities[current_class] = []\n",
    "        all_entities[current_class].append((current_start, ix))\n",
    "    \n",
    "    return all_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2280a464",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T07:12:29.217660Z",
     "start_time": "2022-03-05T07:12:29.212396Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [(1, 24)],\n",
       " 2: [(25, 33)],\n",
       " 4: [(34, 116), (117, 131), (223, 231), (314, 326)],\n",
       " 3: [(132, 142), (143, 222), (232, 313), (327, 386)],\n",
       " 5: [(387, 435)]}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_out = extract_entities(out, token_n)\n",
    "extract_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e0b2e6",
   "metadata": {},
   "source": [
    "### map span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a11c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_span_to_word_indices(span, index_map, bounds):\n",
    "    return (index_map[bounds[span[0], 0]], index_map[bounds[span[1], 1] - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "759c325c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T07:35:34.320441Z",
     "start_time": "2022-03-05T07:35:34.318221Z"
    }
   },
   "outputs": [],
   "source": [
    "span = (1, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "39da9533",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T07:37:16.945242Z",
     "start_time": "2022-03-05T07:37:16.942159Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 103)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first token's start index\n",
    "# last tokens's end index\n",
    "bounds[span[0], 0], bounds[span[1], 1] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ba56eaf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T07:38:53.458113Z",
     "start_time": "2022-03-05T07:38:53.454260Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 19)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the word index\n",
    "index_map[bounds[span[0], 0]], index_map[bounds[span[1], 1] - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "04d8caf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T07:33:08.947493Z",
     "start_time": "2022-03-05T07:33:08.945311Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted_spans = {x: [map_span_to_word_indices(span, index_map, bounds) for span in y]\n",
    "                   for x, y in extract_out.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ff869526",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T07:33:11.342062Z",
     "start_time": "2022-03-05T07:33:11.339083Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [(0, 19)],\n",
       " 2: [(19, 26)],\n",
       " 4: [(26, 97), (98, 107), (187, 192), (265, 277)],\n",
       " 3: [(107, 117), (117, 186), (192, 264), (277, 328)],\n",
       " 5: [(329, 375)]}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_spans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abdd31f",
   "metadata": {},
   "source": [
    "### function split_predstrig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "89bec96f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T06:37:15.306403Z",
     "start_time": "2022-03-04T06:37:15.303593Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_predstring(predstring):\n",
    "    vals = predstring.split()\n",
    "    return int(vals[0]), int(vals[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6218f56a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T06:37:40.117914Z",
     "start_time": "2022-03-04T06:37:40.114215Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 44)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_predstring(val_df.predictionstring[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
