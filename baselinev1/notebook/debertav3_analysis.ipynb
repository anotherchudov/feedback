{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43a33054",
   "metadata": {},
   "source": [
    "# DebertaV3 Analysis Report\n",
    "\n",
    "- [Huggingface DebertaV2model code](https://github.com/anotherchudov/feedback/blob/sergei/models_training/longformer/sumbission/codes/new_transformers_branch/transformers/src/transformers/models/deberta_v2/modeling_deberta_v2.py#L994) \n",
    "\n",
    "- Is it ok to use max_relative_position?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d23838",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "class DebertaV2Model(DebertaV2PreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.embeddings = DebertaV2Embeddings(config)\n",
    "        self.encoder = DebertaV2Encoder(config)\n",
    "        \n",
    "    def forward():\n",
    "        embedding_output = self.embeddings(\n",
    "            input_ids=input_ids,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            mask=attention_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "        )\n",
    "\n",
    "        encoder_outputs = self.encoder(\n",
    "            embedding_output,\n",
    "            attention_mask,\n",
    "            output_hidden_states=True,\n",
    "            output_attentions=output_attentions,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4af3d737",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T09:04:36.988686Z",
     "start_time": "2022-03-02T09:04:36.986180Z"
    }
   },
   "outputs": [],
   "source": [
    "import easydict\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab8c934",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a6360ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T08:52:20.896951Z",
     "start_time": "2022-03-02T08:52:20.892955Z"
    }
   },
   "outputs": [],
   "source": [
    "deberta_config = {\n",
    "    \"model_type\": \"deberta-v2\",\n",
    "    \"attention_probs_dropout_prob\": 0.1,\n",
    "    \"hidden_act\": \"gelu\",\n",
    "    \"hidden_dropout_prob\": 0.1,\n",
    "    \"hidden_size\": 1024,\n",
    "    \"initializer_range\": 0.02,\n",
    "    \"intermediate_size\": 4096,\n",
    "    \"max_position_embeddings\": 512,\n",
    "    \"relative_attention\": True,\n",
    "    \"position_buckets\": 256,\n",
    "    \"norm_rel_ebd\": \"layer_norm\",\n",
    "    \"share_att_key\": True,\n",
    "    \"pos_att_type\": \"p2c|c2p\",\n",
    "    \"layer_norm_eps\": 1e-7,\n",
    "    \"max_relative_positions\": -1,\n",
    "    \"position_biased_input\": False,\n",
    "    \"num_attention_heads\": 16,\n",
    "    \"num_hidden_layers\": 24,\n",
    "    \"type_vocab_size\": 0,\n",
    "    \"vocab_size\": 128100,\n",
    "}\n",
    "\n",
    "config = easydict.EasyDict(deberta_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2335dfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T08:44:02.352284Z",
     "start_time": "2022-03-02T08:44:02.350382Z"
    }
   },
   "source": [
    "## self.embeddings `position_ids` is ok?\n",
    "\n",
    "> the model `position_ids` is set to [0, 1, ..., 510, 511]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc32b8d5",
   "metadata": {},
   "source": [
    "when we use relative position embedding we don't use absolute position embedding so `position_biased_input` option is turned off. totally fine. This won't be applied why training.\n",
    "\n",
    "```python\n",
    "if self.position_biased_input:\n",
    "      embeddings += position_embeddings\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a6e473",
   "metadata": {},
   "source": [
    "## Max Relative Position\n",
    "\n",
    "> embedding is done by which bucket does token is part of, not by each token position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "820af21a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T08:54:46.901250Z",
     "start_time": "2022-03-02T08:54:46.889891Z"
    }
   },
   "outputs": [],
   "source": [
    "class BertEncoder(nn.Module):\n",
    "    \"\"\"Modified BertEncoder with relative position bias support\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "        # initialize model layers\n",
    "#         self.layer = nn.ModuleList(\n",
    "#             [BertLayer(config) for _ in range(config.num_hidden_layers)]\n",
    "#         )\n",
    "        \n",
    "        self.relative_attention = getattr(config, \"relative_attention\", False)\n",
    "        if self.relative_attention:\n",
    "            self.max_relative_positions = getattr(config, \"max_relative_positions\", -1)\n",
    "\n",
    "            if self.max_relative_positions < 1:\n",
    "                self.max_relative_positions = config.max_position_embeddings\n",
    "                self.position_buckets = getattr(config, \"position_buckets\", -1)\n",
    "                pos_ebd_size = self.max_relative_positions * 2\n",
    "\n",
    "                if self.position_buckets > 0:\n",
    "                    pos_ebd_size = self.position_buckets * 2\n",
    "\n",
    "            self.rel_embeddings = nn.Embedding(pos_ebd_size, config.hidden_size)\n",
    "\n",
    "#         self.norm_rel_ebd = [\n",
    "#             x.strip()\n",
    "#             for x in getattr(config, \"norm_rel_ebd\", \"none\").lower().split(\"|\")\n",
    "#         ]\n",
    "#         if \"layer_norm\" in self.norm_rel_ebd:\n",
    "#             self.LayerNorm = LayerNorm(\n",
    "#                 config.hidden_size, config.layer_norm_eps, elementwise_affine=True\n",
    "#             )\n",
    "\n",
    "#         kernel_size = getattr(config, \"conv_kernel_size\", 0)\n",
    "#         self.with_conv = False\n",
    "#         if kernel_size > 0:\n",
    "#             self.with_conv = True\n",
    "#             self.conv = ConvLayer(config)\n",
    "\n",
    "    def get_rel_embedding(self):\n",
    "        rel_embeddings = self.rel_embeddings.weight if self.relative_attention else None\n",
    "        if rel_embeddings is not None and (\"layer_norm\" in self.norm_rel_ebd):\n",
    "            rel_embeddings = self.LayerNorm(rel_embeddings)\n",
    "        return rel_embeddings\n",
    "\n",
    "    def get_attention_mask(self, attention_mask):\n",
    "        if attention_mask.dim() <= 2:\n",
    "            extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "            attention_mask = extended_attention_mask * extended_attention_mask.squeeze(\n",
    "                -2\n",
    "            ).unsqueeze(-1)\n",
    "            attention_mask = attention_mask.byte()\n",
    "        elif attention_mask.dim() == 3:\n",
    "            attention_mask = attention_mask.unsqueeze(1)\n",
    "\n",
    "        return attention_mask\n",
    "\n",
    "    def get_rel_pos(self, hidden_states, query_states=None, relative_pos=None):\n",
    "        if self.relative_attention and relative_pos is None:\n",
    "            q = (\n",
    "                query_states.size(-2)\n",
    "                if query_states is not None\n",
    "                else hidden_states.size(-2)\n",
    "            )\n",
    "            relative_pos = build_relative_position(\n",
    "                q,\n",
    "                hidden_states.size(-2),\n",
    "                bucket_size=self.position_buckets,\n",
    "                max_position=self.max_relative_positions,\n",
    "            )\n",
    "        return relative_pos\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states,\n",
    "        attention_mask,\n",
    "        output_all_encoded_layers=True,\n",
    "        return_att=False,\n",
    "        query_states=None,\n",
    "        relative_pos=None,\n",
    "    ):\n",
    "        if attention_mask.dim() <= 2:\n",
    "            input_mask = attention_mask\n",
    "        else:\n",
    "            input_mask = (attention_mask.sum(-2) > 0).byte()\n",
    "        attention_mask = self.get_attention_mask(attention_mask)\n",
    "        relative_pos = self.get_rel_pos(hidden_states, query_states, relative_pos)\n",
    "\n",
    "        all_encoder_layers = []\n",
    "        att_matrices = []\n",
    "        if isinstance(hidden_states, Sequence):\n",
    "            next_kv = hidden_states[0]\n",
    "        else:\n",
    "            next_kv = hidden_states\n",
    "        rel_embeddings = self.get_rel_embedding()\n",
    "        for i, layer_module in enumerate(self.layer):\n",
    "            output_states = layer_module(\n",
    "                next_kv,\n",
    "                attention_mask,\n",
    "                return_att,\n",
    "                query_states=query_states,\n",
    "                relative_pos=relative_pos,\n",
    "                rel_embeddings=rel_embeddings,\n",
    "            )\n",
    "            if return_att:\n",
    "                output_states, att_m = output_states\n",
    "\n",
    "            if i == 0 and self.with_conv:\n",
    "                prenorm = output_states  # output['prenorm_states']\n",
    "                output_states = self.conv(hidden_states, prenorm, input_mask)\n",
    "\n",
    "            if query_states is not None:\n",
    "                query_states = output_states\n",
    "                if isinstance(hidden_states, Sequence):\n",
    "                    next_kv = hidden_states[i + 1] if i + 1 < len(self.layer) else None\n",
    "            else:\n",
    "                next_kv = output_states\n",
    "\n",
    "            if output_all_encoded_layers:\n",
    "                all_encoder_layers.append(output_states)\n",
    "                if return_att:\n",
    "                    att_matrices.append(att_m)\n",
    "        if not output_all_encoded_layers:\n",
    "            all_encoder_layers.append(output_states)\n",
    "            if return_att:\n",
    "                att_matrices.append(att_m)\n",
    "        return {\"hidden_states\": all_encoder_layers, \"attention_matrices\": att_matrices}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "231948e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T11:31:25.449760Z",
     "start_time": "2022-03-02T11:31:25.440282Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertEncoder(\n",
       "  (rel_embeddings): Embedding(512, 1024)\n",
       ")"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert = BertEncoder(config)\n",
    "bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f0a9a19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T09:14:11.344529Z",
     "start_time": "2022-03-02T09:14:11.341314Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_log_bucket_position(relative_pos, bucket_size, max_position):\n",
    "    sign = np.sign(relative_pos)\n",
    "    mid = bucket_size // 2\n",
    "    \n",
    "    abs_pos = np.where((relative_pos < mid) & (relative_pos > -mid), mid - 1, np.abs(relative_pos))\n",
    "    log_pos = np.ceil(np.log(abs_pos / mid) / np.log((max_position - 1) / mid) * (mid - 1)) + mid\n",
    "    bucket_pos = np.where(abs_pos <= mid, relative_pos, log_pos * sign).astype(np.int)\n",
    "    \n",
    "    return bucket_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "968f55ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T09:26:49.973292Z",
     "start_time": "2022-03-02T09:26:49.967478Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_relative_position(query_size, key_size, bucket_size=-1, max_position=-1):\n",
    "    \"\"\"\n",
    "    Build relative position according to the query and key\n",
    "    - we assume the absolute position of query [ P query ] is range from (0, query_size)\n",
    "    - and the absolute position of key [ P key ] is range from (0, key_size)\n",
    "    \n",
    "    The relative positions from query to key is [ R query -> key ] = P query - P key\n",
    "\n",
    "    Args:\n",
    "        query_size (int): the length of query\n",
    "        key_size (int): the length of key\n",
    "        bucket_size (int): the size of position bucket\n",
    "        max_position (int): the maximum allowed absolute position\n",
    "    Return:\n",
    "        `torch.LongTensor`: A tensor with shape [1, query_size, key_size]\n",
    "    \"\"\"\n",
    "    q_ids = np.arange(0, query_size)\n",
    "    k_ids = np.arange(0, key_size)\n",
    "    rel_pos_ids = q_ids[:, None] - np.tile(k_ids, (q_ids.shape[0], 1))\n",
    "    \n",
    "    print('relative positional ids')\n",
    "    print(rel_pos_ids)\n",
    "    if bucket_size > 0 and max_position > 0:\n",
    "        rel_pos_ids = make_log_bucket_position(rel_pos_ids, bucket_size, max_position)\n",
    "\n",
    "    rel_pos_ids = torch.tensor(rel_pos_ids, dtype=torch.long)\n",
    "    rel_pos_ids = rel_pos_ids[:query_size, :]\n",
    "    rel_pos_ids = rel_pos_ids.unsqueeze(0)\n",
    "\n",
    "    return rel_pos_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b54ff19a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T09:26:50.153544Z",
     "start_time": "2022-03-02T09:26:50.151130Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 512)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.position_buckets, config.max_position_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcf7b16",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### bucket with 512 max relative position & 512 input length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "37dd25ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T09:26:50.890957Z",
     "start_time": "2022-03-02T09:26:50.882998Z"
    },
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative positional ids\n",
      "[[   0   -1   -2 ... -509 -510 -511]\n",
      " [   1    0   -1 ... -508 -509 -510]\n",
      " [   2    1    0 ... -507 -508 -509]\n",
      " ...\n",
      " [ 509  508  507 ...    0   -1   -2]\n",
      " [ 510  509  508 ...    1    0   -1]\n",
      " [ 511  510  509 ...    2    1    0]]\n"
     ]
    }
   ],
   "source": [
    "bucket_pos = build_relative_position(\n",
    "    query_size=512,\n",
    "    key_size=512,\n",
    "    bucket_size=config.position_buckets,\n",
    "    max_position=config.max_position_embeddings,  # alternative for max_relative_embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3d624fcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T09:26:53.812481Z",
     "start_time": "2022-03-02T09:26:53.809897Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pretrained_bucket_values = bucket_pos[:, 0, :][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f81e39e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T09:26:57.487009Z",
     "start_time": "2022-03-02T09:26:57.391494Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# code from https://stackoverflow.com/questions/48026056/visualize-matplotlib-histogram-bin-counts-directly-on-the-graph\n",
    "\n",
    "import matplotlib.pyplot as plt              \n",
    "import numpy as np                                       \n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "counts, bins, patches = plt.hist(pretrained_bucket_values)\n",
    "plt.ylabel('Probability')\n",
    "\n",
    "\n",
    "# Label the raw counts and the percentages below the x-axis...\n",
    "bin_centers = 0.5 * np.diff(bins) + bins[:-1]\n",
    "for count, x in zip(counts, bin_centers):\n",
    "    # Label the raw counts\n",
    "    plt.annotate('{:.2f}'.format(count), xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "        xytext=(0, 18), textcoords='offset points', va='top', ha='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "432fa70b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T09:26:59.778324Z",
     "start_time": "2022-03-02T09:26:59.775683Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-236, -236, -236, -236, -237, -237, -237, -237, -238, -238, -238,\n",
       "       -238, -238, -239, -239, -239, -239, -239, -240, -240, -240, -240,\n",
       "       -241, -241, -241, -241, -241, -242, -242, -242, -242, -242, -243,\n",
       "       -243, -243, -243, -243, -244, -244, -244, -244, -244, -245, -245,\n",
       "       -245, -245, -245, -246, -246, -246, -246, -246, -247, -247, -247,\n",
       "       -247, -247, -248, -248, -248, -248, -248, -249, -249, -249, -249,\n",
       "       -249, -250, -250, -250, -250, -250, -251, -251, -251, -251, -251,\n",
       "       -251, -252, -252, -252, -252, -252, -253, -253, -253, -253, -253,\n",
       "       -254, -254, -254, -254, -254, -254, -255, -255, -255, -255, -255,\n",
       "       -255])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_bucket_values[-100:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b30bd5",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### bucket with 512 max relative position & 2048 input length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4141cd45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T12:47:29.689873Z",
     "start_time": "2022-03-02T12:47:29.585455Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative positional ids\n",
      "[[    0    -1    -2 ... -2045 -2046 -2047]\n",
      " [    1     0    -1 ... -2044 -2045 -2046]\n",
      " [    2     1     0 ... -2043 -2044 -2045]\n",
      " ...\n",
      " [ 2045  2044  2043 ...     0    -1    -2]\n",
      " [ 2046  2045  2044 ...     1     0    -1]\n",
      " [ 2047  2046  2045 ...     2     1     0]]\n"
     ]
    }
   ],
   "source": [
    "bucket_pos = build_relative_position(\n",
    "    query_size=2048,\n",
    "    key_size=2048,\n",
    "    bucket_size=config.position_buckets,\n",
    "    max_position=config.max_position_embeddings,  # alternative for max_relative_embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a141cc2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T12:47:34.809357Z",
     "start_time": "2022-03-02T12:47:34.805123Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[   0,   -1,   -2,  ..., -383, -383, -383],\n",
       "         [   1,    0,   -1,  ..., -383, -383, -383],\n",
       "         [   2,    1,    0,  ..., -383, -383, -383],\n",
       "         ...,\n",
       "         [ 383,  383,  383,  ...,    0,   -1,   -2],\n",
       "         [ 383,  383,  383,  ...,    1,    0,   -1],\n",
       "         [ 383,  383,  383,  ...,    2,    1,    0]]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "10a2855f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T09:27:07.890863Z",
     "start_time": "2022-03-02T09:27:07.888342Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "finetuned_bucket_values = bucket_pos[:, 0, :][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e89427cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T09:27:11.296401Z",
     "start_time": "2022-03-02T09:27:11.188327Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# code from https://stackoverflow.com/questions/48026056/visualize-matplotlib-histogram-bin-counts-directly-on-the-graph\n",
    "\n",
    "import matplotlib.pyplot as plt              \n",
    "import numpy as np                                       \n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "counts, bins, patches = plt.hist(finetuned_bucket_values)\n",
    "plt.ylabel('Probability')\n",
    "\n",
    "\n",
    "# Label the raw counts and the percentages below the x-axis...\n",
    "bin_centers = 0.5 * np.diff(bins) + bins[:-1]\n",
    "for count, x in zip(counts, bin_centers):\n",
    "    # Label the raw counts\n",
    "    plt.annotate('{:.2f}'.format(count), xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "        xytext=(0, 18), textcoords='offset points', va='top', ha='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "95603be5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T09:27:18.700268Z",
     "start_time": "2022-03-02T09:27:18.696389Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,  -1,  -2,  -3,  -4,  -5,  -6,  -7,  -8,  -9, -10, -11, -12,\n",
       "       -13, -14, -15, -16, -17, -18, -19, -20, -21, -22, -23, -24, -25,\n",
       "       -26, -27, -28, -29, -30, -31, -32, -33, -34, -35, -36, -37, -38,\n",
       "       -39, -40, -41, -42, -43, -44, -45, -46, -47, -48, -49, -50, -51,\n",
       "       -52, -53, -54, -55, -56, -57, -58, -59, -60, -61, -62, -63, -64,\n",
       "       -65, -66, -67, -68, -69, -70, -71, -72, -73, -74, -75, -76, -77,\n",
       "       -78, -79, -80, -81, -82, -83, -84, -85, -86, -87, -88, -89, -90,\n",
       "       -91, -92, -93, -94, -95, -96, -97, -98, -99])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_bucket_values[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f3a9efe8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T09:27:19.022970Z",
     "start_time": "2022-03-02T09:27:19.020420Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-100, -101, -102, -103, -104, -105, -106, -107, -108, -109, -110,\n",
       "       -111, -112, -113, -114, -115, -116, -117, -118, -119, -120, -121,\n",
       "       -122, -123, -124, -125, -126, -127, -128, -129, -130, -131, -131,\n",
       "       -132, -133, -133, -134, -135, -135, -136, -137, -137, -138, -139,\n",
       "       -139, -140, -141, -141, -142, -142, -143, -144, -144, -145, -145,\n",
       "       -146, -147, -147, -148, -148, -149, -150, -150, -151, -151, -152,\n",
       "       -152, -153, -153, -154, -155, -155, -156, -156, -157, -157, -158,\n",
       "       -158, -159, -159, -160, -160, -161, -161, -162, -162, -163, -163,\n",
       "       -164, -164, -165, -165, -166, -166, -167, -167, -168, -168, -169,\n",
       "       -169])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_bucket_values[100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "89fd0170",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T09:27:19.900894Z",
     "start_time": "2022-03-02T09:27:19.897305Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-169, -170, -170, -171, -171, -172, -172, -173, -173, -173, -174,\n",
       "       -174, -175, -175, -176, -176, -177, -177, -177, -178, -178, -179,\n",
       "       -179, -179, -180, -180, -181, -181, -181, -182, -182, -183, -183,\n",
       "       -183, -184, -184, -185, -185, -185, -186, -186, -187, -187, -187,\n",
       "       -188, -188, -188, -189, -189, -190, -190, -190, -191, -191, -191,\n",
       "       -192, -192, -192, -193, -193, -194, -194, -194, -195, -195, -195,\n",
       "       -196, -196, -196, -197, -197, -197, -198, -198, -198, -199, -199,\n",
       "       -199, -200, -200, -200, -201, -201, -201, -202, -202, -202, -203,\n",
       "       -203, -203, -204, -204, -204, -204, -205, -205, -205, -206, -206,\n",
       "       -206])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_bucket_values[200:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5be85c8",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Comparing bucket location\n",
    "\n",
    "> we can know that bucket value of pretrained is same with bucket value of finetuned one if only the position length between two token is less or same than 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1bfa2f1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T09:34:23.885836Z",
     "start_time": "2022-03-02T09:34:23.883337Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained bucket value -150 was in location [161, 162]\n",
      "finetuned bucket value -150 was in location [161, 162]\n"
     ]
    }
   ],
   "source": [
    "bucket_value = -150\n",
    "print(f'pretrained bucket value {bucket_value} was in location {np.where(pretrained_bucket_values == bucket_value)[0].tolist()}')\n",
    "print(f'finetuned bucket value {bucket_value} was in location {np.where(finetuned_bucket_values == bucket_value)[0].tolist()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "979dfc1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T09:34:33.164125Z",
     "start_time": "2022-03-02T09:34:33.161483Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained bucket value -255 was in location [506, 507, 508, 509, 510, 511]\n",
      "finetuned bucket value -255 was in location [506, 507, 508, 509, 510, 511]\n"
     ]
    }
   ],
   "source": [
    "bucket_value = -255\n",
    "print(f'pretrained bucket value {bucket_value} was in location {np.where(pretrained_bucket_values == bucket_value)[0].tolist()}')\n",
    "print(f'finetuned bucket value {bucket_value} was in location {np.where(finetuned_bucket_values == bucket_value)[0].tolist()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "abf5234e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T09:34:41.768627Z",
     "start_time": "2022-03-02T09:34:41.765974Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained bucket value -256 was in location []\n",
      "finetuned bucket value -256 was in location [512, 513, 514, 515, 516]\n"
     ]
    }
   ],
   "source": [
    "bucket_value = -256\n",
    "print(f'pretrained bucket value {bucket_value} was in location {np.where(pretrained_bucket_values == bucket_value)[0].tolist()}')\n",
    "print(f'finetuned bucket value {bucket_value} was in location {np.where(finetuned_bucket_values == bucket_value)[0].tolist()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1d744273",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T09:35:25.197052Z",
     "start_time": "2022-03-02T09:35:25.193796Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained bucket value -300 was in location []\n",
      "finetuned bucket value -300 was in location [826, 827, 828, 829, 830, 831, 832, 833, 834]\n"
     ]
    }
   ],
   "source": [
    "bucket_value = -300\n",
    "print(f'pretrained bucket value {bucket_value} was in location {np.where(pretrained_bucket_values == bucket_value)[0].tolist()}')\n",
    "print(f'finetuned bucket value {bucket_value} was in location {np.where(finetuned_bucket_values == bucket_value)[0].tolist()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d735338d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T09:35:37.341922Z",
     "start_time": "2022-03-02T09:35:37.339606Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained bucket value -383 was in location []\n",
      "finetuned bucket value -383 was in location [2041, 2042, 2043, 2044, 2045, 2046, 2047]\n"
     ]
    }
   ],
   "source": [
    "bucket_value = -383\n",
    "print(f'pretrained bucket value {bucket_value} was in location {np.where(pretrained_bucket_values == bucket_value)[0].tolist()}')\n",
    "print(f'finetuned bucket value {bucket_value} was in location {np.where(finetuned_bucket_values == bucket_value)[0].tolist()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3f11f31f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T09:35:48.813336Z",
     "start_time": "2022-03-02T09:35:48.810295Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained bucket value -384 was in location []\n",
      "finetuned bucket value -384 was in location []\n"
     ]
    }
   ],
   "source": [
    "bucket_value = -384\n",
    "print(f'pretrained bucket value {bucket_value} was in location {np.where(pretrained_bucket_values == bucket_value)[0].tolist()}')\n",
    "print(f'finetuned bucket value {bucket_value} was in location {np.where(finetuned_bucket_values == bucket_value)[0].tolist()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fb4da7",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Bert Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6584383",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T09:52:43.385632Z",
     "start_time": "2022-03-02T09:52:43.380419Z"
    },
    "hidden": true
   },
   "source": [
    "```python\n",
    "class BertLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertLayer, self).__init__()\n",
    "        self.attention = BertAttention(config)\n",
    "        self.intermediate = BertIntermediate(config)\n",
    "        self.output = BertOutput(config)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states,\n",
    "        attention_mask,\n",
    "        return_att=False,\n",
    "        query_states=None,\n",
    "        relative_pos=None,\n",
    "        rel_embeddings=None,\n",
    "    ):\n",
    "        attention_output = self.attention(\n",
    "            hidden_states,\n",
    "            attention_mask,\n",
    "            return_att=return_att,\n",
    "            query_states=query_states,\n",
    "            relative_pos=relative_pos,\n",
    "            rel_embeddings=rel_embeddings,\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81f1d5f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```python\n",
    "class BertAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.self = DisentangledSelfAttention(config)\n",
    "        self.output = BertSelfOutput(config)\n",
    "        self.config = config\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states,\n",
    "        attention_mask,\n",
    "        return_att=False,\n",
    "        query_states=None,\n",
    "        relative_pos=None,\n",
    "        rel_embeddings=None,\n",
    "    ):\n",
    "        output = self.self(\n",
    "            hidden_states,\n",
    "            attention_mask,\n",
    "            return_att,\n",
    "            query_states=query_states,\n",
    "            relative_pos=relative_pos,\n",
    "            rel_embeddings=rel_embeddings,  # nn.Embedding(pos_ebd_size, config.hidden_size)\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d09a531",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- [class DisentangledSelfAttention](https://github.com/microsoft/DeBERTa/blob/master/DeBERTa/deberta/disentangled_attention.py#L28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79f3372",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```python\n",
    "class DisentangledSelfAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.num_attention_heads = config.num_attention_heads\n",
    "        _attention_head_size = int(config.hidden_size / config.num_attention_heads)\n",
    "        self.attention_head_size = getattr(config, 'attention_head_size', _attention_head_size)\n",
    "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
    "        self.query_proj = nn.Linear(config.hidden_size, self.all_head_size, bias=True)\n",
    "        self.key_proj = nn.Linear(config.hidden_size, self.all_head_size, bias=True)\n",
    "        self.value_proj = nn.Linear(config.hidden_size, self.all_head_size, bias=True)\n",
    "\n",
    "        self.relative_attention = getattr(config, 'relative_attention', False)\n",
    "\n",
    "        if self.relative_attention:\n",
    "            self.position_buckets = getattr(config, 'position_buckets', -1)\n",
    "            self.max_relative_positions = getattr(config, 'max_relative_positions', -1)\n",
    "            if self.max_relative_positions <1:\n",
    "                self.max_relative_positions = config.max_position_embeddings\n",
    "            self.pos_ebd_size = self.max_relative_positions\n",
    "            if self.position_buckets>0:\n",
    "                self.pos_ebd_size = self.position_buckets\n",
    "                # For backward compitable\n",
    "\n",
    "            self.pos_dropout = StableDropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask, return_att=False, query_states=None, relative_pos=None, rel_embeddings=None):\n",
    "        if query_states is None:\n",
    "            query_states = hidden_states\n",
    "\n",
    "        query_layer = self.transpose_for_scores(self.query_proj(query_states), self.num_attention_heads).float()\n",
    "        key_layer = self.transpose_for_scores(self.key_proj(hidden_states), self.num_attention_heads).float()\n",
    "        value_layer = self.transpose_for_scores(self.value_proj(hidden_states), self.num_attention_heads)\n",
    "        \n",
    "        rel_att = None\n",
    "        scale = 1/math.sqrt(query_layer.size(-1)*scale_factor)\n",
    "        attention_scores = torch.bmm(query_layer, key_layer.transpose(-1, -2)*scale)\n",
    "        if self.relative_attention:\n",
    "            rel_embeddings = self.pos_dropout(rel_embeddings)\n",
    "            rel_att = self.disentangled_attention_bias(query_layer, key_layer, relative_pos, rel_embeddings, scale_factor)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c646ba7e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "pos_ebd_size turns to 256 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a722908a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def disentangled_attention_bias(self, query_layer, key_layer, relative_pos, rel_embeddings, scale_factor):\n",
    "        if relative_pos is None:\n",
    "            q = query_layer.size(-2)\n",
    "            relative_pos = build_relative_position(q, key_layer.size(-2), bucket_size = self.position_buckets, max_position = self.max_relative_positions)\n",
    "        if relative_pos.dim()==2:\n",
    "            relative_pos = relative_pos.unsqueeze(0).unsqueeze(0)\n",
    "        elif relative_pos.dim()==3:\n",
    "            relative_pos = relative_pos.unsqueeze(1)\n",
    "        # bxhxqxk\n",
    "        elif relative_pos.dim()!=4:\n",
    "            raise ValueError(f'Relative postion ids must be of dim 2 or 3 or 4. {relative_pos.dim()}')\n",
    "\n",
    "        att_span = self.pos_ebd_size\n",
    "        relative_pos = relative_pos.long().to(query_layer.device)\n",
    "\n",
    "        rel_embeddings = rel_embeddings[self.pos_ebd_size - att_span:self.pos_ebd_size + att_span, :].unsqueeze(0) #.repeat(query_layer.size(0)//self.num_attention_heads, 1, 1)\n",
    "        if self.share_att_key:\n",
    "            pos_query_layer = self.transpose_for_scores(self.query_proj(rel_embeddings), self.num_attention_heads)\\\n",
    "                .repeat(query_layer.size(0)//self.num_attention_heads, 1, 1) #.split(self.all_head_size, dim=-1)\n",
    "            pos_key_layer = self.transpose_for_scores(self.key_proj(rel_embeddings), self.num_attention_heads)\\\n",
    "                .repeat(query_layer.size(0)//self.num_attention_heads, 1, 1) #.split(self.all_head_size, dim=-1)\n",
    "        else:\n",
    "            if 'c2p' in self.pos_att_type or 'p2p' in self.pos_att_type:\n",
    "                pos_key_layer = self.transpose_for_scores(self.pos_key_proj(rel_embeddings), self.num_attention_heads)\\\n",
    "                    .repeat(query_layer.size(0)//self.num_attention_heads, 1, 1) #.split(self.all_head_size, dim=-1)\n",
    "            if 'p2c' in self.pos_att_type or 'p2p' in self.pos_att_type:\n",
    "                pos_query_layer = self.transpose_for_scores(self.pos_query_proj(rel_embeddings), self.num_attention_heads)\\\n",
    "                    .repeat(query_layer.size(0)//self.num_attention_heads, 1, 1) #.split(self.all_head_size, dim=-1)\n",
    "\n",
    "        score = 0\n",
    "        # content -> position\n",
    "        if 'c2p' in self.pos_att_type:\n",
    "            scale = 1/math.sqrt(pos_key_layer.size(-1)*scale_factor)\n",
    "            c2p_att = torch.bmm(query_layer, pos_key_layer.transpose(-1, -2).to(query_layer)*scale)\n",
    "            c2p_pos = torch.clamp(relative_pos + att_span, 0, att_span*2-1)\n",
    "            c2p_att = torch.gather(c2p_att, dim=-1, index=c2p_pos.squeeze(0).expand([query_layer.size(0), query_layer.size(1), relative_pos.size(-1)]))\n",
    "            score += c2p_att\n",
    "\n",
    "        # position -> content\n",
    "        if 'p2c' in self.pos_att_type or 'p2p' in self.pos_att_type:\n",
    "            scale = 1/math.sqrt(pos_query_layer.size(-1)*scale_factor)\n",
    "            if key_layer.size(-2) != query_layer.size(-2):\n",
    "                r_pos = build_relative_position(key_layer.size(-2), key_layer.size(-2), bucket_size = self.position_buckets, max_position = self.max_relative_positions).to(query_layer.device)\n",
    "                r_pos = r_pos.unsqueeze(0)\n",
    "            else:\n",
    "                r_pos = relative_pos\n",
    "\n",
    "            p2c_pos = torch.clamp(-r_pos + att_span, 0, att_span*2-1)\n",
    "            if query_layer.size(-2) != key_layer.size(-2):\n",
    "                pos_index = relative_pos[:, :, :, 0].unsqueeze(-1)\n",
    "\n",
    "        if 'p2c' in self.pos_att_type:\n",
    "            p2c_att = torch.bmm(key_layer, pos_query_layer.transpose(-1, -2).to(key_layer)*scale)\n",
    "            p2c_att = torch.gather(p2c_att, dim=-1, index=p2c_pos.squeeze(0).expand([query_layer.size(0), key_layer.size(-2), key_layer.size(-2)])).transpose(-1,-2)\n",
    "            if query_layer.size(-2) != key_layer.size(-2):\n",
    "                p2c_att = torch.gather(p2c_att, dim=-2, index=pos_index.expand(p2c_att.size()[:2] + (pos_index.size(-2), key_layer.size(-2))))\n",
    "            score += p2c_att\n",
    "\n",
    "        # position -> position\n",
    "        if 'p2p' in self.pos_att_type:\n",
    "            pos_query = pos_query_layer[:,:,att_span:,:]\n",
    "            p2p_att = torch.matmul(pos_query, pos_key_layer.transpose(-1, -2))\n",
    "            p2p_att = p2p_att.expand(query_layer.size()[:2] + p2p_att.size()[2:])\n",
    "            if query_layer.size(-2) != key_layer.size(-2):\n",
    "                p2p_att = torch.gather(p2p_att, dim=-2, index=pos_index.expand(query_layer.size()[:2] + (pos_index.size(-2), p2p_att.size(-1))))\n",
    "            p2p_att = torch.gather(p2p_att, dim=-1, index=c2p_pos.expand([query_layer.size(0), query_layer.size(1), query_layer.size(2), relative_pos.size(-1)]))\n",
    "            score += p2p_att\n",
    "\n",
    "        return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4ac405",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Pos is clamped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f1bec022",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T13:02:58.306480Z",
     "start_time": "2022-03-02T13:02:58.208053Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative positional ids\n",
      "[[    0    -1    -2 ... -2045 -2046 -2047]\n",
      " [    1     0    -1 ... -2044 -2045 -2046]\n",
      " [    2     1     0 ... -2043 -2044 -2045]\n",
      " ...\n",
      " [ 2045  2044  2043 ...     0    -1    -2]\n",
      " [ 2046  2045  2044 ...     1     0    -1]\n",
      " [ 2047  2046  2045 ...     2     1     0]]\n"
     ]
    }
   ],
   "source": [
    "relative_pos = build_relative_position(\n",
    "    query_size=2048,\n",
    "    key_size=2048,\n",
    "    bucket_size=config.position_buckets,\n",
    "    max_position=config.max_position_embeddings,  # alternative for max_relative_embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "0f4425e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T13:02:58.406193Z",
     "start_time": "2022-03-02T13:02:58.401865Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[   0,   -1,   -2,  ..., -383, -383, -383],\n",
       "         [   1,    0,   -1,  ..., -383, -383, -383],\n",
       "         [   2,    1,    0,  ..., -383, -383, -383],\n",
       "         ...,\n",
       "         [ 383,  383,  383,  ...,    0,   -1,   -2],\n",
       "         [ 383,  383,  383,  ...,    1,    0,   -1],\n",
       "         [ 383,  383,  383,  ...,    2,    1,    0]]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d6ab7113",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T13:03:01.364565Z",
     "start_time": "2022-03-02T13:03:01.362492Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "max_relative_positions = config.max_position_embeddings\n",
    "pos_ebd_size = config.position_buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "68302c50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T13:03:01.528277Z",
     "start_time": "2022-03-02T13:03:01.525841Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_span = pos_ebd_size\n",
    "att_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7de0d319",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T13:03:11.634228Z",
     "start_time": "2022-03-02T13:03:11.628649Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 256,  255,  254,  ..., -127, -127, -127],\n",
       "         [ 257,  256,  255,  ..., -127, -127, -127],\n",
       "         [ 258,  257,  256,  ..., -127, -127, -127],\n",
       "         ...,\n",
       "         [ 639,  639,  639,  ...,  256,  255,  254],\n",
       "         [ 639,  639,  639,  ...,  257,  256,  255],\n",
       "         [ 639,  639,  639,  ...,  258,  257,  256]]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_pos + att_span"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5075f93a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "511 (right token) - 256 (where the token is) - 0 (left token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7e4d3850",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T11:26:00.435990Z",
     "start_time": "2022-03-02T11:26:00.425768Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[256, 255, 254,  ...,   0,   0,   0],\n",
       "         [257, 256, 255,  ...,   0,   0,   0],\n",
       "         [258, 257, 256,  ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [511, 511, 511,  ..., 256, 255, 254],\n",
       "         [511, 511, 511,  ..., 257, 256, 255],\n",
       "         [511, 511, 511,  ..., 258, 257, 256]]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2p_pos = torch.clamp(relative_pos + att_span, 0, att_span*2-1)\n",
    "c2p_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0bad2b51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T11:26:29.811944Z",
     "start_time": "2022-03-02T11:26:29.808387Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([256, 255, 254, 253, 252, 251, 250, 249, 248, 247, 246, 245, 244, 243,\n",
       "        242, 241, 240, 239, 238, 237, 236, 235, 234, 233, 232, 231, 230, 229,\n",
       "        228, 227, 226, 225, 224, 223, 222, 221, 220, 219, 218, 217, 216, 215,\n",
       "        214, 213, 212, 211, 210, 209, 208, 207, 206, 205, 204, 203, 202, 201,\n",
       "        200, 199, 198, 197, 196, 195, 194, 193, 192, 191, 190, 189, 188, 187,\n",
       "        186, 185, 184, 183, 182, 181, 180, 179, 178, 177, 176, 175, 174, 173,\n",
       "        172, 171, 170, 169, 168, 167, 166, 165, 164, 163, 162, 161, 160, 159,\n",
       "        158, 157])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2p_pos[0][0][:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4511f72",
   "metadata": {
    "hidden": true
   },
   "source": [
    "same position exist for 1536 times. 3 quarter of total attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3c8749b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T11:29:23.249788Z",
     "start_time": "2022-03-02T11:29:23.245531Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1536)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(c2p_pos[0][0] == 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190eea20",
   "metadata": {},
   "source": [
    "## Relative Embedding is right?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee757203",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T11:33:43.465285Z",
     "start_time": "2022-03-02T11:33:43.462457Z"
    }
   },
   "source": [
    "```python\n",
    "self.rel_embeddings = nn.Embedding(pos_ebd_size, config.hidden_size)\n",
    "self.LayerNorm = LayerNorm(config.hidden_size, config.layer_norm_eps)\n",
    "\n",
    "def get_rel_embedding(self):\n",
    "    rel_embeddings = self.rel_embeddings.weight if self.relative_attention else None\n",
    "    if rel_embeddings is not None and (\"layer_norm\" in self.norm_rel_ebd):\n",
    "        rel_embeddings = self.LayerNorm(rel_embeddings)\n",
    "    return rel_embeddings\n",
    "\n",
    "rel_embeddings = encoder.get_rel_embedding()\n",
    "self.pos_dropout = StableDropout(config.hidden_dropout_prob)\n",
    "rel_embeddings = self.pos_dropout(rel_embeddings)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "531020c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T11:31:34.794783Z",
     "start_time": "2022-03-02T11:31:34.792366Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(512, 1024)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert.rel_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b5b17e00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T11:41:48.367248Z",
     "start_time": "2022-03-02T11:41:48.364761Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 1024])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_embeddings = bert.rel_embeddings.weight\n",
    "rel_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "93e0f382",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T11:41:58.810454Z",
     "start_time": "2022-03-02T11:41:58.805435Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0698,  0.3482, -1.4406,  ...,  1.4373, -0.5048, -0.6732],\n",
       "        [-1.0669, -1.3299,  0.7206,  ..., -1.2796, -1.0290,  0.6135],\n",
       "        [ 0.5742, -0.5303,  0.3706,  ...,  1.0502,  0.6977,  0.3621],\n",
       "        ...,\n",
       "        [-0.6821, -0.3887, -1.6728,  ..., -1.3490, -0.0899, -2.2291],\n",
       "        [ 0.0834,  0.7432,  2.2757,  ...,  0.2183,  0.8242, -0.7037],\n",
       "        [-0.1434, -0.5098, -1.7966,  ...,  0.2468, -0.8081, -0.6022]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4f8617e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T11:41:27.238021Z",
     "start_time": "2022-03-02T11:41:27.235814Z"
    }
   },
   "outputs": [],
   "source": [
    "LayerNorm = torch.nn.LayerNorm(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "fffcf687",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T11:42:10.031883Z",
     "start_time": "2022-03-02T11:42:10.027771Z"
    }
   },
   "outputs": [],
   "source": [
    "rel_embeddings = LayerNorm(rel_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ef02b36f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T11:42:14.404732Z",
     "start_time": "2022-03-02T11:42:14.401402Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0778,  0.3543, -1.4226,  ...,  1.4362, -0.4930, -0.6603],\n",
       "        [-1.1001, -1.3597,  0.6642,  ..., -1.3101, -1.0626,  0.5585],\n",
       "        [ 0.5074, -0.5537,  0.3117,  ...,  0.9647,  0.6260,  0.3036],\n",
       "        ...,\n",
       "        [-0.7295, -0.4287, -1.7453,  ..., -1.4134, -0.1224, -2.3157],\n",
       "        [ 0.0607,  0.7239,  2.2642,  ...,  0.1963,  0.8053, -0.7305],\n",
       "        [-0.1270, -0.4933, -1.7797,  ...,  0.2631, -0.7916, -0.5857]],\n",
       "       grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9822a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T11:46:14.756141Z",
     "start_time": "2022-03-02T11:46:14.752714Z"
    }
   },
   "source": [
    "- [StableDropout](https://github.com/microsoft/DeBERTa/blob/master/DeBERTa/deberta/ops.py#L131-L180)\n",
    "- [mask code](https://github.com/microsoft/DeBERTa/blob/master/DeBERTa/deberta/ops.py#L101)\n",
    "```python\n",
    "mask=(1-torch.empty_like(input).bernoulli_(1-dropout)).byte()\n",
    "```\n",
    "\n",
    "removed the some part of embedding values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f03207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "286.25px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
