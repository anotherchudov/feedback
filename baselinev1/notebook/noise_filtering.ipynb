{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48b200f4",
   "metadata": {},
   "source": [
    "# 🦆 Training\n",
    "\n",
    "✅ **needed to be checked**\n",
    "- mixed precision (minor code refactoring done) ✅\n",
    "- loss function (cross entropy loss and rce loss)  ✅\n",
    "- collate (does it properly implemented?)\n",
    "    - assumed torch padding function but was not used\n",
    "- entity_extraction function\n",
    "- does deverta accepted long sequence length even the config setted by 512 seq len?\n",
    "\n",
    "✅ **needed to be added**\n",
    "- training depend on device ✅\n",
    "- model output to prediction string converter\n",
    "- f1macro calculation by prediction string\n",
    "- training mode without gradient accumulation\n",
    "\n",
    "---\n",
    "\n",
    "- Environment Setting\n",
    "- Argument Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bd7c2d",
   "metadata": {},
   "source": [
    "## Environment Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0ab4178",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T13:52:14.452350Z",
     "start_time": "2022-03-09T13:52:14.449838Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "\n",
    "DATASET_PATH = ('../../feedback-prize-2021')\n",
    "\n",
    "sys.path.insert(0, './codes')\n",
    "sys.path.append('longformer/tvm/python/')\n",
    "sys.path.append('longformer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2a83c79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T13:52:16.276827Z",
     "start_time": "2022-03-09T13:52:14.453339Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import easydict\n",
    "import argparse\n",
    "\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "import ftfy\n",
    "import dill as pickle\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "from transformers import DebertaV2Model\n",
    "\n",
    "# torch.use_deterministic_algorithms(True)\n",
    "# from longformer.longformer import Longformer, LongformerConfig, RobertaModel\n",
    "# from longformer.sliding_chunks import pad_to_window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fb3b605",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T13:52:16.280677Z",
     "start_time": "2022-03-09T13:52:16.277821Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\"\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6997bb5",
   "metadata": {},
   "source": [
    "**why using `os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\"`?**\n",
    "- [torch.use_deterministic_algorithms](https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html)\n",
    "> **A handful of CUDA operations are nondeterministic if the CUDA version is 10.2 or greater**, unless the environment variable `CUBLAS_WORKSPACE_CONFIG=:4096:8` or `CUBLAS_WORKSPACE_CONFIG=:16:8` is set. See the CUDA documentation for more details: https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility If one of these environment variable configurations is not set, a RuntimeError will be raised from these operations when called with CUDA tensors:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c96213b",
   "metadata": {},
   "source": [
    "## Argument Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06d834b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T13:52:16.301789Z",
     "start_time": "2022-03-09T13:52:16.281972Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_config():\n",
    "    parser = argparse.ArgumentParser(description=\"use huggingface models\")\n",
    "    parser.add_argument(\"--wandb_user\", default='ducky', type=str)\n",
    "    parser.add_argument(\"--wandb_project\", default='feedback_deberta_large', type=str)\n",
    "    parser.add_argument(\"--dataset_path\", default='../../feedback-prize-2021', type=str)\n",
    "    parser.add_argument(\"--save_path\", default='result', type=str)\n",
    "    parser.add_argument(\"--seed\", default=0, type=int)\n",
    "    parser.add_argument(\"--min_len\", default=0, type=int)\n",
    "    parser.add_argument(\"--use_groupped_weights\", default=False, type=bool)\n",
    "    parser.add_argument(\"--global_attn\", default=False, type=int)\n",
    "    parser.add_argument(\"--label_smoothing\", default= 0.1, type=float)\n",
    "    parser.add_argument(\"--epochs\", default=9, type=int)\n",
    "    parser.add_argument(\"--batch_size\", default=4, type=int)\n",
    "    parser.add_argument(\"--grad_acc_steps\", default=2, type=int)\n",
    "    parser.add_argument(\"--grad_checkpt\", default=True, type=bool)\n",
    "    parser.add_argument(\"--data_prefix\", default='', type=str)\n",
    "    parser.add_argument(\"--max_grad_norm\", default=35 * 8, type=int)\n",
    "    parser.add_argument(\"--start_eval_at\", default=0, type=int)\n",
    "    parser.add_argument(\"--lr\", default=3e-5, type=float)\n",
    "    parser.add_argument(\"--min_lr\", default=3e-5, type=float)\n",
    "    parser.add_argument(\"--weight_decay\", default=1e-2, type=float)\n",
    "    parser.add_argument(\"--weights_pow\", default=0.1, type=float)\n",
    "    parser.add_argument(\"--dataset_version\", default=2, type=int)\n",
    "    parser.add_argument(\"--warmup_steps\", default=500, type=int)\n",
    "    parser.add_argument(\"--decay_bias\", default=False, type=bool)\n",
    "    parser.add_argument(\"--val_fold\", default=0, type=int)\n",
    "    parser.add_argument(\"--num_worker\", default=8, type=int)\n",
    "    parser.add_argument(\"--local_rank\", type=int, default=-1, help=\"do not modify!\")\n",
    "    parser.add_argument(\"--device\", type=int, default=0, help=\"select the gpu device to train\")\n",
    "\n",
    "    # optimizer\n",
    "    parser.add_argument(\"--rce_weight\", default=0.1, type=float)\n",
    "    parser.add_argument(\"--ce_weight\", default=0.9, type=float)\n",
    "\n",
    "    # model related arguments\n",
    "    parser.add_argument(\"--model\", default=\"microsoft/deberta-v3-large\", type=str)\n",
    "    parser.add_argument(\"--cnn1d\", default=False, type=bool)\n",
    "    parser.add_argument(\"--extra_dense\", default= False, type=bool)\n",
    "    parser.add_argument(\"--dropout_ratio\", default=0.0, type=float)\n",
    "    args = parser.parse_args(args=[])\n",
    "\n",
    "    if args.local_rank !=-1:\n",
    "        print('[ DDP ] local rank', args.local_rank)\n",
    "        torch.cuda.set_device(args.local_rank)\n",
    "        dist.init_process_group(backend='nccl')\n",
    "        args.device = torch.device(\"cuda\", args.local_rank)\n",
    "        args.rank = torch.distributed.get_rank()\n",
    "        args.world_size = torch.distributed.get_world_size()  \n",
    "\n",
    "        # checking settings for distributed training\n",
    "        assert args.batch_size % args.world_size == 0, f'--batch_size {args.batch_size} must be multiple of world size'\n",
    "        assert torch.cuda.device_count() > args.local_rank, 'insufficient CUDA devices for DDP command'\n",
    "\n",
    "        args.ddp = True\n",
    "    else:\n",
    "        args.device = torch.device(\"cuda\")\n",
    "        args.rank = 0\n",
    "        args.ddp = False\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f00e56b",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b57f981b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T13:52:16.321420Z",
     "start_time": "2022-03-09T13:52:16.303058Z"
    }
   },
   "outputs": [],
   "source": [
    "from module.utils import get_token_weights\n",
    "from module.utils import get_prepare_data\n",
    "from module.utils import get_all_texts\n",
    "from module.utils import get_id_to_ix_map\n",
    "from module.utils import get_fold_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c3dca6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T13:52:16.330952Z",
     "start_time": "2022-03-09T13:52:16.322939Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data_files(args):\n",
    "    token_weights = get_token_weights(args.use_groupped_weights, args.weights_pow)\n",
    "    data = get_prepare_data()\n",
    "    csv = pd.read_csv(osp.join(args.dataset_path, 'train.csv'))\n",
    "    all_texts = get_all_texts(args)\n",
    "    id_to_ix_map = get_id_to_ix_map()\n",
    "    data_splits = get_fold_data()\n",
    "\n",
    "    # text_id example `16585724607E`\n",
    "    train_text_ids = [text_id for fold in range(5) if fold != args.val_fold for text_id in data_splits[args.seed][250]['normed'][fold]]\n",
    "    val_text_ids = data_splits[args.seed][250]['normed'][args.val_fold]\n",
    "\n",
    "    train_ids = [id_to_ix_map[text_id] for text_id in train_text_ids]\n",
    "    val_ids = [id_to_ix_map[text_id] for text_id in val_text_ids]\n",
    "\n",
    "    return all_texts, token_weights, data, csv, train_ids, val_ids, train_text_ids, val_text_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7774e93",
   "metadata": {},
   "source": [
    "## Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5387adc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T13:52:16.353533Z",
     "start_time": "2022-03-09T13:52:16.331727Z"
    }
   },
   "outputs": [],
   "source": [
    "def wandb_setting(args):\n",
    "    wandb.login()\n",
    "    run = wandb.init(entity=args.wandb_user, project=args.wandb_project)\n",
    "    run.name = f'v3_fold{args.val_fold}_minlr{args.min_lr}_maxlr{args.lr}_wd{args.weight_decay}_warmup{args.warmup_steps}_gradnorm{args.max_grad_norm}_biasdecay{args.decay_bias}_ls{args.label_smoothing}_wp{args.weights_pow}_data{args.dataset_version}_rce{args.rce_weight}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5d7840",
   "metadata": {},
   "source": [
    "## 🐣 Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f1a60b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T13:52:16.364587Z",
     "start_time": "2022-03-09T13:52:16.355018Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class TrainDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, ids, data, label_smoothing, token_weights, data_prefix):\n",
    "        self.ids = ids\n",
    "        self.data = data\n",
    "        self.label_smoothing = label_smoothing\n",
    "        self.token_weights = token_weights\n",
    "        self.data_prefix = data_prefix\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i = self.ids[idx]\n",
    "\n",
    "        # load train data\n",
    "        tokens = self.data['tokens'][i]\n",
    "        attention_mask = self.data['attention_masks'][i]\n",
    "        num_tokens = self.data['num_tokens'][i, 0]\n",
    "\n",
    "        # label smoothing\n",
    "        cbio_labels = self.data[f'{self.data_prefix}cbio_labels'][i]\n",
    "        cbio_labels *= (1 - self.label_smoothing)\n",
    "        cbio_labels += self.label_smoothing / 15\n",
    "\n",
    "        # class weight per token\n",
    "        class_weight = np.zeros_like(attention_mask)\n",
    "        argmax_labels = cbio_labels.argmax(-1)\n",
    "\n",
    "        for class_i in range(1, 15):\n",
    "            class_weight[argmax_labels == class_i] = self.token_weights[class_i]\n",
    "\n",
    "        class_none_index = argmax_labels == 0      # 0 is the text that is not entity\n",
    "        class_none_index[num_tokens - 1:] = False  # special token & padding\n",
    "        class_weight[class_none_index] = self.token_weights[0]\n",
    "        class_weight[0] = 0\n",
    "\n",
    "        return tokens, attention_mask, cbio_labels, class_weight, num_tokens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "362dcb5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T13:52:16.387111Z",
     "start_time": "2022-03-09T13:52:16.366163Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class ValDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, ids, data, csv, all_texts, val_text_ids, class_names, token_weights):\n",
    "        self.ids = ids\n",
    "        self.data = data\n",
    "        self.csv = csv\n",
    "        self.space_regex = re.compile('[\\s\\n]')\n",
    "        self.all_texts = all_texts\n",
    "        self.val_text_ids = val_text_ids\n",
    "        self.class_names = class_names\n",
    "        self.token_weights = token_weights\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i = self.ids[idx]\n",
    "\n",
    "        # load text data & text dataframe\n",
    "        text_id = self.val_text_ids[idx]\n",
    "        text = self.all_texts[text_id]\n",
    "        sample_df = self.csv.query('id == @text_id')\n",
    "\n",
    "        # load ground truth prediction string for f1macro metric\n",
    "        gt_dict = {}\n",
    "        for class_i in range(1, 8):\n",
    "            class_name = self.class_names[class_i]\n",
    "            class_df = sample_df.query('discourse_type == @class_name')   \n",
    "            if len(class_df):\n",
    "                gt_dict[class_i] = [(x[0], x[1]) for x in class_df.predictionstring.map(split_predstring)]\n",
    "        \n",
    "        # load valid data\n",
    "        tokens = self.data['tokens'][i]\n",
    "        attention_mask = self.data['attention_masks'][i]\n",
    "        num_tokens = self.data['num_tokens'][i, 0]\n",
    "        token_bounds = self.data['token_offsets'][i]\n",
    "        cbio_labels = self.data['cbio_labels'][i]\n",
    "        \n",
    "        # class weight per token\n",
    "        class_weight = np.zeros_like(attention_mask)\n",
    "        argmax_labels = cbio_labels.argmax(-1)\n",
    "\n",
    "        for class_i in range(1, 15):\n",
    "            class_weight[argmax_labels == class_i] = self.token_weights[class_i]\n",
    "\n",
    "        class_none_index = argmax_labels == 0\n",
    "        class_none_index[num_tokens - 1:] = False\n",
    "        class_weight[class_none_index] = self.token_weights[0]\n",
    "        class_weight[0] = 0\n",
    "        \n",
    "        # ???\n",
    "        index_map = []\n",
    "        current_word = 0\n",
    "        blank = False\n",
    "        for char_ix in range(text.index(text.strip()[0]), len(text)):\n",
    "            if self.space_regex.match(text[char_ix]) is not None:\n",
    "                blank = True\n",
    "            elif blank:\n",
    "                current_word += 1\n",
    "                blank = False\n",
    "            index_map.append(current_word)\n",
    "        \n",
    "        return tokens, attention_mask, cbio_labels, class_weight, token_bounds, gt_dict, index_map, num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "963b1afe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T13:52:16.402339Z",
     "start_time": "2022-03-09T13:52:16.388380Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_dataloader(train_ids, val_ids, data, csv, all_texts, val_text_ids, class_names, token_weights, args):\n",
    "    train_dataset = TrainDataset(train_ids, data, args.label_smoothing, token_weights, args.data_prefix)\n",
    "    val_dataset = ValDataset(val_ids, data, csv, all_texts, val_text_ids, class_names, token_weights)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, collate_fn=train_collate_fn, batch_size=args.batch_size, num_workers=args.num_worker)\n",
    "    val_dataloader = DataLoader(val_dataset, collate_fn=val_collate_fn, batch_size=args.batch_size, num_workers=8)\n",
    "\n",
    "    return train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a0cdc7",
   "metadata": {},
   "source": [
    "## Collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c5639ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T13:52:16.420659Z",
     "start_time": "2022-03-09T13:52:16.403595Z"
    }
   },
   "outputs": [],
   "source": [
    "first_batch = True\n",
    "def train_collate_fn(ins):\n",
    "    global first_batch\n",
    "    if first_batch:\n",
    "        max_len = 2048\n",
    "        first_batch = False\n",
    "    else:\n",
    "        max_len = (max(x[-1] for x in ins) + 7) // 8 * 8\n",
    "        \n",
    "    return tuple(torch.from_numpy(np.concatenate([ins[z][x][None, :max_len] for z in range(len(ins))])) for x in range(len(ins[0]) - 1))\n",
    "    \n",
    "def val_collate_fn(ins):\n",
    "    max_len = (max(x[-1] for x in ins) + 7) // 8 * 8\n",
    "    return tuple(torch.from_numpy(np.concatenate([ins[z][x][None, :max_len] for z in range(len(ins))])) for x in range(len(ins[0]) - 3)) + ([x[-3] for x in ins], [x[-2] for x in ins], np.array([x[-1] for x in ins]),)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6f4d96",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5e317d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T13:52:16.434973Z",
     "start_time": "2022-03-09T13:52:16.422105Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def custom_ce(preds, gts, class_weight):\n",
    "    preds = torch.log_softmax(preds, -1)\n",
    "    loss = -(((preds * gts).sum(-1) * class_weight).sum(-1) / class_weight.sum(-1)).mean()\n",
    "\n",
    "    return loss\n",
    "\n",
    "def custom_rce(preds, gts, class_weight):\n",
    "    preds = torch.log_softmax(preds, -1)\n",
    "    loss = -(((torch.exp(preds) * torch.log_softmax(gts, -1)).sum(-1) * class_weight).sum(-1) / class_weight.sum(-1)).mean()\n",
    "\n",
    "    return loss\n",
    "\n",
    "class Criterion():\n",
    "    \"\"\"Wrapper for multi criterion calculation\"\"\"\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        self.criterions = self.get_criterions()\n",
    "        self.criterion_names = self.args.criterion_list\n",
    "        self.criterion_ratios = args.criterion_ratio\n",
    "\n",
    "    def get_criterions(self):\n",
    "        criterions = []\n",
    "        for criterion in self.args.criterion_list:\n",
    "            if criterion == \"crossentropy\":\n",
    "                criterions.append(nn.CrossEntropyLoss(weight=self.args.class_weight,\n",
    "                                                      label_smoothing=self.args.label_smoothing))\n",
    "            elif criterion == \"custom_ce\":\n",
    "                criterions.append(custom_ce)\n",
    "            elif criterion == \"custom_rce\":\n",
    "                criterions.append(custom_rce)\n",
    "                \n",
    "        return criterions\n",
    "\n",
    "    def reshape(self, preds, gts):\n",
    "        \"\"\"TODO: fix the dataloader to argmax label version and change this code\"\"\"\n",
    "        return preds.view(-1, 15), gts.argmax(-1).view(-1)\n",
    "    \n",
    "    def calculate_loss(self, preds, gts, class_weight=None):\n",
    "        total_loss = 0\n",
    "        for criterion_name, criterion, ratio in zip(self.criterion_names, self.criterions, self.criterion_ratios):\n",
    "            if criterion_name in ['custom_ce', 'custom_rce']:\n",
    "                current_loss = criterion(preds, gts, class_weight)\n",
    "            else:\n",
    "                # TODO: tailored for current dataloader\n",
    "                preds_, gts_ = self.reshape(preds, gts)\n",
    "                current_loss = criterion(preds_, gts_)\n",
    "            total_loss = total_loss + current_loss * ratio\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def __call__(self, preds, gts, class_weight=None):\n",
    "        return self.calculate_loss(preds, gts, class_weight)\n",
    "\n",
    "\n",
    "\n",
    "def get_criterion(args):\n",
    "    criterion = Criterion(args)\n",
    "\n",
    "    return criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fa7e34",
   "metadata": {},
   "source": [
    "## 🧣 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d18f08f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T13:52:16.454925Z",
     "start_time": "2022-03-09T13:52:16.435762Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class DebertaV3Large(torch.nn.Module):\n",
    "    \"\"\"microsoft/deberta-v3-large\"\"\"\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "\n",
    "        self.feats = DebertaV2Model.from_pretrained('microsoft/deberta-v3-large')\n",
    "        self.feats.pooler = None\n",
    "\n",
    "        if args.grad_checkpt:\n",
    "            self.feats.gradient_checkpointing_enable()\n",
    "\n",
    "        if args.cnn1d:\n",
    "            self.conv1d_layer1 = torch.nn.Conv1d(1024, 1024, kernel_size=1)\n",
    "            self.conv1d_layer3 = torch.nn.Conv1d(1024, 1024, kernel_size=3, padding=1)\n",
    "            self.conv1d_layer5 = torch.nn.Conv1d(1024, 1024, kernel_size=5, padding=2)\n",
    "\n",
    "            self.output_length = 1024 * 3\n",
    "        else:\n",
    "            self.output_length = 1024\n",
    "\n",
    "        if args.extra_dense:\n",
    "            self.class_projector = torch.nn.Sequential(\n",
    "                torch.nn.LayerNorm(self.output_length),\n",
    "                torch.nn.Linear(self.output_length, 256),\n",
    "                torch.nn.GELU(),\n",
    "                torch.nn.Linear(256, 15)\n",
    "            )\n",
    "        else:\n",
    "            self.class_projector = torch.nn.Sequential(\n",
    "                torch.nn.LayerNorm(self.output_length),\n",
    "                torch.nn.Linear(self.output_length, 15)\n",
    "            )\n",
    "\n",
    "    def forward(self, tokens, mask):\n",
    "        transformer_output = self.feats(tokens, mask, return_dict=False)[0]\n",
    "        \n",
    "        if self.args.cnn1d:\n",
    "            conv_input = transformer_output.transpose(1, 2) # batch, hidden, seq\n",
    "\n",
    "            conv_output1 = F.relu(self.conv1d_layer1(conv_input)) \n",
    "            conv_output3 = F.relu(self.conv1d_layer3(conv_input)) \n",
    "            conv_output5 = F.relu(self.conv1d_layer5(conv_input)) \n",
    "\n",
    "            concat_output = torch.cat((conv_output1, conv_output3, conv_output5), dim=1).transpose(1, 2)\n",
    "            output = self.class_projector(concat_output)\n",
    "        else:\n",
    "            output = self.class_projector(transformer_output) # batch, seq, hidden\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "568cb661",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T13:52:16.474963Z",
     "start_time": "2022-03-09T13:52:16.455972Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(args):\n",
    "    if args.model == 'microsoft/deberta-v3-large':\n",
    "        model = DebertaV3Large(args).to(args.device)\n",
    "\n",
    "        # dropout layer\n",
    "        for m in model.modules():\n",
    "            if isinstance(m, torch.nn.Dropout):\n",
    "                m.p = args.dropout_ratio\n",
    "\n",
    "    # distributed training\n",
    "    if args.ddp:\n",
    "        model = DDP(model, device_ids=[args.rank], output_device=args.rank)\n",
    "        model.to(args.device)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccfe346",
   "metadata": {},
   "source": [
    "\n",
    "## 🚵🏻 Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cf55134",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T13:52:16.529257Z",
     "start_time": "2022-03-09T13:52:16.475965Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac4b776f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T13:52:16.620088Z",
     "start_time": "2022-03-09T13:52:16.530207Z"
    }
   },
   "outputs": [],
   "source": [
    "from module.metric import calc_acc, process_sample, make_match_dict\n",
    "\n",
    "from module.utils import get_data_files\n",
    "from module.loss import get_criterion\n",
    "from module.optimizer import get_optimizer\n",
    "from module.scheduler import get_scheduler\n",
    "from model.model import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2a12c3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T13:52:16.658277Z",
     "start_time": "2022-03-09T13:52:16.621091Z"
    }
   },
   "outputs": [],
   "source": [
    "seed_everything(42)\n",
    "args = get_config()\n",
    "# wandb_setting(args)\n",
    "\n",
    "class_names = ['None',\n",
    "               'Lead',\n",
    "               'Position',\n",
    "               'Evidence',\n",
    "               'Claim',\n",
    "               'Concluding Statement',\n",
    "               'Counterclaim',\n",
    "               'Rebuttal']\n",
    "\n",
    "# create directory to save model\n",
    "if not osp.exists(args.save_path):\n",
    "    os.makedirs(args.save_path)\n",
    "\n",
    "args.batch_size = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745adcc5",
   "metadata": {},
   "source": [
    "## Noise Filtering - Self Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "86132f03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T14:43:39.715450Z",
     "start_time": "2022-03-09T14:43:39.679195Z"
    }
   },
   "outputs": [],
   "source": [
    "args.batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20e4233e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T13:52:16.729533Z",
     "start_time": "2022-03-09T13:52:16.695078Z"
    }
   },
   "outputs": [],
   "source": [
    "args.device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b18da5ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T13:52:20.967714Z",
     "start_time": "2022-03-09T13:52:16.730880Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "args.model = 'microsoft/deberta-v3-large'\n",
    "model = get_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "294ebb42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T14:43:42.320294Z",
     "start_time": "2022-03-09T14:43:41.501640Z"
    }
   },
   "outputs": [],
   "source": [
    "all_texts, token_weights, data, csv, train_ids, val_ids, train_text_ids, val_text_ids = get_data_files(args)\n",
    "train_dataloader, val_dataloader = get_dataloader(train_ids, val_ids, data, csv, all_texts, val_text_ids, class_names, token_weights, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9fe3ff75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T13:52:21.993656Z",
     "start_time": "2022-03-09T13:52:21.957136Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.sampler.SequentialSampler at 0x7f7eca983e50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f1b7564",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T13:52:22.031229Z",
     "start_time": "2022-03-09T13:52:21.994584Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12454"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_len = len(train_text_ids)\n",
    "train_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e395e03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T13:52:22.069321Z",
     "start_time": "2022-03-09T13:52:22.033170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12454, 2048, 15)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_preds = np.zeros((train_len, 2048, 15), dtype='f4')\n",
    "ensemble_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67be43b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T13:52:22.109628Z",
     "start_time": "2022-03-09T13:52:22.070185Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV3Large(\n",
       "  (feats): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 1024, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (1): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (2): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (3): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (4): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (5): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (6): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (7): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (8): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (9): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (10): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (11): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (12): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (13): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (14): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (15): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (16): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (17): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (18): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (19): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (20): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (21): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (22): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (23): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (class_projector): Sequential(\n",
       "    (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=1024, out_features=15, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0d86be03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T14:44:14.512924Z",
     "start_time": "2022-03-09T14:43:44.117572Z"
    }
   },
   "outputs": [],
   "source": [
    "for step, batch in enumerate(train_dataloader):\n",
    "    tokens, mask, label, class_weight = (x.to(args.device) for x in batch)\n",
    "    outs = model(tokens, mask)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d609d3d9",
   "metadata": {},
   "source": [
    "### Ensemble predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "90883f47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T14:45:53.391583Z",
     "start_time": "2022-03-09T14:45:52.616004Z"
    }
   },
   "outputs": [],
   "source": [
    "outs = outs.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d9141868",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T14:56:58.861730Z",
     "start_time": "2022-03-09T14:56:58.824176Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs_batch_size = outs.shape[0]\n",
    "outs_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e8191e1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T14:57:01.415369Z",
     "start_time": "2022-03-09T14:57:01.374620Z"
    }
   },
   "outputs": [],
   "source": [
    "start_idx = step * args.batch_size\n",
    "end_idx = start_idx + outs_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fc26d26b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T14:45:51.414087Z",
     "start_time": "2022-03-09T14:45:51.371649Z"
    }
   },
   "outputs": [],
   "source": [
    "alpha = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4d9b0e09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T14:57:21.152775Z",
     "start_time": "2022-03-09T14:57:21.104043Z"
    }
   },
   "outputs": [],
   "source": [
    "ensemble_preds[start_idx:end_idx] = alpha * ensemble_preds[start_idx:end_idx] + (1 - alpha) * outs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb1d62f",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6f851bea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T14:45:58.893880Z",
     "start_time": "2022-03-09T14:45:58.857224Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5a89d957",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T15:05:49.624798Z",
     "start_time": "2022-03-09T15:05:49.587902Z"
    }
   },
   "outputs": [],
   "source": [
    "train_accs = np.zeros((train_len), dtype='f4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a97b6190",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T14:46:08.744073Z",
     "start_time": "2022-03-09T14:46:08.451860Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  7, 12, ...,  4,  4,  4],\n",
       "       [ 4,  4,  4, ...,  4,  4,  4],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_preds.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b7e14ce2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T14:46:24.897422Z",
     "start_time": "2022-03-09T14:46:24.848562Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2048, 15)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "be2efbb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T14:46:25.637598Z",
     "start_time": "2022-03-09T14:46:25.586219Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2048, 15])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2f925caf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T14:46:27.280015Z",
     "start_time": "2022-03-09T14:46:27.236062Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_class = label.argmax(-1)\n",
    "label_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c880ac53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T14:46:30.316276Z",
     "start_time": "2022-03-09T14:46:30.274449Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  7, 12, ...,  4,  4,  4],\n",
       "       [ 4,  4,  4, ...,  4,  4,  4]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_class = ensemble_preds[step:step + batch_len].argmax(-1)\n",
    "ensemble_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a0eb5edc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T14:48:09.764229Z",
     "start_time": "2022-03-09T14:48:09.721443Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01025390625, 0.01171875]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_score = [accuracy_score(a, b) for a, b in zip(label_class, ensemble_class)]\n",
    "batch_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a601429c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T14:47:41.448935Z",
     "start_time": "2022-03-09T14:47:41.410195Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B72D0B4875B4', '74CA2200A7FB']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_ids = train_text_ids[:2]\n",
    "batch_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7e8a70f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T15:06:30.689058Z",
     "start_time": "2022-03-09T15:06:30.646990Z"
    }
   },
   "outputs": [],
   "source": [
    "train_accs[start_idx:end_idx] = batch_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "30da15d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T15:06:34.064236Z",
     "start_time": "2022-03-09T15:06:34.023069Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01025391, 0.01171875, 0.        , ..., 0.        , 0.        ,\n",
       "       0.        ], dtype=float32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "982ebd63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T15:06:47.192523Z",
     "start_time": "2022-03-09T15:06:47.151251Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_ids</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B72D0B4875B4</td>\n",
       "      <td>0.010254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74CA2200A7FB</td>\n",
       "      <td>0.011719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60517BFCAA0B</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3C11CE4316CA</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>656C7C849144</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12449</th>\n",
       "      <td>CC3B51667B02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12450</th>\n",
       "      <td>4E8DD68C42AF</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12451</th>\n",
       "      <td>3C54223FAFB9</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12452</th>\n",
       "      <td>399030918355</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12453</th>\n",
       "      <td>B9B45507DDF8</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12454 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           text_ids     score\n",
       "0      B72D0B4875B4  0.010254\n",
       "1      74CA2200A7FB  0.011719\n",
       "2      60517BFCAA0B  0.000000\n",
       "3      3C11CE4316CA  0.000000\n",
       "4      656C7C849144  0.000000\n",
       "...             ...       ...\n",
       "12449  CC3B51667B02  0.000000\n",
       "12450  4E8DD68C42AF  0.000000\n",
       "12451  3C54223FAFB9  0.000000\n",
       "12452  399030918355  0.000000\n",
       "12453  B9B45507DDF8  0.000000\n",
       "\n",
       "[12454 rows x 2 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame({'text_ids': train_text_ids, 'score': train_accs})\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bc0cd499",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T14:48:57.581727Z",
     "start_time": "2022-03-09T14:48:57.541789Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['74CA2200A7FB']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.query('score > 0.011').text_ids.values.tolist()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "261.033px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
