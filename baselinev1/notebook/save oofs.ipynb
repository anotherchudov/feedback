{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13b89802",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T05:32:29.895241Z",
     "start_time": "2022-03-10T05:32:29.891923Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "DATASET_PATH = ('../../../feedback-prize-2021')\n",
    "\n",
    "sys.path.insert(0, '../codes/new_transformers_branch/transformers/src')\n",
    "sys.path.append('../codes')\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77bd1ea6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T05:32:30.711043Z",
     "start_time": "2022-03-10T05:32:30.137501Z"
    },
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-02-20T05:05:17.067581Z",
     "iopub.status.busy": "2022-02-20T05:05:17.066064Z",
     "iopub.status.idle": "2022-02-20T05:05:19.721931Z",
     "shell.execute_reply": "2022-02-20T05:05:19.721361Z",
     "shell.execute_reply.started": "2022-02-20T04:49:57.249100Z"
    },
    "papermill": {
     "duration": 2.668516,
     "end_time": "2022-02-20T05:05:19.722096",
     "exception": false,
     "start_time": "2022-02-20T05:05:17.053580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f3e3f120a90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import re\n",
    "import pickle\n",
    "import random\n",
    "import easydict\n",
    "\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from new_transformers import DebertaV2TokenizerFast\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.autograd.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7223963f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T05:32:32.234305Z",
     "start_time": "2022-03-10T05:32:30.712194Z"
    }
   },
   "outputs": [],
   "source": [
    "from module.metric import calc_acc, process_sample, make_match_dict\n",
    "\n",
    "from module.utils import get_data_files\n",
    "from module.dataset import get_dataloader\n",
    "from module.loss import get_criterion\n",
    "from module.optimizer import get_optimizer\n",
    "from module.scheduler import get_scheduler\n",
    "from model.model import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20ab89b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T05:32:32.237563Z",
     "start_time": "2022-03-10T05:32:32.235494Z"
    }
   },
   "outputs": [],
   "source": [
    "# global variables\n",
    "seed = 0\n",
    "\n",
    "# change here\n",
    "ckpt_path = '../input/feedbackv2/debertav1/*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c602972",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T05:32:32.256829Z",
     "start_time": "2022-03-10T05:32:32.238558Z"
    }
   },
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({'model': 'microsoft/deberta-v3-large-ducky',\n",
    "                          'grad_checkpt': True,\n",
    "                          'cnn1d': False,\n",
    "                          'extra_dense': False,\n",
    "                          'device': 0,\n",
    "                          'ddp': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e81ce9fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T05:32:52.296403Z",
     "start_time": "2022-03-10T05:32:52.290601Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\"\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b19b23b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T05:33:30.456625Z",
     "start_time": "2022-03-10T05:33:30.411443Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 0\n",
    "val_fold = 0\n",
    "\n",
    "with open('../data_file/id_to_ix_map.pickle', 'rb') as f:\n",
    "    id_to_ix_map = {x.split('/')[-1].split('.')[0]: y for x, y in pickle.load(f).items()}\n",
    "with open('../data_file/data_splits.pickle', 'rb') as f:\n",
    "    data_splits = pickle.load(f)\n",
    "\n",
    "val_files_all = []\n",
    "for val_fold in range(5):\n",
    "    train_ids = [\n",
    "        id_to_ix_map[x] \n",
    "        for fold in range(5) if fold != val_fold \n",
    "        for x in data_splits[seed][250]['normed'][fold]\n",
    "    ]\n",
    "    val_files = data_splits[seed][250]['normed'][val_fold]\n",
    "    val_ids = [id_to_ix_map[x] for x in val_files]\n",
    "    val_files_all.append(val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37d2373e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T05:35:07.941179Z",
     "start_time": "2022-03-10T05:35:07.927786Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-20T05:05:37.943920Z",
     "iopub.status.busy": "2022-02-20T05:05:37.943325Z",
     "iopub.status.idle": "2022-02-20T05:05:38.105465Z",
     "shell.execute_reply": "2022-02-20T05:05:38.104913Z",
     "shell.execute_reply.started": "2022-02-20T04:50:18.063170Z"
    },
    "papermill": {
     "duration": 0.185206,
     "end_time": "2022-02-20T05:05:38.105599",
     "exception": false,
     "start_time": "2022-02-20T05:05:37.920393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, files):\n",
    "        tokenizer = DebertaV2TokenizerFast.from_pretrained('microsoft/deberta-v3-large')\n",
    "        tokenizer.model_max_length = 2048\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        self.texts = {}\n",
    "        self.raw_texts = {}\n",
    "        \n",
    "        for file in files:\n",
    "            file_name = osp.join(DATASET_PATH, 'train', file + '.txt')\n",
    "            with open(file_name) as f:\n",
    "                text = f.read().strip()\n",
    "                self.texts[file] = fix_text(text)\n",
    "                self.raw_texts[file] = text\n",
    "                \n",
    "        self.text_ids = list(self.texts.keys())\n",
    "        self.space_regex = re.compile('[\\s\\n]')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text_ids)\n",
    "    \n",
    "    def __getitem__(self, ix):\n",
    "        tokens_array = np.zeros(2048, 'i8')\n",
    "        mask_array = np.zeros(2048, 'f4')\n",
    "        offsets_array = np.zeros((2048, 2), 'i4')\n",
    "        \n",
    "        text = self.texts[self.text_ids[ix]]\n",
    "        raw_text = self.raw_texts[self.text_ids[ix]]\n",
    "        text_id = self.text_ids[ix]\n",
    "        \n",
    "        tokenizer_outs = self.tokenizer(text, return_offsets_mapping=True)\n",
    "        tokenizer_outs['input_ids'] = [x if x != 126861 else 128000 for x in tokenizer_outs['input_ids']]\n",
    "        \n",
    "        tokens = np.array(tokenizer_outs['input_ids'], 'i8')\n",
    "        mask = np.array(tokenizer_outs['attention_mask'], 'f4')\n",
    "        offsets = np.vstack(tokenizer_outs['offset_mapping']).astype('i4')\n",
    "        \n",
    "        tokens_array[:len(tokens)] = tokens\n",
    "        tokens_array[len(tokens):] = 0\n",
    "        mask_array[:len(tokens)] = mask\n",
    "        mask_array[len(tokens):] = 0\n",
    "        offsets_array[:len(tokens)] = offsets\n",
    "        offsets_array[len(tokens):] = 0\n",
    "        \n",
    "        index_map = []\n",
    "        current_word = 0\n",
    "        blank = False\n",
    "        for char_ix in range(raw_text.index(raw_text.strip()[0]), len(raw_text)):\n",
    "            if self.space_regex.match(raw_text[char_ix]) is not None:\n",
    "                blank = True\n",
    "            elif blank:\n",
    "                current_word += 1\n",
    "                blank = False\n",
    "            index_map.append(current_word)\n",
    "        \n",
    "        return tokens_array, mask_array, offsets_array, index_map, text_id, len(tokens)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "421bd62e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T05:44:59.158433Z",
     "start_time": "2022-03-10T05:44:59.154012Z"
    }
   },
   "outputs": [],
   "source": [
    "first_batch = True\n",
    "def collate_fn(ins):\n",
    "    global first_batch\n",
    "    if first_batch:\n",
    "        max_len = 2048\n",
    "        first_batch = False\n",
    "    else:\n",
    "        max_len = (max(x[-1] for x in ins) + 7) // 8 * 8\n",
    "    return tuple(\n",
    "        torch.from_numpy(np.concatenate([ins[z][x][None, :max_len] for z in range(len(ins))])) \n",
    "        for x \n",
    "        in range(len(ins[0]) - 3)) + \\\n",
    "        ([x[-3] for x in ins], [x[-2] for x in ins], np.array([x[-1] for x in ins]),)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf7da19d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T05:35:08.601862Z",
     "start_time": "2022-03-10T05:35:08.597707Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-20T05:05:38.132364Z",
     "iopub.status.busy": "2022-02-20T05:05:38.131501Z",
     "iopub.status.idle": "2022-02-20T05:05:38.133363Z",
     "shell.execute_reply": "2022-02-20T05:05:38.133816Z",
     "shell.execute_reply.started": "2022-02-20T04:50:37.096190Z"
    },
    "papermill": {
     "duration": 0.021113,
     "end_time": "2022-02-20T05:05:38.133936",
     "exception": false,
     "start_time": "2022-02-20T05:05:38.112823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def map_span_to_word_indices(span, index_map, bounds):\n",
    "    return (index_map[bounds[span[0], 0]], \n",
    "            index_map[bounds[span[1], 1] - 1])\n",
    "\n",
    "def calc_entity_score(span, ps, c):\n",
    "    s, e = span\n",
    "    score = (ps[s, c * 2 - 1] + ps[s + 1: e + 1, c * 2].sum())/(e - s + 1)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9af6fdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T05:35:09.656713Z",
     "start_time": "2022-03-10T05:35:09.651867Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_entities(ps, n):\n",
    "    cat_ps = ps.argmax(-1)\n",
    "    all_entities = {}\n",
    "    current_cat = None\n",
    "    current_start = None\n",
    "    for ix in range(1, n - 1):\n",
    "        # B-LABEL(1, 3, 5, 7, ...)\n",
    "        if cat_ps[ix] % 2 == 1:\n",
    "            if current_cat is not None:\n",
    "                if current_cat not in all_entities:\n",
    "                    all_entities[current_cat] = []\n",
    "                all_entities[current_cat].append((current_start, ix - 1))\n",
    "            current_cat = (cat_ps[ix] + 1) // 2\n",
    "            current_start = ix\n",
    "        # O\n",
    "        elif cat_ps[ix] == 0:\n",
    "            if current_cat is not None:\n",
    "                if current_cat not in all_entities:\n",
    "                    all_entities[current_cat] = []\n",
    "                all_entities[current_cat].append((current_start, ix - 1))\n",
    "            current_cat = None\n",
    "        elif current_cat is not None and cat_ps[ix] != current_cat * 2:\n",
    "            if current_cat not in all_entities:\n",
    "                all_entities[current_cat] = []\n",
    "            all_entities[current_cat].append((current_start, ix - 1))\n",
    "            current_cat = None\n",
    "    if current_cat is not None:\n",
    "        if current_cat not in all_entities:\n",
    "            all_entities[current_cat] = []\n",
    "        all_entities[current_cat].append((current_start, ix))\n",
    "\n",
    "    return all_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1cd3352",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T05:35:41.466444Z",
     "start_time": "2022-03-10T05:35:33.108457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Ducky Modified DebertaV2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = get_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e60b377",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T05:39:11.098056Z",
     "start_time": "2022-03-10T05:39:11.095747Z"
    }
   },
   "outputs": [],
   "source": [
    "fix_text = lambda x: x.replace('\\n', '‽')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f3d823d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T05:59:47.742234Z",
     "start_time": "2022-03-10T05:45:01.968331Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3121 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3139 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3096 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3098 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_names = ['None', 'Lead', 'Position', 'Evidence', 'Claim',\n",
    "               'Concluding Statement', 'Counterclaim', 'Rebuttal']\n",
    "\n",
    "\n",
    "outs_f = []\n",
    "bounds_f = []\n",
    "token_nums_f = []\n",
    "word_indices_f = []\n",
    "sample_ids_f = []\n",
    "\n",
    "checkpoints = os.listdir('../result/random_deletion_0.1')\n",
    "checkpoints = sorted(checkpoints, key=lambda checkpoint: checkpoint[checkpoint.index('fold') + 4])\n",
    "checkpoints = [osp.join('../result/random_deletion_0.1', checkpoint) for checkpoint in checkpoints]\n",
    "\n",
    "\n",
    "for val_fold in range(5):\n",
    "    val_files = val_files_all[val_fold]\n",
    "    dataset = Dataset(val_files)\n",
    "    dataset = torch.utils.data.DataLoader(dataset, collate_fn=collate_fn,\n",
    "                                      batch_size=1, num_workers=2, shuffle=False)\n",
    "\n",
    "    model.eval().cuda();\n",
    "\n",
    "    all_outs = np.zeros((len(val_files), 2048, 15), 'f4')\n",
    "    all_bounds = np.zeros((len(val_files), 2048, 2), 'i4')\n",
    "    all_token_nums = np.zeros(len(val_files), 'i4')\n",
    "    all_word_indices = []\n",
    "    all_sample_ids = []\n",
    "    model.load_state_dict(torch.load(checkpoints[val_fold]));\n",
    "    ix = 0\n",
    "    for batch in tqdm(dataset, leave=False):\n",
    "        tokens, mask, bounds, word_indices, sample_ids, num_tokens = batch\n",
    "        batch_size, batch_len = tokens.shape[:2]\n",
    "        with torch.no_grad():\n",
    "            # outs = t.softmax(model(tokens.cuda(), mask.cuda()), -1)\n",
    "            outs = model(tokens.cuda(), mask.cuda())\n",
    "        all_outs[ix: ix + batch_size, :batch_len] += outs.cpu().numpy()\n",
    "        all_bounds[ix: ix + batch_size, :batch_len] = bounds\n",
    "        all_token_nums[ix: ix + batch_size] = num_tokens\n",
    "        all_word_indices.extend(word_indices)\n",
    "        all_sample_ids.extend(sample_ids)\n",
    "        ix += batch_size\n",
    "    \n",
    "    outs_f.append(all_outs)\n",
    "    bounds_f.append(all_bounds)\n",
    "    token_nums_f.append(all_token_nums)\n",
    "    word_indices_f += all_word_indices\n",
    "    sample_ids_f += all_sample_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a84455ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T06:15:44.843052Z",
     "start_time": "2022-03-10T06:15:44.383341Z"
    }
   },
   "outputs": [],
   "source": [
    "all_outs = np.concatenate(outs_f)\n",
    "all_bounds = np.concatenate(bounds_f)\n",
    "all_token_nums = np.concatenate(token_nums_f)\n",
    "all_word_indices = word_indices_f\n",
    "all_sample_ids = sample_ids_f\n",
    "all_texts = {}\n",
    "for sid in all_sample_ids:\n",
    "    fname = osp.join(f'{DATASET_PATH}/train/', sid+'.txt')\n",
    "    with open(fname) as f:\n",
    "        all_texts[sid] = f.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac486d5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T06:15:47.741593Z",
     "start_time": "2022-03-10T06:15:47.737519Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15594, 2048, 15), (15594, 2048, 2), (15594,), 15594, 15594)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_outs.shape, all_bounds.shape, all_token_nums.shape, len(all_word_indices), len(all_sample_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e44c0d32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T06:15:55.013618Z",
     "start_time": "2022-03-10T06:15:55.011545Z"
    }
   },
   "outputs": [],
   "source": [
    "oofs = {\n",
    "    'all_outs': all_outs,\n",
    "    'all_bounds': all_bounds,\n",
    "    'all_token_nums': all_token_nums,\n",
    "    'all_word_indices': all_word_indices,\n",
    "    'all_sample_ids': all_sample_ids,\n",
    "    'all_texts': all_texts\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d72b7826",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T06:16:07.939986Z",
     "start_time": "2022-03-10T06:16:05.688050Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(oofs, open('oofs_ducky.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 117.383581,
   "end_time": "2022-02-20T05:07:06.356701",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-20T05:05:08.973120",
   "version": "2.3.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
