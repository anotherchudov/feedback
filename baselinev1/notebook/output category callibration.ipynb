{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fc1922f",
   "metadata": {},
   "source": [
    "# Callibration\n",
    "\n",
    "- input   0 0 1 0 0 2 2 2\n",
    "- output  0 0 1 2 2 2 2 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c0b89c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T05:40:10.543612Z",
     "start_time": "2022-03-15T05:40:10.541084Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "DATASET_PATH = ('../../../feedback-prize-2021')\n",
    "\n",
    "sys.path.insert(0, '../codes/new_transformers_branch/transformers/src')\n",
    "sys.path.append('../codes')\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a35dd0e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T05:40:11.144904Z",
     "start_time": "2022-03-15T05:40:10.544288Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import re\n",
    "import pickle\n",
    "import random\n",
    "import easydict\n",
    "import copy\n",
    "\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from new_transformers import DebertaV2TokenizerFast\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3486b14",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e62ee9d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T05:40:11.768278Z",
     "start_time": "2022-03-15T05:40:11.146198Z"
    }
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "data = h5py.File(f'../data_file/deberta_spm_data_v2.h5py')\n",
    "labels = data[f'cbio_labels']\n",
    "labels = np.argmax(labels, -1)\n",
    "labels = labels[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8bd9e6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T05:40:12.350855Z",
     "start_time": "2022-03-15T05:40:11.769242Z"
    }
   },
   "outputs": [],
   "source": [
    "token_n_list = []\n",
    "for num_tokens in data['num_tokens']:\n",
    "    token_n_list.append(num_tokens[0])\n",
    "    \n",
    "token_n_list = np.array(token_n_list[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb60287e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T05:40:12.396521Z",
     "start_time": "2022-03-15T05:40:12.351679Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "with open('../data_file/data_splits.pickle', 'rb') as f:\n",
    "    data_splits = pickle.load(f)\n",
    "\n",
    "with open('../data_file/id_to_ix_map.pickle', 'rb') as f:\n",
    "    id_to_ix_map = {x.split('/')[-1].split('.')[0]: y for x, y in pickle.load(f).items()}\n",
    "\n",
    "train_idx = []\n",
    "valid_idx = []\n",
    "for val_fold in range(5):\n",
    "    train_text_ids = [text_id for fold in range(5) if fold != val_fold for text_id in data_splits[seed][250]['normed'][fold]]\n",
    "    val_text_ids = data_splits[seed][250]['normed'][val_fold]\n",
    "    \n",
    "    train_fold_idx = [id_to_ix_map[text_id] for text_id in train_text_ids]\n",
    "    val_fold_idx = [id_to_ix_map[text_id] for text_id in val_text_ids]\n",
    "    \n",
    "    train_idx.append(train_fold_idx)\n",
    "    valid_idx.append(val_fold_idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bca59da",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5b54b7",
   "metadata": {},
   "source": [
    "## adding +1 to continuous sequence to learn position bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe47c389",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T05:40:12.401437Z",
     "start_time": "2022-03-15T05:40:12.397420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+1 will be added at 92 index with length 6\n",
      "before [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "after  [6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 6 6 6 6 6 6 6 6 6 6]\n"
     ]
    }
   ],
   "source": [
    "test = copy.deepcopy(labels[0])\n",
    "token_n = token_n_list[0]\n",
    "\n",
    "# padding\n",
    "test[token_n:] = -1\n",
    "\n",
    "# place where zero class will be assigned\n",
    "zero_n = random.randint(1, 20)\n",
    "zero_start_i = random.randint(1, token_n - 1)\n",
    "zero_end_i = min(zero_start_i + zero_n, token_n - 1)\n",
    "\n",
    "# place that will be printed\n",
    "print_start_i = max(zero_start_i - 10, 0)\n",
    "print_end_i = min(zero_end_i + 10, token_n - 1)\n",
    "\n",
    "print(f'+1 will be added at {zero_start_i} index with length {zero_n}')\n",
    "print(f'before {test[print_start_i:print_end_i]}')\n",
    "\n",
    "# augmentation\n",
    "test[zero_start_i:zero_end_i] += 1\n",
    "test = np.clip(test, 0, 14)\n",
    "\n",
    "print(f'after  {test[print_start_i:print_end_i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2aba529",
   "metadata": {},
   "source": [
    "### Replacing category randomly by continuous 0 (length is 1 - 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dace83af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T05:40:12.412907Z",
     "start_time": "2022-03-15T05:40:12.402177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 category will be added at 45 index with length 5\n",
      "before [2 2 2 2 2 0 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 7 8 8 8]\n",
      "after  [2 2 2 2 2 0 3 4 4 4 0 0 0 0 0 4 4 4 4 4 4 7 8 8 8]\n"
     ]
    }
   ],
   "source": [
    "test = copy.deepcopy(labels[0])\n",
    "token_n = token_n_list[0]\n",
    "\n",
    "# padding\n",
    "test[token_n:] = -1\n",
    "\n",
    "# place where zero class will be assigned\n",
    "zero_n = random.randint(1, 5)\n",
    "zero_start_i = random.randint(1, token_n - 1)\n",
    "zero_end_i = min(zero_start_i + zero_n, token_n - 1)\n",
    "\n",
    "# place that will be printed\n",
    "print_start_i = max(zero_start_i - 10, 0)\n",
    "print_end_i = min(zero_end_i + 10, token_n - 1)\n",
    "\n",
    "print(f'0 category will be added at {zero_start_i} index with length {zero_n}')\n",
    "print(f'before {test[print_start_i:print_end_i]}')\n",
    "\n",
    "# augmentation\n",
    "test[zero_start_i:zero_end_i] = 0\n",
    "\n",
    "print(f'after  {test[print_start_i:print_end_i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df9a984",
   "metadata": {},
   "source": [
    "### Replacing category randomly by any category (length is 30 - 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c864c29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T05:40:12.424251Z",
     "start_time": "2022-03-15T05:40:12.413877Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category replacement will be happend at 61 times\n",
      "showing at index 37\n",
      "before [2 2 2 0 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 7]\n",
      "after  [ 2  2  2  0 14  4  2  4  4  4  5  9  4  6 12  4  0  4  4  7]\n"
     ]
    }
   ],
   "source": [
    "test = copy.deepcopy(labels[0])\n",
    "token_n = token_n_list[0]\n",
    "\n",
    "# padding\n",
    "test[token_n:] = -1\n",
    "\n",
    "# place where zero class will be assigned\n",
    "replace_n = random.randint(30, 100)\n",
    "replace_idx = np.random.choice(range(1, token_n - 1), size=replace_n, replace=False)\n",
    "replace_cats = np.random.choice(range(0, 15), size=replace_n, replace=True)\n",
    "\n",
    "# place that will be printed\n",
    "print_start_i = max(replace_idx[0] - 10, 0)\n",
    "print_end_i = min(replace_idx[0] + 10, token_n - 1)\n",
    "\n",
    "print(f'category replacement will be happend at {replace_n} times')\n",
    "print(f'showing at index {print_start_i}')\n",
    "print(f'before {test[print_start_i:print_end_i]}')\n",
    "\n",
    "# augmentation\n",
    "test[replace_idx] = replace_cats\n",
    "\n",
    "print(f'after  {test[print_start_i:print_end_i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580c1706",
   "metadata": {},
   "source": [
    "### Replace starting category as even number (ex: 122 -> 222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2230a444",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T05:40:12.444459Z",
     "start_time": "2022-03-15T05:40:12.425856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4 will be replaced\n",
      "example: category 5 will be replaced to 6\n",
      "before [8 8 8 8 8 5 6 6 6 6]\n",
      "after  [8 8 8 8 8 6 6 6 6 6]\n"
     ]
    }
   ],
   "source": [
    "test = copy.deepcopy(labels[0])\n",
    "token_n = token_n_list[0]\n",
    "\n",
    "# padding\n",
    "test[token_n:] = -1\n",
    "\n",
    "# place where odd category exist\n",
    "odd_category = [1, 3, 5, 7, 9, 11, 13]\n",
    "\n",
    "odd_cat_idx = [i for i, category in enumerate(test) if category in odd_category]\n",
    "replace_n = random.randint(1, len(odd_cat_idx))\n",
    "odd_cat_idx = np.random.choice(odd_cat_idx, size=replace_n, replace=False)\n",
    "\n",
    "# place that will be printed\n",
    "print_start_i = max(odd_cat_idx[0] - 5, 0)\n",
    "print_end_i = min(odd_cat_idx[0] + 5, token_n - 1)\n",
    "\n",
    "print(f'total {replace_n} will be replaced')\n",
    "print(f'example: category {test[odd_cat_idx[0]]} will be replaced to {test[odd_cat_idx[0]] + 1}')\n",
    "print(f'before {test[print_start_i:print_end_i]}')\n",
    "\n",
    "# augmentation\n",
    "test[odd_cat_idx] += 1\n",
    "\n",
    "print(f'after  {test[print_start_i:print_end_i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdf9e1b",
   "metadata": {},
   "source": [
    "### Replace starting category to different category (ex: 122 -> 322)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d63c093a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T05:40:12.459746Z",
     "start_time": "2022-03-15T05:40:12.445721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3 will be replaced\n",
      "category 3 will be replaced to 13\n",
      "before [2 2 2 2 0 3 4 4 4 4]\n",
      "after  [ 2  2  2  2  0 13  4  4  4  4]\n"
     ]
    }
   ],
   "source": [
    "test = copy.deepcopy(labels[0])\n",
    "token_n = token_n_list[0]\n",
    "\n",
    "# padding\n",
    "test[token_n:] = -1\n",
    "\n",
    "# place where odd category exist\n",
    "odd_category = [1, 3, 5, 7, 9, 11, 13]\n",
    "odd_cat_idx = [i for i, category in enumerate(test) if category in odd_category]\n",
    "\n",
    "replace_n = random.randint(1, len(odd_cat_idx))\n",
    "odd_cat_idx = np.random.choice(odd_cat_idx, size=replace_n, replace=False)\n",
    "\n",
    "replace_cats = []\n",
    "for odd_cat_i in odd_cat_idx:\n",
    "    current_cat = test[odd_cat_i]\n",
    "    odd_sample = copy.deepcopy(odd_category)\n",
    "    odd_sample.remove(current_cat)\n",
    "    replace_cats.append(random.choice(odd_sample))\n",
    "    \n",
    "replace_cats = np.array(replace_cats)\n",
    "\n",
    "# place that will be printed\n",
    "print_start_i = max(odd_cat_idx[0] - 5, 0)\n",
    "print_end_i = min(odd_cat_idx[0] + 5, token_n - 1)\n",
    "\n",
    "print(f'total {replace_n} will be replaced')\n",
    "print(f'category {test[odd_cat_idx[0]]} will be replaced to {replace_cats[0]}')\n",
    "print(f'before {test[print_start_i:print_end_i]}')\n",
    "\n",
    "# augmentation\n",
    "test[odd_cat_idx] = replace_cats\n",
    "\n",
    "print(f'after  {test[print_start_i:print_end_i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f10217",
   "metadata": {},
   "source": [
    "### Starting Point (`B` in BIO label) imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4b9a1f11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T12:47:23.782140Z",
     "start_time": "2022-03-15T12:47:23.769456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 13 will be replaced\n",
      "index [253] will be replaced to 9\n",
      "before [10 10 10 10 10 10 10 10 10 10]\n",
      "after  [10 10 10 10 10  9 10 10 10 10]\n"
     ]
    }
   ],
   "source": [
    "test = copy.deepcopy(labels[0])\n",
    "token_n = token_n_list[0]\n",
    "\n",
    "# padding\n",
    "test[token_n:] = -1\n",
    "\n",
    "# place where odd category exist\n",
    "even_category = [2, 4, 6, 8, 10, 12, 14]\n",
    "even_cat_idx = [i for i, category in enumerate(test) if category in even_category]\n",
    "\n",
    "max_n = max(1, len(even_cat_idx) // 20)\n",
    "replace_n = random.randint(1, max_n)\n",
    "even_cat_idx = np.random.choice(even_cat_idx, size=replace_n, replace=False)\n",
    "\n",
    "replace_idx = []\n",
    "for even_cat_i in even_cat_idx:\n",
    "    if test[even_cat_i] - 1 == test[even_cat_i - 1]:\n",
    "        continue\n",
    "    \n",
    "    replace_idx.append(even_cat_i)\n",
    "    \n",
    "replace_idx = np.array(replace_idx)\n",
    "\n",
    "# place that will be printed\n",
    "print_start_i = max(replace_idx[0] - 5, 0)\n",
    "print_end_i = min(replace_idx[0] + 5, token_n - 1)\n",
    "\n",
    "print(f'total {replace_n} will be replaced')\n",
    "print(f'index {[replace_idx[0]]} will be replaced to {test[replace_idx[0]] - 1}')\n",
    "print(f'before {test[print_start_i:print_end_i]}')\n",
    "\n",
    "# augmentation\n",
    "test[replace_idx] -= 1\n",
    "\n",
    "print(f'after  {test[print_start_i:print_end_i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f469c07",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f6acc9ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T14:41:00.902467Z",
     "start_time": "2022-03-15T14:41:00.878644Z"
    },
    "code_folding": [
     8,
     18,
     55,
     69
    ]
   },
   "outputs": [],
   "source": [
    "class CategoryDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, labels, token_n_list):\n",
    "        self.labels = labels\n",
    "        self.token_n_list = token_n_list\n",
    "        \n",
    "        self.odd_category = [1, 3, 5, 7, 9, 11, 13]\n",
    "        self.even_category = [2, 4, 6, 8, 10, 12, 14]\n",
    "        \n",
    "    def position_bias(self, label, token_n):\n",
    "        replace_n = random.randint(10, 20)\n",
    "        replace_start_i = random.randint(1, token_n - 1)\n",
    "        replace_end_i = min(replace_start_i + replace_n, token_n - 1)\n",
    "        \n",
    "        label[replace_start_i:replace_end_i] += 1\n",
    "        label = np.clip(label, 0, 14)\n",
    "        \n",
    "        return label\n",
    "\n",
    "    def replace_with_zero(self, label, token_n):\n",
    "        \"\"\"\"\"\"\n",
    "        zero_n = random.randint(1, 5)\n",
    "        zero_start_i = random.randint(1, token_n - 1)\n",
    "        zero_end_i = min(zero_start_i + zero_n, token_n - 1)\n",
    "        \n",
    "        label[zero_start_i:zero_end_i] = 0\n",
    "        \n",
    "        return label\n",
    "    \n",
    "    def add_starting_point(self, label, target, token_n):\n",
    "        \n",
    "        even_cat_idx = [i for i, category in enumerate(label) if category in self.even_category]\n",
    "        if len(even_cat_idx) == 0:\n",
    "            return label, target\n",
    "        \n",
    "        max_n = min(5, len(even_cat_idx) // 20)\n",
    "        replace_n = random.randint(1, max_n)\n",
    "        even_cat_idx = np.random.choice(even_cat_idx, size=replace_n, replace=False)\n",
    "\n",
    "        replace_idx = []\n",
    "        for even_cat_i in even_cat_idx:\n",
    "            if label[even_cat_i] - 1 == label[even_cat_i - 1]:\n",
    "                continue\n",
    "\n",
    "            replace_idx.append(even_cat_i)\n",
    "\n",
    "        replace_idx = np.array(replace_idx)\n",
    "        if len(replace_idx) == 0:\n",
    "            return label, target\n",
    "        \n",
    "        # augmentation\n",
    "        label[replace_idx] -= 1\n",
    "        target[replace_idx] -= 1\n",
    "        \n",
    "        return label, target\n",
    "    \n",
    "    def b_to_i_label(self, label, token_n):\n",
    "        \"\"\"\"\"\"\n",
    "        odd_cat_idx = [i for i, category in enumerate(label) if category in self.odd_category]\n",
    "        if len(odd_cat_idx) == 0:\n",
    "            return label\n",
    "\n",
    "        replace_n = random.randint(1, len(odd_cat_idx))\n",
    "        replace_n = min(2, replace_n)\n",
    "        odd_cat_idx = np.random.choice(odd_cat_idx, size=replace_n, replace=False)\n",
    "\n",
    "        label[odd_cat_idx] += 1\n",
    "        \n",
    "        return label\n",
    "    \n",
    "    def replace_b_label(self, label, token_n):\n",
    "        \"\"\"\"\"\"\n",
    "        odd_cat_idx = [i for i, category in enumerate(label) if category in self.odd_category]\n",
    "        if len(odd_cat_idx) == 0:\n",
    "            return label\n",
    "\n",
    "        replace_n = random.randint(1, len(odd_cat_idx))\n",
    "        replace_n = min(2, replace_n)\n",
    "        odd_cat_idx = np.random.choice(odd_cat_idx, size=replace_n, replace=False)\n",
    "\n",
    "        replace_cats = []\n",
    "        for odd_cat_i in odd_cat_idx:\n",
    "            current_cat = label[odd_cat_i]\n",
    "            odd_sample = copy.deepcopy(self.odd_category)\n",
    "            odd_sample.remove(current_cat)\n",
    "            replace_cats.append(random.choice(odd_sample))\n",
    "\n",
    "        replace_cats = np.array(replace_cats)\n",
    "\n",
    "        # augmentation\n",
    "        label[odd_cat_idx] = replace_cats\n",
    "        \n",
    "        return label\n",
    "    \n",
    "    def replace_with_random_label(self, label, token_n):\n",
    "        \"\"\"\"\"\"\n",
    "        replace_n = random.randint(10, 50)\n",
    "        replace_idx = np.random.choice(range(1, token_n - 1), size=replace_n, replace=False)\n",
    "        replace_cats = np.random.choice(range(0, 15), size=replace_n, replace=True)\n",
    "\n",
    "        label[replace_idx] = replace_cats\n",
    "\n",
    "        return label\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        targets = copy.deepcopy(self.labels[idx])\n",
    "        inputs = copy.deepcopy(targets)\n",
    "        token_n = self.token_n_list[idx]\n",
    "\n",
    "        # augmentation\n",
    "        if random.random() < 0.99:\n",
    "            inputs, targets = self.add_starting_point(inputs, targets, token_n)\n",
    "            inputs = self.position_bias(inputs, token_n)\n",
    "            inputs = self.replace_with_zero(inputs, token_n)\n",
    "            inputs = self.b_to_i_label(inputs, token_n)\n",
    "            inputs = self.replace_b_label(inputs, token_n)\n",
    "            inputs = self.replace_with_random_label(inputs, token_n)\n",
    "\n",
    "        # padding\n",
    "        inputs[token_n:] = 15\n",
    "        targets[token_n:] = 15\n",
    "        \n",
    "        return inputs, targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4f34b2",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "39eef4b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T14:41:02.003858Z",
     "start_time": "2022-03-15T14:41:01.994657Z"
    }
   },
   "outputs": [],
   "source": [
    "class Callibration(nn.Module):\n",
    "    def __init__(self,\n",
    "                 hidden_size=128,\n",
    "                 n_layers=2,\n",
    "                 device='cuda:0'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.device = device\n",
    "\n",
    "        self.embedding = nn.Embedding(16, hidden_size, padding_idx=15)\n",
    "        self.lstm = nn.LSTM(hidden_size,\n",
    "                            hidden_size,\n",
    "                            n_layers,\n",
    "                            bidirectional=True,\n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, 16)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        h = torch.zeros(self.n_layers * 2, batch_size, self.hidden_size)\n",
    "        h = h.to(self.device)\n",
    "\n",
    "        c = torch.zeros(self.n_layers * 2, batch_size, self.hidden_size)\n",
    "        c = c.to(self.device)\n",
    "\n",
    "        return (h, c)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.size()\n",
    "        out = self.embedding(x)\n",
    "        \n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        out, hidden = self.lstm(out, hidden)\n",
    "        \n",
    "        out = out.contiguous().view(batch_size, -1, self.hidden_size * 2)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcb809c",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "82ea9d14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T14:41:02.948174Z",
     "start_time": "2022-03-15T14:41:02.945875Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "484948ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T14:41:08.134185Z",
     "start_time": "2022-03-15T14:41:08.131009Z"
    }
   },
   "outputs": [],
   "source": [
    "save_path = '../result/callibration_all'\n",
    "\n",
    "if not osp.exists(save_path):\n",
    "    os.makedirs(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "83ec7bb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T15:36:59.402810Z",
     "start_time": "2022-03-15T14:50:06.997075Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53fc5af03dca4d0abc4979a025f7ce58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/390 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ TRAIN ] fold 1 epoch 1 loss: 1.1601\n",
      "[ TRAIN ] fold 1 epoch 1 loss: 0.6316\n",
      "[ TRAIN ] fold 1 epoch 1 loss: 0.4395\n",
      "[ TRAIN ] fold 1 epoch 1 loss: 0.3382\n",
      "[ TRAIN ] fold 1 epoch 1 loss: 0.2759\n",
      "[ TRAIN ] fold 1 epoch 1 loss: 0.2336\n",
      "[ TRAIN ] fold 1 epoch 1 loss: 0.2030\n",
      "[ TRAIN ] fold 1 epoch 1 loss: 0.1798\n",
      "[ TRAIN ] fold 1 epoch 1 loss: 0.1616\n",
      "[ TRAIN ] fold 1 epoch 1 loss: 0.1469\n",
      "[ TRAIN ] fold 1 epoch 1 loss: 0.1348\n",
      "[ TRAIN ] fold 1 epoch 1 loss: 0.1247\n",
      "[ TRAIN ] fold 1 epoch 1 loss: 0.1160\n",
      "[ TRAIN ] fold 1 epoch 1 loss: 0.1086\n",
      "[ TRAIN ] fold 1 epoch 1 loss: 0.1021\n",
      "[ TRAIN ] fold 1 epoch 1 loss: 0.0964\n",
      "[ TRAIN ] fold 1 epoch 1 loss: 0.0914\n",
      "[ TRAIN ] fold 1 epoch 1 loss: 0.0869\n",
      "[ TRAIN ] fold 1 epoch 1 loss: 0.0828\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382eeabfb52f42148bdc68b7598b6965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ VALID ] fold 1 epoch 1 loss: 0.0099\n",
      "[ VALID ] fold 1 epoch 1 loss: 0.0097\n",
      "[ VALID ] fold 1 epoch 1 loss: 0.0099\n",
      "[ VALID ] fold 1 epoch 1 loss: 0.0099\n",
      "[ VALID ] fold 1 epoch 1 loss: 0.0098\n",
      "[ VALID ] fold 1 epoch 1 loss: 0.0098\n",
      "[ VALID ] fold 1 epoch 1 loss: 0.0098\n",
      "[ VALID ] fold 1 epoch 1 loss: 0.0098\n",
      "[ VALID ] fold 1 epoch 1 loss: 0.0097\n",
      "Adjusting learning rate of group 0 to 9.0000e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7e847228c4e4f65b65c2893e8a77bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/390 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ TRAIN ] fold 1 epoch 2 loss: 0.0094\n",
      "[ TRAIN ] fold 1 epoch 2 loss: 0.0093\n",
      "[ TRAIN ] fold 1 epoch 2 loss: 0.0093\n",
      "[ TRAIN ] fold 1 epoch 2 loss: 0.0092\n",
      "[ TRAIN ] fold 1 epoch 2 loss: 0.0091\n",
      "[ TRAIN ] fold 1 epoch 2 loss: 0.0090\n",
      "[ TRAIN ] fold 1 epoch 2 loss: 0.0090\n",
      "[ TRAIN ] fold 1 epoch 2 loss: 0.0089\n",
      "[ TRAIN ] fold 1 epoch 2 loss: 0.0088\n",
      "[ TRAIN ] fold 1 epoch 2 loss: 0.0087\n",
      "[ TRAIN ] fold 1 epoch 2 loss: 0.0086\n",
      "[ TRAIN ] fold 1 epoch 2 loss: 0.0086\n",
      "[ TRAIN ] fold 1 epoch 2 loss: 0.0085\n",
      "[ TRAIN ] fold 1 epoch 2 loss: 0.0084\n",
      "[ TRAIN ] fold 1 epoch 2 loss: 0.0084\n",
      "[ TRAIN ] fold 1 epoch 2 loss: 0.0084\n",
      "[ TRAIN ] fold 1 epoch 2 loss: 0.0083\n",
      "[ TRAIN ] fold 1 epoch 2 loss: 0.0083\n",
      "[ TRAIN ] fold 1 epoch 2 loss: 0.0082\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73de6ec21e774a41bd2354cc81412ed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ VALID ] fold 1 epoch 2 loss: 0.0076\n",
      "[ VALID ] fold 1 epoch 2 loss: 0.0073\n",
      "[ VALID ] fold 1 epoch 2 loss: 0.0073\n",
      "[ VALID ] fold 1 epoch 2 loss: 0.0074\n",
      "[ VALID ] fold 1 epoch 2 loss: 0.0074\n",
      "[ VALID ] fold 1 epoch 2 loss: 0.0074\n",
      "[ VALID ] fold 1 epoch 2 loss: 0.0074\n",
      "[ VALID ] fold 1 epoch 2 loss: 0.0074\n",
      "[ VALID ] fold 1 epoch 2 loss: 0.0074\n",
      "Adjusting learning rate of group 0 to 8.1000e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "515b4a08397845e4b49b83764f582e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/390 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ TRAIN ] fold 1 epoch 3 loss: 0.0073\n",
      "[ TRAIN ] fold 1 epoch 3 loss: 0.0073\n",
      "[ TRAIN ] fold 1 epoch 3 loss: 0.0073\n",
      "[ TRAIN ] fold 1 epoch 3 loss: 0.0072\n",
      "[ TRAIN ] fold 1 epoch 3 loss: 0.0072\n",
      "[ TRAIN ] fold 1 epoch 3 loss: 0.0072\n",
      "[ TRAIN ] fold 1 epoch 3 loss: 0.0072\n",
      "[ TRAIN ] fold 1 epoch 3 loss: 0.0072\n",
      "[ TRAIN ] fold 1 epoch 3 loss: 0.0072\n",
      "[ TRAIN ] fold 1 epoch 3 loss: 0.0072\n",
      "[ TRAIN ] fold 1 epoch 3 loss: 0.0071\n",
      "[ TRAIN ] fold 1 epoch 3 loss: 0.0071\n",
      "[ TRAIN ] fold 1 epoch 3 loss: 0.0071\n",
      "[ TRAIN ] fold 1 epoch 3 loss: 0.0071\n",
      "[ TRAIN ] fold 1 epoch 3 loss: 0.0070\n",
      "[ TRAIN ] fold 1 epoch 3 loss: 0.0070\n",
      "[ TRAIN ] fold 1 epoch 3 loss: 0.0070\n",
      "[ TRAIN ] fold 1 epoch 3 loss: 0.0070\n",
      "[ TRAIN ] fold 1 epoch 3 loss: 0.0070\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4364fe8083a49a5ba395bbc9cd478a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ VALID ] fold 1 epoch 3 loss: 0.0069\n",
      "[ VALID ] fold 1 epoch 3 loss: 0.0065\n",
      "[ VALID ] fold 1 epoch 3 loss: 0.0065\n",
      "[ VALID ] fold 1 epoch 3 loss: 0.0066\n",
      "[ VALID ] fold 1 epoch 3 loss: 0.0066\n",
      "[ VALID ] fold 1 epoch 3 loss: 0.0066\n",
      "[ VALID ] fold 1 epoch 3 loss: 0.0067\n",
      "[ VALID ] fold 1 epoch 3 loss: 0.0067\n",
      "[ VALID ] fold 1 epoch 3 loss: 0.0067\n",
      "Adjusting learning rate of group 0 to 7.2900e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e170d6baf8534894b49b6fbaa592348d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/390 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ TRAIN ] fold 1 epoch 4 loss: 0.0068\n",
      "[ TRAIN ] fold 1 epoch 4 loss: 0.0068\n",
      "[ TRAIN ] fold 1 epoch 4 loss: 0.0067\n",
      "[ TRAIN ] fold 1 epoch 4 loss: 0.0067\n",
      "[ TRAIN ] fold 1 epoch 4 loss: 0.0067\n",
      "[ TRAIN ] fold 1 epoch 4 loss: 0.0067\n",
      "[ TRAIN ] fold 1 epoch 4 loss: 0.0067\n",
      "[ TRAIN ] fold 1 epoch 4 loss: 0.0066\n",
      "[ TRAIN ] fold 1 epoch 4 loss: 0.0066\n",
      "[ TRAIN ] fold 1 epoch 4 loss: 0.0066\n",
      "[ TRAIN ] fold 1 epoch 4 loss: 0.0066\n",
      "[ TRAIN ] fold 1 epoch 4 loss: 0.0066\n",
      "[ TRAIN ] fold 1 epoch 4 loss: 0.0065\n",
      "[ TRAIN ] fold 1 epoch 4 loss: 0.0065\n",
      "[ TRAIN ] fold 1 epoch 4 loss: 0.0065\n",
      "[ TRAIN ] fold 1 epoch 4 loss: 0.0065\n",
      "[ TRAIN ] fold 1 epoch 4 loss: 0.0065\n",
      "[ TRAIN ] fold 1 epoch 4 loss: 0.0065\n",
      "[ TRAIN ] fold 1 epoch 4 loss: 0.0065\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a1b90364aa4ecd8f34992d827cd04c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ VALID ] fold 1 epoch 4 loss: 0.0062\n",
      "[ VALID ] fold 1 epoch 4 loss: 0.0061\n",
      "[ VALID ] fold 1 epoch 4 loss: 0.0060\n",
      "[ VALID ] fold 1 epoch 4 loss: 0.0062\n",
      "[ VALID ] fold 1 epoch 4 loss: 0.0063\n",
      "[ VALID ] fold 1 epoch 4 loss: 0.0064\n",
      "[ VALID ] fold 1 epoch 4 loss: 0.0064\n",
      "[ VALID ] fold 1 epoch 4 loss: 0.0064\n",
      "[ VALID ] fold 1 epoch 4 loss: 0.0064\n",
      "Adjusting learning rate of group 0 to 6.5610e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8526c81b67a4f8890cccb2081d20c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/390 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ TRAIN ] fold 1 epoch 5 loss: 0.0063\n",
      "[ TRAIN ] fold 1 epoch 5 loss: 0.0063\n",
      "[ TRAIN ] fold 1 epoch 5 loss: 0.0063\n",
      "[ TRAIN ] fold 1 epoch 5 loss: 0.0063\n",
      "[ TRAIN ] fold 1 epoch 5 loss: 0.0063\n",
      "[ TRAIN ] fold 1 epoch 5 loss: 0.0063\n",
      "[ TRAIN ] fold 1 epoch 5 loss: 0.0064\n",
      "[ TRAIN ] fold 1 epoch 5 loss: 0.0063\n",
      "[ TRAIN ] fold 1 epoch 5 loss: 0.0063\n",
      "[ TRAIN ] fold 1 epoch 5 loss: 0.0063\n",
      "[ TRAIN ] fold 1 epoch 5 loss: 0.0063\n",
      "[ TRAIN ] fold 1 epoch 5 loss: 0.0063\n",
      "[ TRAIN ] fold 1 epoch 5 loss: 0.0063\n",
      "[ TRAIN ] fold 1 epoch 5 loss: 0.0063\n",
      "[ TRAIN ] fold 1 epoch 5 loss: 0.0063\n",
      "[ TRAIN ] fold 1 epoch 5 loss: 0.0063\n",
      "[ TRAIN ] fold 1 epoch 5 loss: 0.0063\n",
      "[ TRAIN ] fold 1 epoch 5 loss: 0.0063\n",
      "[ TRAIN ] fold 1 epoch 5 loss: 0.0062\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "644f8ba0c1b54f45805f9011fed747bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ VALID ] fold 1 epoch 5 loss: 0.0063\n",
      "[ VALID ] fold 1 epoch 5 loss: 0.0063\n",
      "[ VALID ] fold 1 epoch 5 loss: 0.0063\n",
      "[ VALID ] fold 1 epoch 5 loss: 0.0063\n",
      "[ VALID ] fold 1 epoch 5 loss: 0.0064\n",
      "[ VALID ] fold 1 epoch 5 loss: 0.0064\n",
      "[ VALID ] fold 1 epoch 5 loss: 0.0064\n",
      "[ VALID ] fold 1 epoch 5 loss: 0.0064\n",
      "[ VALID ] fold 1 epoch 5 loss: 0.0063\n",
      "Adjusting learning rate of group 0 to 5.9049e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234078810a154eb2b2b3d445fc6fb3c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/390 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ TRAIN ] fold 1 epoch 6 loss: 0.0061\n",
      "[ TRAIN ] fold 1 epoch 6 loss: 0.0063\n",
      "[ TRAIN ] fold 1 epoch 6 loss: 0.0063\n",
      "[ TRAIN ] fold 1 epoch 6 loss: 0.0062\n",
      "[ TRAIN ] fold 1 epoch 6 loss: 0.0062\n",
      "[ TRAIN ] fold 1 epoch 6 loss: 0.0062\n",
      "[ TRAIN ] fold 1 epoch 6 loss: 0.0062\n",
      "[ TRAIN ] fold 1 epoch 6 loss: 0.0061\n",
      "[ TRAIN ] fold 1 epoch 6 loss: 0.0062\n",
      "[ TRAIN ] fold 1 epoch 6 loss: 0.0061\n",
      "[ TRAIN ] fold 1 epoch 6 loss: 0.0061\n",
      "[ TRAIN ] fold 1 epoch 6 loss: 0.0061\n",
      "[ TRAIN ] fold 1 epoch 6 loss: 0.0062\n",
      "[ TRAIN ] fold 1 epoch 6 loss: 0.0062\n",
      "[ TRAIN ] fold 1 epoch 6 loss: 0.0062\n",
      "[ TRAIN ] fold 1 epoch 6 loss: 0.0062\n",
      "[ TRAIN ] fold 1 epoch 6 loss: 0.0062\n",
      "[ TRAIN ] fold 1 epoch 6 loss: 0.0062\n",
      "[ TRAIN ] fold 1 epoch 6 loss: 0.0062\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a7f4a827495481cbc699774cb137d44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ VALID ] fold 1 epoch 6 loss: 0.0063\n",
      "[ VALID ] fold 1 epoch 6 loss: 0.0062\n",
      "[ VALID ] fold 1 epoch 6 loss: 0.0060\n",
      "[ VALID ] fold 1 epoch 6 loss: 0.0061\n",
      "[ VALID ] fold 1 epoch 6 loss: 0.0062\n",
      "[ VALID ] fold 1 epoch 6 loss: 0.0062\n",
      "[ VALID ] fold 1 epoch 6 loss: 0.0062\n",
      "[ VALID ] fold 1 epoch 6 loss: 0.0063\n",
      "[ VALID ] fold 1 epoch 6 loss: 0.0062\n",
      "Adjusting learning rate of group 0 to 5.3144e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05db35e2d6f3475f8b78dd06a9c4d2d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/390 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ TRAIN ] fold 1 epoch 7 loss: 0.0061\n",
      "[ TRAIN ] fold 1 epoch 7 loss: 0.0061\n",
      "[ TRAIN ] fold 1 epoch 7 loss: 0.0059\n",
      "[ TRAIN ] fold 1 epoch 7 loss: 0.0060\n",
      "[ TRAIN ] fold 1 epoch 7 loss: 0.0060\n",
      "[ TRAIN ] fold 1 epoch 7 loss: 0.0060\n",
      "[ TRAIN ] fold 1 epoch 7 loss: 0.0060\n",
      "[ TRAIN ] fold 1 epoch 7 loss: 0.0060\n",
      "[ TRAIN ] fold 1 epoch 7 loss: 0.0060\n",
      "[ TRAIN ] fold 1 epoch 7 loss: 0.0060\n",
      "[ TRAIN ] fold 1 epoch 7 loss: 0.0060\n",
      "[ TRAIN ] fold 1 epoch 7 loss: 0.0060\n",
      "[ TRAIN ] fold 1 epoch 7 loss: 0.0060\n",
      "[ TRAIN ] fold 1 epoch 7 loss: 0.0060\n",
      "[ TRAIN ] fold 1 epoch 7 loss: 0.0060\n",
      "[ TRAIN ] fold 1 epoch 7 loss: 0.0060\n",
      "[ TRAIN ] fold 1 epoch 7 loss: 0.0060\n",
      "[ TRAIN ] fold 1 epoch 7 loss: 0.0060\n",
      "[ TRAIN ] fold 1 epoch 7 loss: 0.0060\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43bbd326577847b98143b3325a523b07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ VALID ] fold 1 epoch 7 loss: 0.0058\n",
      "[ VALID ] fold 1 epoch 7 loss: 0.0058\n",
      "[ VALID ] fold 1 epoch 7 loss: 0.0057\n",
      "[ VALID ] fold 1 epoch 7 loss: 0.0059\n",
      "[ VALID ] fold 1 epoch 7 loss: 0.0060\n",
      "[ VALID ] fold 1 epoch 7 loss: 0.0061\n",
      "[ VALID ] fold 1 epoch 7 loss: 0.0061\n",
      "[ VALID ] fold 1 epoch 7 loss: 0.0061\n",
      "[ VALID ] fold 1 epoch 7 loss: 0.0061\n",
      "Adjusting learning rate of group 0 to 4.7830e-04.\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0d0a0ed1067476ba94352e05c6b9d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/390 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ TRAIN ] fold 2 epoch 1 loss: 1.3036\n",
      "[ TRAIN ] fold 2 epoch 1 loss: 0.6989\n",
      "[ TRAIN ] fold 2 epoch 1 loss: 0.4829\n",
      "[ TRAIN ] fold 2 epoch 1 loss: 0.3708\n",
      "[ TRAIN ] fold 2 epoch 1 loss: 0.3016\n",
      "[ TRAIN ] fold 2 epoch 1 loss: 0.2549\n",
      "[ TRAIN ] fold 2 epoch 1 loss: 0.2212\n",
      "[ TRAIN ] fold 2 epoch 1 loss: 0.1957\n",
      "[ TRAIN ] fold 2 epoch 1 loss: 0.1756\n",
      "[ TRAIN ] fold 2 epoch 1 loss: 0.1595\n",
      "[ TRAIN ] fold 2 epoch 1 loss: 0.1462\n",
      "[ TRAIN ] fold 2 epoch 1 loss: 0.1350\n",
      "[ TRAIN ] fold 2 epoch 1 loss: 0.1256\n",
      "[ TRAIN ] fold 2 epoch 1 loss: 0.1175\n",
      "[ TRAIN ] fold 2 epoch 1 loss: 0.1104\n",
      "[ TRAIN ] fold 2 epoch 1 loss: 0.1041\n",
      "[ TRAIN ] fold 2 epoch 1 loss: 0.0986\n",
      "[ TRAIN ] fold 2 epoch 1 loss: 0.0936\n",
      "[ TRAIN ] fold 2 epoch 1 loss: 0.0892\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aecfaf32ddb043f2b4cda9c470260897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ VALID ] fold 2 epoch 1 loss: 0.0094\n",
      "[ VALID ] fold 2 epoch 1 loss: 0.0092\n",
      "[ VALID ] fold 2 epoch 1 loss: 0.0093\n",
      "[ VALID ] fold 2 epoch 1 loss: 0.0093\n",
      "[ VALID ] fold 2 epoch 1 loss: 0.0093\n",
      "[ VALID ] fold 2 epoch 1 loss: 0.0092\n",
      "[ VALID ] fold 2 epoch 1 loss: 0.0091\n",
      "[ VALID ] fold 2 epoch 1 loss: 0.0092\n",
      "[ VALID ] fold 2 epoch 1 loss: 0.0092\n",
      "Adjusting learning rate of group 0 to 9.0000e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3713595c1f6643df87cb4bc38fcbe607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/390 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ TRAIN ] fold 2 epoch 2 loss: 0.0091\n",
      "[ TRAIN ] fold 2 epoch 2 loss: 0.0091\n",
      "[ TRAIN ] fold 2 epoch 2 loss: 0.0089\n",
      "[ TRAIN ] fold 2 epoch 2 loss: 0.0089\n",
      "[ TRAIN ] fold 2 epoch 2 loss: 0.0088\n",
      "[ TRAIN ] fold 2 epoch 2 loss: 0.0087\n",
      "[ TRAIN ] fold 2 epoch 2 loss: 0.0087\n",
      "[ TRAIN ] fold 2 epoch 2 loss: 0.0086\n",
      "[ TRAIN ] fold 2 epoch 2 loss: 0.0086\n",
      "[ TRAIN ] fold 2 epoch 2 loss: 0.0085\n",
      "[ TRAIN ] fold 2 epoch 2 loss: 0.0084\n",
      "[ TRAIN ] fold 2 epoch 2 loss: 0.0084\n",
      "[ TRAIN ] fold 2 epoch 2 loss: 0.0083\n",
      "[ TRAIN ] fold 2 epoch 2 loss: 0.0083\n",
      "[ TRAIN ] fold 2 epoch 2 loss: 0.0082\n",
      "[ TRAIN ] fold 2 epoch 2 loss: 0.0082\n",
      "[ TRAIN ] fold 2 epoch 2 loss: 0.0082\n",
      "[ TRAIN ] fold 2 epoch 2 loss: 0.0081\n",
      "[ TRAIN ] fold 2 epoch 2 loss: 0.0081\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb8a6f026db94d7eb43a281425376b16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ VALID ] fold 2 epoch 2 loss: 0.0074\n",
      "[ VALID ] fold 2 epoch 2 loss: 0.0072\n",
      "[ VALID ] fold 2 epoch 2 loss: 0.0072\n",
      "[ VALID ] fold 2 epoch 2 loss: 0.0072\n",
      "[ VALID ] fold 2 epoch 2 loss: 0.0072\n",
      "[ VALID ] fold 2 epoch 2 loss: 0.0072\n",
      "[ VALID ] fold 2 epoch 2 loss: 0.0072\n",
      "[ VALID ] fold 2 epoch 2 loss: 0.0073\n",
      "[ VALID ] fold 2 epoch 2 loss: 0.0072\n",
      "Adjusting learning rate of group 0 to 8.1000e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f58196fc3da490785ef419f6d8365e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/390 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ TRAIN ] fold 2 epoch 3 loss: 0.0072\n",
      "[ TRAIN ] fold 2 epoch 3 loss: 0.0072\n",
      "[ TRAIN ] fold 2 epoch 3 loss: 0.0072\n",
      "[ TRAIN ] fold 2 epoch 3 loss: 0.0072\n",
      "[ TRAIN ] fold 2 epoch 3 loss: 0.0071\n",
      "[ TRAIN ] fold 2 epoch 3 loss: 0.0071\n",
      "[ TRAIN ] fold 2 epoch 3 loss: 0.0071\n",
      "[ TRAIN ] fold 2 epoch 3 loss: 0.0070\n",
      "[ TRAIN ] fold 2 epoch 3 loss: 0.0070\n",
      "[ TRAIN ] fold 2 epoch 3 loss: 0.0070\n",
      "[ TRAIN ] fold 2 epoch 3 loss: 0.0070\n",
      "[ TRAIN ] fold 2 epoch 3 loss: 0.0070\n",
      "[ TRAIN ] fold 2 epoch 3 loss: 0.0070\n",
      "[ TRAIN ] fold 2 epoch 3 loss: 0.0069\n",
      "[ TRAIN ] fold 2 epoch 3 loss: 0.0069\n",
      "[ TRAIN ] fold 2 epoch 3 loss: 0.0069\n",
      "[ TRAIN ] fold 2 epoch 3 loss: 0.0069\n",
      "[ TRAIN ] fold 2 epoch 3 loss: 0.0069\n",
      "[ TRAIN ] fold 2 epoch 3 loss: 0.0069\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd445e26ccc54366a8f560a73676a1ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ VALID ] fold 2 epoch 3 loss: 0.0060\n",
      "[ VALID ] fold 2 epoch 3 loss: 0.0060\n",
      "[ VALID ] fold 2 epoch 3 loss: 0.0061\n",
      "[ VALID ] fold 2 epoch 3 loss: 0.0063\n",
      "[ VALID ] fold 2 epoch 3 loss: 0.0064\n",
      "[ VALID ] fold 2 epoch 3 loss: 0.0064\n",
      "[ VALID ] fold 2 epoch 3 loss: 0.0064\n",
      "[ VALID ] fold 2 epoch 3 loss: 0.0065\n",
      "[ VALID ] fold 2 epoch 3 loss: 0.0065\n",
      "Adjusting learning rate of group 0 to 7.2900e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "500034a5a5d345329e3b58efb248f547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/390 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ TRAIN ] fold 2 epoch 4 loss: 0.0068\n",
      "[ TRAIN ] fold 2 epoch 4 loss: 0.0067\n",
      "[ TRAIN ] fold 2 epoch 4 loss: 0.0067\n",
      "[ TRAIN ] fold 2 epoch 4 loss: 0.0066\n",
      "[ TRAIN ] fold 2 epoch 4 loss: 0.0066\n",
      "[ TRAIN ] fold 2 epoch 4 loss: 0.0066\n",
      "[ TRAIN ] fold 2 epoch 4 loss: 0.0066\n",
      "[ TRAIN ] fold 2 epoch 4 loss: 0.0066\n",
      "[ TRAIN ] fold 2 epoch 4 loss: 0.0066\n",
      "[ TRAIN ] fold 2 epoch 4 loss: 0.0066\n",
      "[ TRAIN ] fold 2 epoch 4 loss: 0.0066\n",
      "[ TRAIN ] fold 2 epoch 4 loss: 0.0066\n",
      "[ TRAIN ] fold 2 epoch 4 loss: 0.0065\n",
      "[ TRAIN ] fold 2 epoch 4 loss: 0.0065\n",
      "[ TRAIN ] fold 2 epoch 4 loss: 0.0065\n",
      "[ TRAIN ] fold 2 epoch 4 loss: 0.0065\n",
      "[ TRAIN ] fold 2 epoch 4 loss: 0.0065\n",
      "[ TRAIN ] fold 2 epoch 4 loss: 0.0065\n",
      "[ TRAIN ] fold 2 epoch 4 loss: 0.0065\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05196389b86f44a6b4b4e0ff1c5569fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ VALID ] fold 2 epoch 4 loss: 0.0061\n",
      "[ VALID ] fold 2 epoch 4 loss: 0.0061\n",
      "[ VALID ] fold 2 epoch 4 loss: 0.0060\n",
      "[ VALID ] fold 2 epoch 4 loss: 0.0063\n",
      "[ VALID ] fold 2 epoch 4 loss: 0.0064\n",
      "[ VALID ] fold 2 epoch 4 loss: 0.0064\n",
      "[ VALID ] fold 2 epoch 4 loss: 0.0064\n",
      "[ VALID ] fold 2 epoch 4 loss: 0.0064\n",
      "[ VALID ] fold 2 epoch 4 loss: 0.0064\n",
      "Adjusting learning rate of group 0 to 6.5610e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45871d27e6864418987ff44ec61c6ee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/390 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ TRAIN ] fold 2 epoch 5 loss: 0.0064\n",
      "[ TRAIN ] fold 2 epoch 5 loss: 0.0063\n",
      "[ TRAIN ] fold 2 epoch 5 loss: 0.0063\n",
      "[ TRAIN ] fold 2 epoch 5 loss: 0.0063\n",
      "[ TRAIN ] fold 2 epoch 5 loss: 0.0063\n",
      "[ TRAIN ] fold 2 epoch 5 loss: 0.0063\n",
      "[ TRAIN ] fold 2 epoch 5 loss: 0.0063\n",
      "[ TRAIN ] fold 2 epoch 5 loss: 0.0063\n",
      "[ TRAIN ] fold 2 epoch 5 loss: 0.0062\n",
      "[ TRAIN ] fold 2 epoch 5 loss: 0.0062\n",
      "[ TRAIN ] fold 2 epoch 5 loss: 0.0063\n",
      "[ TRAIN ] fold 2 epoch 5 loss: 0.0063\n",
      "[ TRAIN ] fold 2 epoch 5 loss: 0.0062\n",
      "[ TRAIN ] fold 2 epoch 5 loss: 0.0062\n",
      "[ TRAIN ] fold 2 epoch 5 loss: 0.0062\n",
      "[ TRAIN ] fold 2 epoch 5 loss: 0.0062\n",
      "[ TRAIN ] fold 2 epoch 5 loss: 0.0062\n",
      "[ TRAIN ] fold 2 epoch 5 loss: 0.0062\n",
      "[ TRAIN ] fold 2 epoch 5 loss: 0.0062\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f141348ac48f4d5c856549218abd6ec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ VALID ] fold 2 epoch 5 loss: 0.0064\n",
      "[ VALID ] fold 2 epoch 5 loss: 0.0061\n",
      "[ VALID ] fold 2 epoch 5 loss: 0.0061\n",
      "[ VALID ] fold 2 epoch 5 loss: 0.0062\n",
      "[ VALID ] fold 2 epoch 5 loss: 0.0062\n",
      "[ VALID ] fold 2 epoch 5 loss: 0.0062\n",
      "[ VALID ] fold 2 epoch 5 loss: 0.0062\n",
      "[ VALID ] fold 2 epoch 5 loss: 0.0063\n",
      "[ VALID ] fold 2 epoch 5 loss: 0.0063\n",
      "Adjusting learning rate of group 0 to 5.9049e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4c0f5459421495f83aabd9d3cb3f4fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/390 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ TRAIN ] fold 2 epoch 6 loss: 0.0061\n",
      "[ TRAIN ] fold 2 epoch 6 loss: 0.0060\n",
      "[ TRAIN ] fold 2 epoch 6 loss: 0.0061\n",
      "[ TRAIN ] fold 2 epoch 6 loss: 0.0061\n",
      "[ TRAIN ] fold 2 epoch 6 loss: 0.0061\n",
      "[ TRAIN ] fold 2 epoch 6 loss: 0.0061\n",
      "[ TRAIN ] fold 2 epoch 6 loss: 0.0061\n",
      "[ TRAIN ] fold 2 epoch 6 loss: 0.0061\n",
      "[ TRAIN ] fold 2 epoch 6 loss: 0.0061\n",
      "[ TRAIN ] fold 2 epoch 6 loss: 0.0061\n",
      "[ TRAIN ] fold 2 epoch 6 loss: 0.0061\n",
      "[ TRAIN ] fold 2 epoch 6 loss: 0.0061\n",
      "[ TRAIN ] fold 2 epoch 6 loss: 0.0061\n",
      "[ TRAIN ] fold 2 epoch 6 loss: 0.0061\n",
      "[ TRAIN ] fold 2 epoch 6 loss: 0.0061\n",
      "[ TRAIN ] fold 2 epoch 6 loss: 0.0061\n",
      "[ TRAIN ] fold 2 epoch 6 loss: 0.0061\n",
      "[ TRAIN ] fold 2 epoch 6 loss: 0.0061\n",
      "[ TRAIN ] fold 2 epoch 6 loss: 0.0061\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "270f0d0bea594a3d8f4764aea547a33a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ VALID ] fold 2 epoch 6 loss: 0.0065\n",
      "[ VALID ] fold 2 epoch 6 loss: 0.0061\n",
      "[ VALID ] fold 2 epoch 6 loss: 0.0061\n",
      "[ VALID ] fold 2 epoch 6 loss: 0.0061\n",
      "[ VALID ] fold 2 epoch 6 loss: 0.0061\n",
      "[ VALID ] fold 2 epoch 6 loss: 0.0061\n",
      "[ VALID ] fold 2 epoch 6 loss: 0.0062\n",
      "[ VALID ] fold 2 epoch 6 loss: 0.0062\n",
      "[ VALID ] fold 2 epoch 6 loss: 0.0062\n",
      "Adjusting learning rate of group 0 to 5.3144e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4104a612139c429b80803f465f3bf1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/390 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4122420/3469466770.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[ TRAIN ] fold {fold + 1} epoch {epoch + 1} loss: {np.array(train_losses).mean():.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for fold in range(5):\n",
    "    batch_size = 32\n",
    "    \n",
    "    model = Callibration().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer=optimizer,\n",
    "                                            lr_lambda=lambda epoch: 0.9 ** epoch,\n",
    "                                            last_epoch=-1,\n",
    "                                            verbose=True)\n",
    "    \n",
    "    train_labels = copy.deepcopy(labels[train_idx[fold]])\n",
    "    train_token_n_list = copy.deepcopy(token_n_list[train_idx[fold]])\n",
    "\n",
    "    valid_labels = copy.deepcopy(labels[valid_idx[fold]])\n",
    "    valid_token_n_list = copy.deepcopy(token_n_list[valid_idx[fold]])\n",
    "\n",
    "    train_dataset = CategoryDataset(train_labels, train_token_n_list)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    valid_dataset = CategoryDataset(valid_labels, valid_token_n_list)\n",
    "    valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    for epoch in range(7):\n",
    "        train_losses = []\n",
    "        for step, (inputs, targets) in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            batch_size, seq_len = inputs.size()\n",
    "\n",
    "            preds = model(inputs)\n",
    "            preds = preds.view(batch_size * seq_len, 16)\n",
    "            targets = targets.view(-1)\n",
    "\n",
    "            loss = criterion(preds, targets)\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "            if (step + 1) % 20 == 0:\n",
    "                print(f\"[ TRAIN ] fold {fold + 1} epoch {epoch + 1} loss: {np.array(train_losses).mean():.4f}\")\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "        valid_losses = []\n",
    "        for step, (inputs, targets) in tqdm(enumerate(valid_dataloader), total=len(valid_dataloader)):\n",
    "            with torch.no_grad():\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "\n",
    "                batch_size, seq_len = inputs.size()\n",
    "\n",
    "                preds = model(inputs)\n",
    "                preds = preds.view(batch_size * seq_len, 16)\n",
    "                targets = targets.view(-1)\n",
    "\n",
    "                loss = criterion(preds, targets)\n",
    "                valid_losses.append(loss.item())\n",
    "\n",
    "                if (step + 1) % 10 == 0:\n",
    "                    print(f\"[ VALID ] fold {fold + 1} epoch {epoch + 1} loss: {np.array(valid_losses).mean():.4f}\")\n",
    "                    \n",
    "        scheduler.step()\n",
    "        torch.save(model.state_dict(), osp.join(save_path, f'fold_{fold}_callibration.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b74faa86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T13:32:05.131289Z",
     "start_time": "2022-03-15T13:32:05.128730Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3246949926.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_4122420/3246949926.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    STOP!!!\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "STOP!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ed8dff",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d3e20c3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T14:40:08.748834Z",
     "start_time": "2022-03-15T14:40:08.632571Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callibration_checkpoints = os.listdir('../result/callibration_random_with_starting_1percent_clean/')\n",
    "\n",
    "callibration = Callibration()\n",
    "callibration.eval().cuda()\n",
    "callibration.load_state_dict(torch.load('../result/callibration_random_with_starting_1percent_clean/' + callibration_checkpoints[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "70452400",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T14:40:09.108491Z",
     "start_time": "2022-03-15T14:40:09.023567Z"
    }
   },
   "outputs": [],
   "source": [
    "token_n = 15\n",
    "inputs = torch.zeros(2048)\n",
    "\n",
    "inputs[token_n:] = 15\n",
    "\n",
    "inputs[:token_n] = torch.Tensor([0, 1, 4, 5, 3, 4, 4, 4, 3, 4, 4, 3, 4, 4, 0])\n",
    "inputs = inputs.long().to(device).unsqueeze(0)\n",
    "\n",
    "output = callibration(inputs)\n",
    "cal_output = output.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9beb157c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T14:40:09.399142Z",
     "start_time": "2022-03-15T14:40:09.394961Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 4, 5, 3, 4, 4, 4, 3, 4, 4, 3, 4, 4, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[:, :15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3ed3fbd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T14:40:10.747195Z",
     "start_time": "2022-03-15T14:40:10.742969Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 3, 4, 4, 3, 4, 4, 4, 3, 4, 4, 3, 4, 4, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_output[:, :15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "48c07d03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T09:58:20.094829Z",
     "start_time": "2022-03-15T09:58:20.091780Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 4, 5, 3, 4, 4, 4, 3, 4, 4, 3, 4, 4, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[:, :15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c7bb99c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T09:58:20.462448Z",
     "start_time": "2022-03-15T09:58:20.459689Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_output[:, :15]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "418.984px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
