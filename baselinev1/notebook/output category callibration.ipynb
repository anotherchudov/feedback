{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fc1922f",
   "metadata": {},
   "source": [
    "# Callibration\n",
    "\n",
    "- input   0 0 1 0 0 2 2 2\n",
    "- output  0 0 1 2 2 2 2 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c0b89c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T16:44:07.865727Z",
     "start_time": "2022-03-14T16:44:07.863520Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "DATASET_PATH = ('../../../feedback-prize-2021')\n",
    "\n",
    "sys.path.insert(0, '../codes/new_transformers_branch/transformers/src')\n",
    "sys.path.append('../codes')\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a35dd0e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T16:44:08.473847Z",
     "start_time": "2022-03-14T16:44:07.866530Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import re\n",
    "import pickle\n",
    "import random\n",
    "import easydict\n",
    "import copy\n",
    "\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from new_transformers import DebertaV2TokenizerFast\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3486b14",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e62ee9d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T16:44:09.749169Z",
     "start_time": "2022-03-14T16:44:08.475422Z"
    }
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "data = h5py.File(f'../data_file/deberta_spm_data_v2.h5py')\n",
    "labels = data[f'cbio_labels']\n",
    "labels = np.argmax(labels, -1)\n",
    "labels = labels[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37092575",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T16:44:10.342918Z",
     "start_time": "2022-03-14T16:44:09.750279Z"
    }
   },
   "outputs": [],
   "source": [
    "token_n_list = []\n",
    "for num_tokens in data['num_tokens']:\n",
    "    token_n_list.append(num_tokens[0])\n",
    "    \n",
    "token_n_list = np.array(token_n_list[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "589a858c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T16:44:10.390194Z",
     "start_time": "2022-03-14T16:44:10.343996Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "with open('../data_file/data_splits.pickle', 'rb') as f:\n",
    "    data_splits = pickle.load(f)\n",
    "\n",
    "with open('../data_file/id_to_ix_map.pickle', 'rb') as f:\n",
    "    id_to_ix_map = {x.split('/')[-1].split('.')[0]: y for x, y in pickle.load(f).items()}\n",
    "\n",
    "train_idx = []\n",
    "valid_idx = []\n",
    "for val_fold in range(5):\n",
    "    train_text_ids = [text_id for fold in range(5) if fold != val_fold for text_id in data_splits[seed][250]['normed'][fold]]\n",
    "    val_text_ids = data_splits[seed][250]['normed'][val_fold]\n",
    "    \n",
    "    train_fold_idx = [id_to_ix_map[text_id] for text_id in train_text_ids]\n",
    "    val_fold_idx = [id_to_ix_map[text_id] for text_id in val_text_ids]\n",
    "    \n",
    "    train_idx.append(train_fold_idx)\n",
    "    valid_idx.append(val_fold_idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bca59da",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2aba529",
   "metadata": {},
   "source": [
    "### Replacing category randomly by continuous 0 (length is 1 - 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dace83af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T16:44:10.410387Z",
     "start_time": "2022-03-14T16:44:10.391624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 category will be added at 195 index with length 2\n",
      "before [ 6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  0  0  9 10]\n",
      "after  [ 6  6  6  6  6  6  6  6  6  6  0  0  6  6  6  6  6  6  0  0  9 10]\n"
     ]
    }
   ],
   "source": [
    "test = copy.deepcopy(labels[0])\n",
    "token_n = token_n_list[0]\n",
    "\n",
    "# padding\n",
    "test[token_n:] = -1\n",
    "\n",
    "# place where zero class will be assigned\n",
    "zero_n = random.randint(1, 5)\n",
    "zero_start_i = random.randint(1, token_n - 1)\n",
    "zero_end_i = min(zero_start_i + zero_n, token_n - 1)\n",
    "\n",
    "# place that will be printed\n",
    "print_start_i = max(zero_start_i - 10, 0)\n",
    "print_end_i = min(zero_end_i + 10, token_n - 1)\n",
    "\n",
    "print(f'0 category will be added at {zero_start_i} index with length {zero_n}')\n",
    "print(f'before {test[print_start_i:print_end_i]}')\n",
    "\n",
    "# augmentation\n",
    "test[zero_start_i:zero_end_i] = 0\n",
    "\n",
    "print(f'after  {test[print_start_i:print_end_i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df9a984",
   "metadata": {},
   "source": [
    "### Replacing category randomly by any category (length is 30 - 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c864c29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T16:44:10.427281Z",
     "start_time": "2022-03-14T16:44:10.411856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category replacement will be happend at 37 times\n",
      "showing at index 112\n",
      "before [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "after  [ 6  6  6  6  6  6  6  6  6 14  0  4  6  6  6  6  6  6  6  6]\n"
     ]
    }
   ],
   "source": [
    "test = copy.deepcopy(labels[0])\n",
    "token_n = token_n_list[0]\n",
    "\n",
    "# padding\n",
    "test[token_n:] = -1\n",
    "\n",
    "# place where zero class will be assigned\n",
    "replace_n = random.randint(30, 100)\n",
    "replace_idx = np.random.choice(range(1, token_n - 1), size=replace_n, replace=False)\n",
    "replace_cats = np.random.choice(range(0, 15), size=replace_n, replace=True)\n",
    "\n",
    "# place that will be printed\n",
    "print_start_i = max(replace_idx[0] - 10, 0)\n",
    "print_end_i = min(replace_idx[0] + 10, token_n - 1)\n",
    "\n",
    "print(f'category replacement will be happend at {replace_n} times')\n",
    "print(f'showing at index {print_start_i}')\n",
    "print(f'before {test[print_start_i:print_end_i]}')\n",
    "\n",
    "# augmentation\n",
    "test[replace_idx] = replace_cats\n",
    "\n",
    "print(f'after  {test[print_start_i:print_end_i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580c1706",
   "metadata": {},
   "source": [
    "### Replace starting category as even number (ex: 122 -> 222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2230a444",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T16:44:10.454090Z",
     "start_time": "2022-03-14T16:44:10.428382Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 5 will be replaced\n",
      "example: category 3 will be replaced to 4\n",
      "before [2 2 2 2 0 3 4 4 4 4]\n",
      "after  [2 2 2 2 0 4 4 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "test = copy.deepcopy(labels[0])\n",
    "token_n = token_n_list[0]\n",
    "\n",
    "# padding\n",
    "test[token_n:] = -1\n",
    "\n",
    "# place where odd category exist\n",
    "odd_category = [1, 3, 5, 7, 9, 11, 13]\n",
    "\n",
    "odd_cat_idx = [i for i, category in enumerate(test) if category in odd_category]\n",
    "replace_n = random.randint(1, len(odd_cat_idx))\n",
    "odd_cat_idx = np.random.choice(odd_cat_idx, size=replace_n, replace=False)\n",
    "\n",
    "# place that will be printed\n",
    "print_start_i = max(odd_cat_idx[0] - 5, 0)\n",
    "print_end_i = min(odd_cat_idx[0] + 5, token_n - 1)\n",
    "\n",
    "print(f'total {replace_n} will be replaced')\n",
    "print(f'example: category {test[odd_cat_idx[0]]} will be replaced to {test[odd_cat_idx[0]] + 1}')\n",
    "print(f'before {test[print_start_i:print_end_i]}')\n",
    "\n",
    "# augmentation\n",
    "test[odd_cat_idx] += 1\n",
    "\n",
    "print(f'after  {test[print_start_i:print_end_i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdf9e1b",
   "metadata": {},
   "source": [
    "### Replace starting category to different category (ex: 122 -> 322)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d63c093a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T16:44:10.475753Z",
     "start_time": "2022-03-14T16:44:10.456620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4 will be replaced\n",
      "category 3 will be replaced to 11\n",
      "before [2 2 2 2 0 3 4 4 4 4]\n",
      "after  [ 2  2  2  2  0 11  4  4  4  4]\n"
     ]
    }
   ],
   "source": [
    "test = copy.deepcopy(labels[0])\n",
    "token_n = token_n_list[0]\n",
    "\n",
    "# padding\n",
    "test[token_n:] = -1\n",
    "\n",
    "# place where odd category exist\n",
    "odd_category = [1, 3, 5, 7, 9, 11, 13]\n",
    "odd_cat_idx = [i for i, category in enumerate(test) if category in odd_category]\n",
    "\n",
    "replace_n = random.randint(1, len(odd_cat_idx))\n",
    "odd_cat_idx = np.random.choice(odd_cat_idx, size=replace_n, replace=False)\n",
    "\n",
    "replace_cats = []\n",
    "for odd_cat_i in odd_cat_idx:\n",
    "    current_cat = test[odd_cat_i]\n",
    "    odd_sample = copy.deepcopy(odd_category)\n",
    "    odd_sample.remove(current_cat)\n",
    "    replace_cats.append(random.choice(odd_sample))\n",
    "    \n",
    "replace_cats = np.array(replace_cats)\n",
    "\n",
    "# place that will be printed\n",
    "print_start_i = max(odd_cat_idx[0] - 5, 0)\n",
    "print_end_i = min(odd_cat_idx[0] + 5, token_n - 1)\n",
    "\n",
    "print(f'total {replace_n} will be replaced')\n",
    "print(f'category {test[odd_cat_idx[0]]} will be replaced to {replace_cats[0]}')\n",
    "print(f'before {test[print_start_i:print_end_i]}')\n",
    "\n",
    "# augmentation\n",
    "test[odd_cat_idx] = replace_cats\n",
    "\n",
    "print(f'after  {test[print_start_i:print_end_i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f469c07",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6acc9ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T16:44:10.501431Z",
     "start_time": "2022-03-14T16:44:10.476698Z"
    }
   },
   "outputs": [],
   "source": [
    "class CategoryDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, labels, token_n_list):\n",
    "        self.labels = labels\n",
    "        self.token_n_list = token_n_list\n",
    "        \n",
    "        self.odd_category = [1, 3, 5, 7, 9, 11, 13]\n",
    "\n",
    "    def replace_with_zero(self, label, token_n):\n",
    "        \"\"\"\"\"\"\n",
    "        zero_n = random.randint(1, 5)\n",
    "        zero_start_i = random.randint(1, token_n - 1)\n",
    "        zero_end_i = min(zero_start_i + zero_n, token_n - 1)\n",
    "        \n",
    "        label[zero_start_i:zero_end_i] = 0\n",
    "        \n",
    "        return label\n",
    "    \n",
    "    def b_to_i_label(self, label, token_n):\n",
    "        \"\"\"\"\"\"\n",
    "        odd_cat_idx = [i for i, category in enumerate(label) if category in self.odd_category]\n",
    "        if len(odd_cat_idx) == 0:\n",
    "            return label\n",
    "\n",
    "        replace_n = random.randint(1, len(odd_cat_idx))\n",
    "        odd_cat_idx = np.random.choice(odd_cat_idx, size=replace_n, replace=False)\n",
    "\n",
    "        label[odd_cat_idx] += 1\n",
    "        \n",
    "        return label\n",
    "    \n",
    "    def replace_b_label(self, label, token_n):\n",
    "        \"\"\"\"\"\"\n",
    "        odd_cat_idx = [i for i, category in enumerate(label) if category in self.odd_category]\n",
    "        if len(odd_cat_idx) == 0:\n",
    "            return label\n",
    "\n",
    "        replace_n = random.randint(1, len(odd_cat_idx))\n",
    "        odd_cat_idx = np.random.choice(odd_cat_idx, size=replace_n, replace=False)\n",
    "\n",
    "        replace_cats = []\n",
    "        for odd_cat_i in odd_cat_idx:\n",
    "            current_cat = label[odd_cat_i]\n",
    "            odd_sample = copy.deepcopy(self.odd_category)\n",
    "            odd_sample.remove(current_cat)\n",
    "            replace_cats.append(random.choice(odd_sample))\n",
    "\n",
    "        replace_cats = np.array(replace_cats)\n",
    "\n",
    "        # augmentation\n",
    "        label[odd_cat_idx] = replace_cats\n",
    "        \n",
    "        return label\n",
    "    \n",
    "    def replace_with_random_label(self, label, token_n):\n",
    "        \"\"\"\"\"\"\n",
    "        replace_n = random.randint(30, 100)\n",
    "        replace_idx = np.random.choice(range(1, token_n - 1), size=replace_n, replace=False)\n",
    "        replace_cats = np.random.choice(range(0, 15), size=replace_n, replace=True)\n",
    "\n",
    "        label[replace_idx] = replace_cats\n",
    "\n",
    "        return label\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        targets = copy.deepcopy(self.labels[idx])\n",
    "        inputs = copy.deepcopy(targets)\n",
    "        token_n = self.token_n_list[idx]\n",
    "        \n",
    "        # padding\n",
    "        inputs[token_n:] = 15\n",
    "        targets[token_n:] = 15\n",
    "\n",
    "        # augmentation\n",
    "        inputs = self.replace_with_zero(inputs, token_n)\n",
    "        inputs = self.b_to_i_label(inputs, token_n)\n",
    "        inputs = self.replace_b_label(inputs, token_n)\n",
    "        inputs = self.replace_with_random_label(inputs, token_n)\n",
    "        \n",
    "        return inputs, targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4f34b2",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39eef4b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T16:44:10.523355Z",
     "start_time": "2022-03-14T16:44:10.502591Z"
    }
   },
   "outputs": [],
   "source": [
    "class Callibration(nn.Module):\n",
    "    def __init__(self,\n",
    "                 hidden_size=128,\n",
    "                 n_layers=2,\n",
    "                 device='cuda:0'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.device = device\n",
    "\n",
    "        self.embedding = nn.Embedding(16, hidden_size, padding_idx=15)\n",
    "        self.lstm = nn.LSTM(hidden_size,\n",
    "                            hidden_size,\n",
    "                            n_layers,\n",
    "                            bidirectional=True,\n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, 16)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        h = torch.zeros(self.n_layers * 2, batch_size, self.hidden_size)\n",
    "        h = h.to(self.device)\n",
    "\n",
    "        c = torch.zeros(self.n_layers * 2, batch_size, self.hidden_size)\n",
    "        c = c.to(self.device)\n",
    "\n",
    "        return (h, c)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.size()\n",
    "        out = self.embedding(x)\n",
    "        \n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        out, hidden = self.lstm(out, hidden)\n",
    "        \n",
    "        out = out.contiguous().view(batch_size, -1, self.hidden_size * 2)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcb809c",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82ea9d14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T16:44:10.544588Z",
     "start_time": "2022-03-14T16:44:10.524551Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "853b17ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T16:44:10.561238Z",
     "start_time": "2022-03-14T16:44:10.545943Z"
    }
   },
   "outputs": [],
   "source": [
    "save_path = '../result/callibration'\n",
    "\n",
    "if not osp.exists(save_path):\n",
    "    os.makedirs(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ec7bb1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-14T16:45:24.843Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a7a99157724e6ca4fa3b1e8ca1a43b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ TRAIN ] fold 1 epoch 1 loss: 1.2897\n",
      "[ TRAIN ] fold 1 epoch 1 loss: 0.6929\n",
      "[ TRAIN ] fold 1 epoch 1 loss: 0.4773\n",
      "[ TRAIN ] fold 1 epoch 1 loss: 0.3655\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "755b8cce7de542b8b1163f30a588687a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ VALID ] fold 1 epoch 1 loss: 0.0242\n",
      "[ VALID ] fold 1 epoch 1 loss: 0.0232\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "426f59890218499db38419f809c350d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ TRAIN ] fold 1 epoch 2 loss: 0.0214\n",
      "[ TRAIN ] fold 1 epoch 2 loss: 0.0203\n",
      "[ TRAIN ] fold 1 epoch 2 loss: 0.0194\n",
      "[ TRAIN ] fold 1 epoch 2 loss: 0.0186\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9de9eeb43b1e4427a6fc95adbdcd4a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ VALID ] fold 1 epoch 2 loss: 0.0158\n",
      "[ VALID ] fold 1 epoch 2 loss: 0.0152\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f613fc0845a4928b203d704ec319cec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ TRAIN ] fold 1 epoch 3 loss: 0.0143\n",
      "[ TRAIN ] fold 1 epoch 3 loss: 0.0141\n",
      "[ TRAIN ] fold 1 epoch 3 loss: 0.0137\n",
      "[ TRAIN ] fold 1 epoch 3 loss: 0.0134\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c04da2b5ca80460b9ad1ca0bd1daaee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ VALID ] fold 1 epoch 3 loss: 0.0122\n",
      "[ VALID ] fold 1 epoch 3 loss: 0.0120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f5a394ccc44434b3d8de9491a19ec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fold in range(5):\n",
    "    batch_size = 128\n",
    "    \n",
    "    model = Callibration().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    train_labels = copy.deepcopy(labels[train_idx[fold]])\n",
    "    train_token_n_list = copy.deepcopy(token_n_list[train_idx[fold]])\n",
    "\n",
    "    valid_labels = copy.deepcopy(labels[valid_idx[fold]])\n",
    "    valid_token_n_list = copy.deepcopy(token_n_list[valid_idx[fold]])\n",
    "\n",
    "    train_dataset = CategoryDataset(train_labels, train_token_n_list)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    valid_dataset = CategoryDataset(valid_labels, valid_token_n_list)\n",
    "    valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    for epoch in range(5):\n",
    "        train_losses = []\n",
    "        for step, (inputs, targets) in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            batch_size, seq_len = inputs.size()\n",
    "\n",
    "            preds = model(inputs)\n",
    "            preds = preds.view(batch_size * seq_len, 16)\n",
    "            targets = targets.view(-1)\n",
    "\n",
    "            loss = criterion(preds, targets)\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "            if (step + 1) % 20 == 0:\n",
    "                print(f\"[ TRAIN ] fold {fold + 1} epoch {epoch + 1} loss: {np.array(train_losses).mean():.4f}\")\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        valid_losses = []\n",
    "        for step, (inputs, targets) in tqdm(enumerate(valid_dataloader), total=len(valid_dataloader)):\n",
    "            with torch.no_grad():\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "\n",
    "                batch_size, seq_len = inputs.size()\n",
    "\n",
    "                preds = model(inputs)\n",
    "                preds = preds.view(batch_size * seq_len, 16)\n",
    "                targets = targets.view(-1)\n",
    "\n",
    "                loss = criterion(preds, targets)\n",
    "                valid_losses.append(loss.item())\n",
    "\n",
    "                if (step + 1) % 10 == 0:\n",
    "                    print(f\"[ VALID ] fold {fold + 1} epoch {epoch + 1} loss: {np.array(valid_losses).mean():.4f}\")\n",
    "            \n",
    "        torch.save(model.state_dict(), osp.join(save_path, f'fold_{fold}_callibration.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70452400",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T16:45:11.981994Z",
     "start_time": "2022-03-14T16:45:11.981986Z"
    }
   },
   "outputs": [],
   "source": [
    "token_n = 15\n",
    "inputs = torch.zeros(2048)\n",
    "\n",
    "inputs[token_n:] = 15\n",
    "\n",
    "inputs[:token_n] = torch.Tensor([0, 3, 4, 4, 0, 4, 0, 4, 3, 5, 0, 0, 1, 4, 0])\n",
    "inputs = inputs.long().to(device).unsqueeze(0)\n",
    "\n",
    "output = model(inputs)\n",
    "cal_output = output.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beb157c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T16:45:11.982601Z",
     "start_time": "2022-03-14T16:45:11.982591Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs[:, :15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed3fbd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T16:45:11.983171Z",
     "start_time": "2022-03-14T16:45:11.983163Z"
    }
   },
   "outputs": [],
   "source": [
    "cal_output[:, :15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c07d03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T16:45:11.983823Z",
     "start_time": "2022-03-14T16:45:11.983814Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs[:, :15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7bb99c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T16:45:11.984294Z",
     "start_time": "2022-03-14T16:45:11.984286Z"
    }
   },
   "outputs": [],
   "source": [
    "cal_output[:, :15]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "418.997px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
