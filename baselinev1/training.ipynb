{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48b200f4",
   "metadata": {},
   "source": [
    "# 🦆 Training\n",
    "\n",
    "✅ **needed to be checked**\n",
    "- mixed precision (minor code refactoring done) ✅\n",
    "- loss function (cross entropy loss and rce loss)  ✅\n",
    "- collate (does it properly implemented?)\n",
    "    - assumed torch padding function but was not used\n",
    "- entity_extraction function\n",
    "- does deverta accepted long sequence length even the config setted by 512 seq len?\n",
    "\n",
    "✅ **needed to be added**\n",
    "- training depend on device ✅\n",
    "- model output to prediction string converter\n",
    "- f1macro calculation by prediction string\n",
    "- training mode without gradient accumulation\n",
    "\n",
    "---\n",
    "\n",
    "- Environment Setting\n",
    "- Argument Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bd7c2d",
   "metadata": {},
   "source": [
    "## Environment Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0ab4178",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:17:23.085934Z",
     "start_time": "2022-02-28T17:17:23.077317Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "\n",
    "DATASET_PATH = ('../../feedback-prize-2021')\n",
    "\n",
    "sys.path.insert(0, './codes')\n",
    "sys.path.append('longformer/tvm/python/')\n",
    "sys.path.append('longformer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2a83c79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:17:23.962458Z",
     "start_time": "2022-02-28T17:17:23.087095Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import easydict\n",
    "import argparse\n",
    "\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "import ftfy\n",
    "import dill as pickle\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "from transformers import DebertaV2Model\n",
    "\n",
    "# torch.use_deterministic_algorithms(True)\n",
    "# from longformer.longformer import Longformer, LongformerConfig, RobertaModel\n",
    "# from longformer.sliding_chunks import pad_to_window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fb3b605",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:17:23.966566Z",
     "start_time": "2022-02-28T17:17:23.963573Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\"\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6997bb5",
   "metadata": {},
   "source": [
    "**why using `os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\"`?**\n",
    "- [torch.use_deterministic_algorithms](https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html)\n",
    "> **A handful of CUDA operations are nondeterministic if the CUDA version is 10.2 or greater**, unless the environment variable `CUBLAS_WORKSPACE_CONFIG=:4096:8` or `CUBLAS_WORKSPACE_CONFIG=:16:8` is set. See the CUDA documentation for more details: https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility If one of these environment variable configurations is not set, a RuntimeError will be raised from these operations when called with CUDA tensors:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c96213b",
   "metadata": {},
   "source": [
    "## Argument Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06d834b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:17:23.987520Z",
     "start_time": "2022-02-28T17:17:23.967800Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_config():\n",
    "    parser = argparse.ArgumentParser(description=\"use huggingface models\")\n",
    "    parser.add_argument(\"--wandb_user\", default='ducky', type=str)\n",
    "    parser.add_argument(\"--wandb_project\", default='feedback_deberta_large', type=str)\n",
    "    parser.add_argument(\"--dataset_path\", default='../../feedback-prize-2021', type=str)\n",
    "    parser.add_argument(\"--save_path\", default='result', type=str)\n",
    "    parser.add_argument(\"--seed\", default=0, type=int)\n",
    "    parser.add_argument(\"--min_len\", default=0, type=int)\n",
    "    parser.add_argument(\"--use_groupped_weights\", default=False, type=bool)\n",
    "    parser.add_argument(\"--global_attn\", default=False, type=int)\n",
    "    parser.add_argument(\"--label_smoothing\", default= 0.1, type=float)\n",
    "    parser.add_argument(\"--epochs\", default=9, type=int)\n",
    "    parser.add_argument(\"--batch_size\", default=4, type=int)\n",
    "    parser.add_argument(\"--grad_acc_steps\", default=2, type=int)\n",
    "    parser.add_argument(\"--grad_checkpt\", default=True, type=bool)\n",
    "    parser.add_argument(\"--data_prefix\", default='', type=str)\n",
    "    parser.add_argument(\"--max_grad_norm\", default=35 * 8, type=int)\n",
    "    parser.add_argument(\"--start_eval_at\", default=0, type=int)\n",
    "    parser.add_argument(\"--lr\", default=3e-5, type=float)\n",
    "    parser.add_argument(\"--min_lr\", default=3e-5, type=float)\n",
    "    parser.add_argument(\"--weight_decay\", default=1e-2, type=float)\n",
    "    parser.add_argument(\"--weights_pow\", default=0.1, type=float)\n",
    "    parser.add_argument(\"--dataset_version\", default=2, type=int)\n",
    "    parser.add_argument(\"--warmup_steps\", default=500, type=int)\n",
    "    parser.add_argument(\"--decay_bias\", default=False, type=bool)\n",
    "    parser.add_argument(\"--val_fold\", default=0, type=int)\n",
    "    parser.add_argument(\"--num_worker\", default=8, type=int)\n",
    "    parser.add_argument(\"--local_rank\", type=int, default=-1, help=\"do not modify!\")\n",
    "    parser.add_argument(\"--device\", type=int, default=0, help=\"select the gpu device to train\")\n",
    "\n",
    "    # optimizer\n",
    "    parser.add_argument(\"--rce_weight\", default=0.1, type=float)\n",
    "    parser.add_argument(\"--ce_weight\", default=0.9, type=float)\n",
    "\n",
    "    # model related arguments\n",
    "    parser.add_argument(\"--model\", default=\"microsoft/deberta-v3-large\", type=str)\n",
    "    parser.add_argument(\"--cnn1d\", default=False, type=bool)\n",
    "    parser.add_argument(\"--extra_dense\", default= False, type=bool)\n",
    "    parser.add_argument(\"--dropout_ratio\", default=0.0, type=float)\n",
    "    args = parser.parse_args(args=[])\n",
    "\n",
    "    if args.local_rank !=-1:\n",
    "        print('[ DDP ] local rank', args.local_rank)\n",
    "        torch.cuda.set_device(args.local_rank)\n",
    "        dist.init_process_group(backend='nccl')\n",
    "        args.device = torch.device(\"cuda\", args.local_rank)\n",
    "        args.rank = torch.distributed.get_rank()\n",
    "        args.world_size = torch.distributed.get_world_size()  \n",
    "\n",
    "        # checking settings for distributed training\n",
    "        assert args.batch_size % args.world_size == 0, f'--batch_size {args.batch_size} must be multiple of world size'\n",
    "        assert torch.cuda.device_count() > args.local_rank, 'insufficient CUDA devices for DDP command'\n",
    "\n",
    "        args.ddp = True\n",
    "    else:\n",
    "        args.device = torch.device(\"cuda\")\n",
    "        args.rank = 0\n",
    "        args.ddp = False\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f00e56b",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b57f981b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:17:24.007351Z",
     "start_time": "2022-02-28T17:17:23.988639Z"
    }
   },
   "outputs": [],
   "source": [
    "from module.utils import get_token_weights\n",
    "from module.utils import get_prepare_data\n",
    "from module.utils import get_all_texts\n",
    "from module.utils import get_id_to_ix_map\n",
    "from module.utils import get_fold_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c3dca6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:17:24.016936Z",
     "start_time": "2022-02-28T17:17:24.008874Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data_files(args):\n",
    "    token_weights = get_token_weights(args.use_groupped_weights, args.weights_pow)\n",
    "    data = get_prepare_data()\n",
    "    csv = pd.read_csv(osp.join(args.dataset_path, 'train.csv'))\n",
    "    all_texts = get_all_texts(args)\n",
    "    id_to_ix_map = get_id_to_ix_map()\n",
    "    data_splits = get_fold_data()\n",
    "\n",
    "    # text_id example `16585724607E`\n",
    "    train_text_ids = [text_id for fold in range(5) if fold != args.val_fold for text_id in data_splits[args.seed][250]['normed'][fold]]\n",
    "    val_text_ids = data_splits[args.seed][250]['normed'][args.val_fold]\n",
    "\n",
    "    train_ids = [id_to_ix_map[text_id] for text_id in train_text_ids]\n",
    "    val_ids = [id_to_ix_map[text_id] for text_id in val_text_ids]\n",
    "\n",
    "    return all_texts, token_weights, data, csv, train_ids, val_ids, train_text_ids, val_text_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7774e93",
   "metadata": {},
   "source": [
    "## Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5387adc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:17:24.037276Z",
     "start_time": "2022-02-28T17:17:24.017838Z"
    }
   },
   "outputs": [],
   "source": [
    "def wandb_setting(args):\n",
    "    wandb.login()\n",
    "    run = wandb.init(entity=args.wandb_user, project=args.wandb_project)\n",
    "    run.name = f'v3_fold{args.val_fold}_minlr{args.min_lr}_maxlr{args.lr}_wd{args.weight_decay}_warmup{args.warmup_steps}_gradnorm{args.max_grad_norm}_biasdecay{args.decay_bias}_ls{args.label_smoothing}_wp{args.weights_pow}_data{args.dataset_version}_rce{args.rce_weight}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5d7840",
   "metadata": {},
   "source": [
    "## 🐣 Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f1a60b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:17:24.048024Z",
     "start_time": "2022-02-28T17:17:24.038624Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class TrainDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, ids, data, label_smoothing, token_weights, data_prefix):\n",
    "        self.ids = ids\n",
    "        self.data = data\n",
    "        self.label_smoothing = label_smoothing\n",
    "        self.token_weights = token_weights\n",
    "        self.data_prefix = data_prefix\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i = self.ids[idx]\n",
    "\n",
    "        # load train data\n",
    "        tokens = self.data['tokens'][i]\n",
    "        attention_mask = self.data['attention_masks'][i]\n",
    "        num_tokens = self.data['num_tokens'][i, 0]\n",
    "\n",
    "        # label smoothing\n",
    "        cbio_labels = self.data[f'{self.data_prefix}cbio_labels'][i]\n",
    "        cbio_labels *= (1 - self.label_smoothing)\n",
    "        cbio_labels += self.label_smoothing / 15\n",
    "\n",
    "        # class weight per token\n",
    "        class_weight = np.zeros_like(attention_mask)\n",
    "        argmax_labels = cbio_labels.argmax(-1)\n",
    "\n",
    "        for class_i in range(1, 15):\n",
    "            class_weight[argmax_labels == class_i] = self.token_weights[class_i]\n",
    "\n",
    "        class_none_index = argmax_labels == 0      # 0 is the text that is not entity\n",
    "        class_none_index[num_tokens - 1:] = False  # special token & padding\n",
    "        class_weight[class_none_index] = self.token_weights[0]\n",
    "        class_weight[0] = 0\n",
    "\n",
    "        return tokens, attention_mask, cbio_labels, class_weight, num_tokens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "362dcb5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:17:24.069363Z",
     "start_time": "2022-02-28T17:17:24.048905Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class ValDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, ids, data, csv, all_texts, val_text_ids, class_names, token_weights):\n",
    "        self.ids = ids\n",
    "        self.data = data\n",
    "        self.csv = csv\n",
    "        self.space_regex = re.compile('[\\s\\n]')\n",
    "        self.all_texts = all_texts\n",
    "        self.val_text_ids = val_text_ids\n",
    "        self.class_names = class_names\n",
    "        self.token_weights = token_weights\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i = self.ids[idx]\n",
    "\n",
    "        # load text data & text dataframe\n",
    "        text_id = self.val_text_ids[idx]\n",
    "        text = self.all_texts[text_id]\n",
    "        sample_df = self.csv.query('id == @text_id')\n",
    "\n",
    "        # load ground truth prediction string for f1macro metric\n",
    "        gt_dict = {}\n",
    "        for class_i in range(1, 8):\n",
    "            class_name = self.class_names[class_i]\n",
    "            class_df = sample_df.query('discourse_type == @class_name')   \n",
    "            if len(class_df):\n",
    "                gt_dict[class_i] = [(x[0], x[1]) for x in class_df.predictionstring.map(split_predstring)]\n",
    "        \n",
    "        # load valid data\n",
    "        tokens = self.data['tokens'][i]\n",
    "        attention_mask = self.data['attention_masks'][i]\n",
    "        num_tokens = self.data['num_tokens'][i, 0]\n",
    "        token_bounds = self.data['token_offsets'][i]\n",
    "        cbio_labels = self.data['cbio_labels'][i]\n",
    "        \n",
    "        # class weight per token\n",
    "        class_weight = np.zeros_like(attention_mask)\n",
    "        argmax_labels = cbio_labels.argmax(-1)\n",
    "\n",
    "        for class_i in range(1, 15):\n",
    "            class_weight[argmax_labels == class_i] = self.token_weights[class_i]\n",
    "\n",
    "        class_none_index = argmax_labels == 0\n",
    "        class_none_index[num_tokens - 1:] = False\n",
    "        class_weight[class_none_index] = self.token_weights[0]\n",
    "        class_weight[0] = 0\n",
    "        \n",
    "        # ???\n",
    "        index_map = []\n",
    "        current_word = 0\n",
    "        blank = False\n",
    "        for char_ix in range(text.index(text.strip()[0]), len(text)):\n",
    "            if self.space_regex.match(text[char_ix]) is not None:\n",
    "                blank = True\n",
    "            elif blank:\n",
    "                current_word += 1\n",
    "                blank = False\n",
    "            index_map.append(current_word)\n",
    "        \n",
    "        return tokens, attention_mask, cbio_labels, class_weight, token_bounds, gt_dict, index_map, num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "963b1afe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:17:24.087046Z",
     "start_time": "2022-02-28T17:17:24.072058Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_dataloader(train_ids, val_ids, data, csv, all_texts, val_text_ids, class_names, token_weights, args):\n",
    "    train_dataset = TrainDataset(train_ids, data, args.label_smoothing, token_weights, args.data_prefix)\n",
    "    val_dataset = ValDataset(val_ids, data, csv, all_texts, val_text_ids, class_names, token_weights)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, collate_fn=train_collate_fn, batch_size=args.batch_size, num_workers=args.num_worker)\n",
    "    val_dataloader = DataLoader(val_dataset, collate_fn=val_collate_fn, batch_size=args.batch_size, num_workers=8, persistent_workers=True)\n",
    "\n",
    "    return train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a0cdc7",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c5639ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:17:24.109619Z",
     "start_time": "2022-02-28T17:17:24.088215Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "first_batch = True\n",
    "def train_collate_fn(ins):\n",
    "    global first_batch\n",
    "    if first_batch:\n",
    "        max_len = 2048\n",
    "        first_batch = False\n",
    "    else:\n",
    "        max_len = (max(x[-1] for x in ins) + 7) // 8 * 8\n",
    "        \n",
    "    return tuple(torch.from_numpy(np.concatenate([ins[z][x][None, :max_len] for z in range(len(ins))])) for x in range(len(ins[0]) - 1))\n",
    "    \n",
    "def val_collate_fn(ins):\n",
    "    max_len = (max(x[-1] for x in ins) + 7) // 8 * 8\n",
    "    return tuple(torch.from_numpy(np.concatenate([ins[z][x][None, :max_len] for z in range(len(ins))])) for x in range(len(ins[0]) - 3)) + ([x[-3] for x in ins], [x[-2] for x in ins], np.array([x[-1] for x in ins]),)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6f4d96",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5e317d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:17:24.124751Z",
     "start_time": "2022-02-28T17:17:24.111034Z"
    }
   },
   "outputs": [],
   "source": [
    "def custom_ce(preds, gts, class_weight):\n",
    "    preds = torch.log_softmax(preds, -1)\n",
    "    loss = -(((preds * gts).sum(-1) * class_weight).sum(-1) / class_weight.sum(-1)).mean()\n",
    "\n",
    "    return loss\n",
    "\n",
    "def custom_rce(preds, gts, class_weight):\n",
    "    preds = torch.log_softmax(preds, -1)\n",
    "    loss = -(((torch.exp(preds) * torch.log_softmax(gts, -1)).sum(-1) * class_weight).sum(-1) / class_weight.sum(-1)).mean()\n",
    "\n",
    "    return loss\n",
    "\n",
    "class Criterion():\n",
    "    \"\"\"Wrapper for multi criterion calculation\"\"\"\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        self.criterions = self.get_criterions()\n",
    "        self.criterion_names = self.args.criterion_list\n",
    "        self.criterion_ratios = args.criterion_ratio\n",
    "\n",
    "    def get_criterions(self):\n",
    "        criterions = []\n",
    "        for criterion in self.args.criterion_list:\n",
    "            if criterion == \"crossentropy\":\n",
    "                criterions.append(nn.CrossEntropyLoss(weight=self.args.class_weight,\n",
    "                                                      label_smoothing=self.args.label_smoothing))\n",
    "            elif criterion == \"custom_ce\":\n",
    "                criterions.append(custom_ce)\n",
    "            elif criterion == \"custom_rce\":\n",
    "                criterions.append(custom_rce)\n",
    "                \n",
    "        return criterions\n",
    "\n",
    "    def reshape(self, preds, gts):\n",
    "        \"\"\"TODO: fix the dataloader to argmax label version and change this code\"\"\"\n",
    "        return preds.view(-1, 15), gts.argmax(-1).view(-1)\n",
    "    \n",
    "    def calculate_loss(self, preds, gts, class_weight=None):\n",
    "        total_loss = 0\n",
    "        for criterion_name, criterion, ratio in zip(self.criterion_names, self.criterions, self.criterion_ratios):\n",
    "            if criterion_name in ['custom_ce', 'custom_rce']:\n",
    "                current_loss = criterion(preds, gts, class_weight)\n",
    "            else:\n",
    "                # TODO: tailored for current dataloader\n",
    "                preds_, gts_ = self.reshape(preds, gts)\n",
    "                current_loss = criterion(preds_, gts_)\n",
    "            total_loss = total_loss + current_loss * ratio\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def __call__(self, preds, gts, class_weight=None):\n",
    "        return self.calculate_loss(preds, gts, class_weight)\n",
    "\n",
    "\n",
    "\n",
    "def get_criterion(args):\n",
    "    criterion = Criterion(args)\n",
    "\n",
    "    return criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fa7e34",
   "metadata": {},
   "source": [
    "## 🧣 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d18f08f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:17:24.144050Z",
     "start_time": "2022-02-28T17:17:24.126021Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class DebertaV3Large(torch.nn.Module):\n",
    "    \"\"\"microsoft/deberta-v3-large\"\"\"\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "\n",
    "        self.feats = DebertaV2Model.from_pretrained('microsoft/deberta-v3-large')\n",
    "        self.feats.pooler = None\n",
    "\n",
    "        if args.grad_checkpt:\n",
    "            self.feats.gradient_checkpointing_enable()\n",
    "\n",
    "        if args.cnn1d:\n",
    "            self.conv1d_layer1 = torch.nn.Conv1d(1024, 1024, kernel_size=1)\n",
    "            self.conv1d_layer3 = torch.nn.Conv1d(1024, 1024, kernel_size=3, padding=1)\n",
    "            self.conv1d_layer5 = torch.nn.Conv1d(1024, 1024, kernel_size=5, padding=2)\n",
    "\n",
    "            self.output_length = 1024 * 3\n",
    "        else:\n",
    "            self.output_length = 1024\n",
    "\n",
    "        if args.extra_dense:\n",
    "            self.class_projector = torch.nn.Sequential(\n",
    "                torch.nn.LayerNorm(self.output_length),\n",
    "                torch.nn.Linear(self.output_length, 256),\n",
    "                torch.nn.GELU(),\n",
    "                torch.nn.Linear(256, 15)\n",
    "            )\n",
    "        else:\n",
    "            self.class_projector = torch.nn.Sequential(\n",
    "                torch.nn.LayerNorm(self.output_length),\n",
    "                torch.nn.Linear(self.output_length, 15)\n",
    "            )\n",
    "\n",
    "    def forward(self, tokens, mask):\n",
    "        transformer_output = self.feats(tokens, mask, return_dict=False)[0]\n",
    "        \n",
    "        if self.args.cnn1d:\n",
    "            conv_input = transformer_output.transpose(1, 2) # batch, hidden, seq\n",
    "\n",
    "            conv_output1 = F.relu(self.conv1d_layer1(conv_input)) \n",
    "            conv_output3 = F.relu(self.conv1d_layer3(conv_input)) \n",
    "            conv_output5 = F.relu(self.conv1d_layer5(conv_input)) \n",
    "\n",
    "            concat_output = torch.cat((conv_output1, conv_output3, conv_output5), dim=1).transpose(1, 2)\n",
    "            output = self.class_projector(concat_output)\n",
    "        else:\n",
    "            output = self.class_projector(transformer_output) # batch, seq, hidden\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "568cb661",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:17:24.164471Z",
     "start_time": "2022-02-28T17:17:24.145494Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(args):\n",
    "    if args.model == 'microsoft/deberta-v3-large':\n",
    "        model = DebertaV3Large(args).to(args.device)\n",
    "\n",
    "        # dropout layer\n",
    "        for m in model.modules():\n",
    "            if isinstance(m, torch.nn.Dropout):\n",
    "                m.p = args.dropout_ratio\n",
    "\n",
    "    # distributed training\n",
    "    if args.ddp:\n",
    "        model = DDP(model, device_ids=[args.rank], output_device=args.rank)\n",
    "        model.to(args.device)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccfe346",
   "metadata": {},
   "source": [
    "\n",
    "## 🚵🏻 Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cf55134",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:17:24.208073Z",
     "start_time": "2022-02-28T17:17:24.165837Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac4b776f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:17:25.026801Z",
     "start_time": "2022-02-28T17:17:24.209027Z"
    }
   },
   "outputs": [],
   "source": [
    "from module.metric import calc_acc, process_sample, make_match_dict\n",
    "\n",
    "from module.utils import get_data_files\n",
    "from module.dataset import get_dataloader\n",
    "from module.loss import get_criterion\n",
    "from module.optimizer import get_optimizer\n",
    "from module.scheduler import get_scheduler\n",
    "from model.model import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2a12c3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:17:25.061638Z",
     "start_time": "2022-02-28T17:17:25.027916Z"
    }
   },
   "outputs": [],
   "source": [
    "seed_everything(42)\n",
    "args = get_config()\n",
    "# wandb_setting(args)\n",
    "\n",
    "class_names = ['None',\n",
    "               'Lead',\n",
    "               'Position',\n",
    "               'Evidence',\n",
    "               'Claim',\n",
    "               'Concluding Statement',\n",
    "               'Counterclaim',\n",
    "               'Rebuttal']\n",
    "\n",
    "# create directory to save model\n",
    "if not osp.exists(args.save_path):\n",
    "    os.makedirs(args.save_path)\n",
    "\n",
    "args.batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f41ab2d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:17:25.093698Z",
     "start_time": "2022-02-28T17:17:25.062759Z"
    }
   },
   "outputs": [],
   "source": [
    "args.device = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61c70ef4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:17:32.266138Z",
     "start_time": "2022-02-28T17:17:25.094743Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "args.model = 'microsoft/deberta-v3-large'\n",
    "model = get_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53dd3040",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:17:33.055528Z",
     "start_time": "2022-02-28T17:17:32.267103Z"
    }
   },
   "outputs": [],
   "source": [
    "all_texts, token_weights, data, csv, train_ids, val_ids, train_text_ids, val_text_ids = get_data_files(args)\n",
    "train_dataloader, val_dataloader = get_dataloader(args, train_ids, val_ids, data, csv, all_texts, val_text_ids, class_names, token_weights)\n",
    "\n",
    "args.criterion_list = [\"custom_ce\", \"custom_rce\"]\n",
    "args.criterion_ratio = [args.ce_weight, args.rce_weight]\n",
    "criterion = get_criterion(args)\n",
    "\n",
    "args.optimizer = \"adam\"\n",
    "optimizer = get_optimizer(args, model)\n",
    "\n",
    "# scheduler\n",
    "args.steps_per_epoch = len(train_dataloader)\n",
    "args.scheduler = \"plateau\"\n",
    "scheduler = get_scheduler(args, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec8dd426",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:17:33.092931Z",
     "start_time": "2022-02-28T17:17:33.056512Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV3Large(\n",
       "  (feats): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 1024, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (1): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (2): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (3): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (4): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (5): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (6): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (7): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (8): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (9): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (10): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (11): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (12): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (13): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (14): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (15): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (16): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (17): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (18): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (19): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (20): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (21): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (22): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (23): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (class_projector): Sequential(\n",
       "    (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=1024, out_features=15, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745adcc5",
   "metadata": {},
   "source": [
    "## SWA (Stochastic Weighted Average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "169722f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:17:41.868101Z",
     "start_time": "2022-02-28T17:17:41.775986Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim.swa_utils import AveragedModel, SWALR\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "swa_model = AveragedModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45dad13d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:17:42.048271Z",
     "start_time": "2022-02-28T17:17:42.017617Z"
    }
   },
   "outputs": [],
   "source": [
    "args.steps_per_epoch = len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8f66891",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:17:42.287671Z",
     "start_time": "2022-02-28T17:17:42.255683Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6227"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8672d60b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:21:39.108483Z",
     "start_time": "2022-02-28T17:21:39.054137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('feats.embeddings.word_embeddings.weight', Parameter containing:\n",
      "tensor([[-0.0481, -0.0435, -0.0472,  ..., -0.0504, -0.0499, -0.0345],\n",
      "        [-0.0016, -0.0074,  0.0130,  ..., -0.0136, -0.0066, -0.0036],\n",
      "        [-0.0035, -0.0076,  0.0116,  ..., -0.0137, -0.0063, -0.0046],\n",
      "        ...,\n",
      "        [-0.0476, -0.0571, -0.0349,  ..., -0.0569, -0.0481, -0.0336],\n",
      "        [-0.0425, -0.0474, -0.0440,  ..., -0.0526, -0.0543, -0.0435],\n",
      "        [-0.0376, -0.0404, -0.0396,  ..., -0.0565, -0.0464, -0.0312]],\n",
      "       device='cuda:2', requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for i in model.named_parameters():\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "01204a65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:22:06.998870Z",
     "start_time": "2022-02-28T17:22:06.960961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('module.feats.embeddings.word_embeddings.weight', Parameter containing:\n",
      "tensor([[-0.0493, -0.0447, -0.0484,  ..., -0.0516, -0.0511, -0.0357],\n",
      "        [-0.0016, -0.0078,  0.0130,  ..., -0.0137, -0.0064, -0.0036],\n",
      "        [-0.0034, -0.0079,  0.0116,  ..., -0.0139, -0.0061, -0.0046],\n",
      "        ...,\n",
      "        [-0.0488, -0.0583, -0.0361,  ..., -0.0581, -0.0493, -0.0347],\n",
      "        [-0.0437, -0.0486, -0.0452,  ..., -0.0538, -0.0555, -0.0447],\n",
      "        [-0.0388, -0.0416, -0.0408,  ..., -0.0577, -0.0476, -0.0324]],\n",
      "       device='cuda:2', requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for i in swa_model.named_parameters():\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2d3b303",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:19:16.891494Z",
     "start_time": "2022-02-28T17:19:16.852571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('module.feats.embeddings.word_embeddings.weight', Parameter containing:\n",
      "tensor([[-0.0502, -0.0456, -0.0493,  ..., -0.0525, -0.0520, -0.0366],\n",
      "        [-0.0016, -0.0079,  0.0130,  ..., -0.0137, -0.0063, -0.0036],\n",
      "        [-0.0034, -0.0080,  0.0117,  ..., -0.0141, -0.0059, -0.0046],\n",
      "        ...,\n",
      "        [-0.0497, -0.0593, -0.0371,  ..., -0.0591, -0.0503, -0.0357],\n",
      "        [-0.0446, -0.0495, -0.0461,  ..., -0.0548, -0.0565, -0.0456],\n",
      "        [-0.0397, -0.0425, -0.0417,  ..., -0.0586, -0.0485, -0.0334]],\n",
      "       device='cuda:2', requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for i in swa_model.named_parameters():\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "171e7bb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:18:06.446286Z",
     "start_time": "2022-02-28T17:18:06.410949Z"
    }
   },
   "outputs": [],
   "source": [
    "step_half_cycle = 5\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=step_half_cycle, eta_min=1e-7)\n",
    "swa_start = step_half_cycle * 3\n",
    "swa_save_per_steps = int(args.steps_per_epoch / 3)\n",
    "\n",
    "# SWA was intended to be used by epoch but here it will be used by steps\n",
    "# the main reason is the model is slow and heavy so cannot afford so much epochs\n",
    "swa_scheduler = SWALR(optimizer, swa_lr=1e-5, anneal_epochs=args.steps_per_epoch, anneal_strategy='cos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7809a8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:18:09.404971Z",
     "start_time": "2022-02-28T17:18:09.370796Z"
    }
   },
   "outputs": [],
   "source": [
    "swa_start = 15\n",
    "swa_save_per_step = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d86be03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:21:16.109173Z",
     "start_time": "2022-02-28T17:20:16.184022Z"
    }
   },
   "outputs": [],
   "source": [
    "for step, batch in enumerate(train_dataloader):\n",
    "    print(f'current step is {step}')\n",
    "    tokens, mask, label, class_weight = (x.to(args.device) for x in batch)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    outs = model(tokens, mask)\n",
    "    loss = criterion(outs, label, class_weight=class_weight)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (step + 1) > swa_start:\n",
    "        if (step + 1) % swa_save_per_step == 0:\n",
    "            print('working on swa!!!')\n",
    "            swa_model.update_parameters(model)\n",
    "        swa_scheduler.step()\n",
    "    else:\n",
    "        scheduler.step()\n",
    "        \n",
    "    for param_group in optimizer.param_groups:\n",
    "        print('lr', param_group['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34307d35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:17:33.278366Z",
     "start_time": "2022-02-28T17:17:33.278359Z"
    }
   },
   "outputs": [],
   "source": [
    "# Update bn statistics for the swa_model at the end\n",
    "torch.optim.swa_utils.update_bn(loader, swa_model)\n",
    "# Use swa_model to make predictions on test data \n",
    "preds = swa_model(test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cce0ac1",
   "metadata": {},
   "source": [
    "# Test Laboratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e1e6ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:17:33.278814Z",
     "start_time": "2022-02-28T17:17:33.278806Z"
    }
   },
   "outputs": [],
   "source": [
    "STOP!!!! YOU SHALL NOT PASS!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8785413",
   "metadata": {},
   "source": [
    "## scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ac1f72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:17:33.280112Z",
     "start_time": "2022-02-28T17:17:33.280104Z"
    }
   },
   "outputs": [],
   "source": [
    "args.min_lr = 1e-07\n",
    "\n",
    "lr_schedule = np.r_[np.linspace(0, args.lr, args.warmup_steps),\n",
    "                    (np.cos(np.linspace(0, np.pi, len(train_dataloader)*args.epochs - args.warmup_steps)) * .5 + .5) * (args.lr - args.min_lr)\n",
    "                    + args.min_lr]\n",
    "\n",
    "plt.plot(np.arange(len(lr_schedule)), lr_schedule)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84db536a",
   "metadata": {},
   "source": [
    "## cross entropy check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ed3e27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:17:33.280614Z",
     "start_time": "2022-02-28T17:17:33.280607Z"
    }
   },
   "outputs": [],
   "source": [
    "args.criterion_list = [\"crossentropy\", \"custom_rce\"]\n",
    "args.criterion_ratio = [args.ce_weight, args.rce_weight]\n",
    "args.class_weight = torch.Tensor(token_weights).to(args.device).half()\n",
    "\n",
    "criterion = get_criterion(args)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414bc2fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:17:33.280995Z",
     "start_time": "2022-02-28T17:17:33.280988Z"
    }
   },
   "outputs": [],
   "source": [
    "loss = criterion(outs, label, class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b058821",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:17:33.281453Z",
     "start_time": "2022-02-28T17:17:33.281445Z"
    }
   },
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c802c0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T17:17:33.281870Z",
     "start_time": "2022-02-28T17:17:33.281863Z"
    }
   },
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261a6307",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "261.033px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
