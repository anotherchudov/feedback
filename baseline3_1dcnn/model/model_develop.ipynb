{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e690ede",
   "metadata": {},
   "source": [
    "# Model Developing\n",
    "\n",
    "> Notebook that will be used to build model and check the specification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e58c8cc",
   "metadata": {},
   "source": [
    "## Hugging face"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3def0396",
   "metadata": {},
   "source": [
    "### DebertaV2\n",
    "> Will check it out with pretrained and both bert\n",
    "\n",
    "- [deberta_v2 - huggingface documentation](https://huggingface.co/transformers/v4.8.2/model_doc/deberta_v2.html)\n",
    "- [deberta-v3-large - huggingface website](https://huggingface.co/microsoft/deberta-v3-large)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21d8d5e",
   "metadata": {},
   "source": [
    "### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dd7e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "try:\n",
    "    from transformers.modeling_bert import BertConfig, BertEncoder, BertModel    \n",
    "except:\n",
    "    from transformers.models.bert.modeling_bert import BertConfig, BertEncoder, BertModel    \n",
    "\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.cfg = cfg\n",
    "        self.cate_emb = nn.Embedding(cfg.cate_vocab_size, cfg.emb_size, padding_idx=0)\n",
    "        self.cate_proj = nn.Sequential(\n",
    "            nn.Linear(cfg.emb_size*cfg.cate_col_size*cfg.n_rows_per_step, cfg.hidden_size),\n",
    "            nn.LayerNorm(cfg.hidden_size),\n",
    "        )\n",
    "        self.cont_bn = nn.BatchNorm1d(cfg.cont_col_size)\n",
    "        self.cont_emb = nn.Sequential(\n",
    "            nn.Linear(cfg.cont_col_size*cfg.n_rows_per_step, cfg.hidden_size),\n",
    "            nn.LayerNorm(cfg.hidden_size),\n",
    "        )\n",
    "        self.comb_proj = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(cfg.hidden_size*2, cfg.hidden_size),\n",
    "            nn.LayerNorm(cfg.hidden_size),\n",
    "        )\n",
    "        \n",
    "        self.encoder = nn.LSTM(cfg.hidden_size, \n",
    "                            cfg.hidden_size, cfg.nlayers, dropout=cfg.dropout, batch_first=True)           \n",
    "        \n",
    "        def get_reg():\n",
    "            return nn.Sequential(\n",
    "            nn.Linear(cfg.hidden_size, cfg.hidden_size),\n",
    "            nn.LayerNorm(cfg.hidden_size),\n",
    "            nn.Dropout(cfg.dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(cfg.hidden_size, cfg.target_size),\n",
    "        )\n",
    "        self.reg_layer = get_reg()\n",
    "        \n",
    "    def forward(self, cate_x, cont_x, mask):        \n",
    "        batch_size = cate_x.size(0)\n",
    "        \n",
    "        cont_x = self.cont_bn(cont_x.view(-1, cont_x.size(-1))).view(batch_size, -1, cont_x.size(-1))\n",
    "        \n",
    "        half_seq_len = cate_x.size(1) // self.cfg.n_rows_per_step\n",
    "        cate_emb = self.cate_emb(cate_x).view(batch_size, half_seq_len, -1)\n",
    "        cate_emb = self.cate_proj(cate_emb)\n",
    "        cont_emb = self.cont_emb(cont_x.view(batch_size, half_seq_len, -1))\n",
    "        \n",
    "        seq_emb = torch.cat([cate_emb, cont_emb], 2)\n",
    "        \n",
    "        seq_emb = self.comb_proj(seq_emb)\n",
    "        \n",
    "        _, (h, c) = self.encoder(seq_emb)\n",
    "        sequence_output = h[-1]\n",
    "        \n",
    "        pred_y = self.reg_layer(sequence_output)\n",
    "        return pred_y\n",
    "\n",
    "\n",
    "class DSB_BertModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(DSB_BertModel, self).__init__()\n",
    "        self.cfg = cfg\n",
    "        self.cate_emb = nn.Embedding(cfg.cate_vocab_size, cfg.emb_size, padding_idx=0)\n",
    "        self.cate_proj = nn.Sequential(\n",
    "            nn.Linear(cfg.emb_size*cfg.cate_col_size*cfg.n_rows_per_step, cfg.hidden_size),\n",
    "            nn.LayerNorm(cfg.hidden_size),\n",
    "        )\n",
    "        self.cont_bn = nn.BatchNorm1d(cfg.cont_col_size)\n",
    "        self.cont_emb = nn.Sequential(\n",
    "            nn.Linear(cfg.cont_col_size*cfg.n_rows_per_step, cfg.hidden_size),\n",
    "            nn.LayerNorm(cfg.hidden_size),\n",
    "        )\n",
    "        self.comb_proj = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(cfg.hidden_size*2, cfg.hidden_size),\n",
    "            nn.LayerNorm(cfg.hidden_size),\n",
    "        )\n",
    "        \n",
    "        self.config = BertConfig( \n",
    "            3, # not used\n",
    "            hidden_size=cfg.hidden_size,\n",
    "            num_hidden_layers=cfg.nlayers,\n",
    "            num_attention_heads=cfg.nheads,\n",
    "            intermediate_size=cfg.hidden_size,\n",
    "            hidden_dropout_prob=cfg.dropout,\n",
    "            attention_probs_dropout_prob=cfg.dropout,            \n",
    "        )\n",
    "        self.encoder = BertModel(self.config)        \n",
    "        \n",
    "        def get_reg():\n",
    "            return nn.Sequential(\n",
    "            nn.Linear(cfg.hidden_size, cfg.hidden_size),\n",
    "            nn.LayerNorm(cfg.hidden_size),\n",
    "            nn.Dropout(cfg.dropout),\n",
    "            nn.ReLU(),            \n",
    "            nn.Linear(cfg.hidden_size, cfg.target_size),\n",
    "        )\n",
    "        self.reg_layer = get_reg()\n",
    "        \n",
    "    def forward(self, cate_x, cont_x, mask):        \n",
    "        batch_size = cate_x.size(0)        \n",
    "        \n",
    "        cont_x = self.cont_bn(cont_x.view(-1, cont_x.size(-1))).view(batch_size, -1, cont_x.size(-1))        \n",
    "        \n",
    "        half_seq_len = cate_x.size(1) // self.cfg.n_rows_per_step\n",
    "        cate_emb = self.cate_emb(cate_x).view(batch_size, half_seq_len, -1)\n",
    "        cate_emb = self.cate_proj(cate_emb)\n",
    "        cont_emb = self.cont_emb(cont_x.view(batch_size, half_seq_len, -1))        \n",
    "        seq_emb = torch.cat([cate_emb, cont_emb], 2)        \n",
    "        seq_emb = self.comb_proj(seq_emb)   \n",
    "        mask, _ = mask.view(batch_size, half_seq_len, -1).max(2)\n",
    "        \n",
    "        encoded_layers = self.encoder(inputs_embeds=seq_emb, attention_mask=mask)\n",
    "        sequence_output = encoded_layers[0]\n",
    "        sequence_output = sequence_output[:, -1]        \n",
    "        \n",
    "        pred_y = self.reg_layer(sequence_output)\n",
    "        return pred_y\n",
    "\n",
    "\n",
    "class LSTMATTNModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(LSTMATTNModel, self).__init__()\n",
    "        self.cfg = cfg\n",
    "        self.cate_emb = nn.Embedding(cfg.cate_vocab_size, cfg.emb_size, padding_idx=0)\n",
    "        self.cate_proj = nn.Sequential(\n",
    "            nn.Linear(cfg.emb_size * cfg.cate_col_size * cfg.n_rows_per_step, cfg.hidden_size),\n",
    "            nn.LayerNorm(cfg.hidden_size),\n",
    "        )\n",
    "        self.cont_bn = nn.BatchNorm1d(cfg.cont_col_size)\n",
    "        self.cont_emb = nn.Sequential(\n",
    "            nn.Linear(cfg.cont_col_size * cfg.n_rows_per_step, cfg.hidden_size),\n",
    "            nn.LayerNorm(cfg.hidden_size),\n",
    "        )\n",
    "        self.comb_proj = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(cfg.hidden_size * 2, cfg.hidden_size),\n",
    "            nn.LayerNorm(cfg.hidden_size),\n",
    "        )\n",
    "        # self.cnn = nn.Sequential(\n",
    "        #     nn.Conv1d(cfg.hidden_size, cfg.hidden_size, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "        #     nn.BatchNorm1d(cfg.hidden_size),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Dropout(cfg.dropout)\n",
    "        # )\n",
    "        self.encoder = nn.LSTM(cfg.hidden_size, cfg.hidden_size, 1,\n",
    "                               bidirectional=False, dropout=cfg.dropout, batch_first=True)\n",
    "        self.config = BertConfig( \n",
    "            3, # not used\n",
    "            hidden_size=cfg.hidden_size,\n",
    "            num_hidden_layers=1,\n",
    "            num_attention_heads=cfg.nheads,\n",
    "            intermediate_size=cfg.hidden_size,\n",
    "            hidden_dropout_prob=cfg.dropout,\n",
    "            attention_probs_dropout_prob=cfg.dropout,\n",
    "        )\n",
    "        self.attn = BertEncoder(self.config)                 \n",
    "        def get_reg():\n",
    "            return nn.Sequential(\n",
    "            nn.Linear(cfg.hidden_size, cfg.hidden_size),\n",
    "            nn.LayerNorm(cfg.hidden_size),\n",
    "            nn.Dropout(cfg.dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(cfg.hidden_size, cfg.hidden_size),\n",
    "            nn.LayerNorm(cfg.hidden_size),\n",
    "            nn.Dropout(cfg.dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(cfg.hidden_size, cfg.target_size),            \n",
    "        )           \n",
    "        self.reg_layer = get_reg()\n",
    "    def forward(self, cate_x, cont_x, mask):        \n",
    "        batch_size = cate_x.size(0)\n",
    "        # ac->prev_ac, rel_ac->prev_rel_ac\n",
    "        # cont_x[:, 1:, -2:] = cont_x[:, :-1, -2:].clone()\n",
    "        # cont_x[:, 0, -2:] = 0\n",
    "        cont_x = self.cont_bn(cont_x.view(-1, cont_x.size(-1))).view(batch_size, -1, cont_x.size(-1))\n",
    "        half_seq_len = cate_x.size(1) // self.cfg.n_rows_per_step\n",
    "        cate_emb = self.cate_emb(cate_x).view(batch_size, half_seq_len, -1)\n",
    "        cate_emb = self.cate_proj(cate_emb)\n",
    "        cont_emb = self.cont_emb(cont_x.view(batch_size, half_seq_len, -1))        \n",
    "        seq_emb = torch.cat([cate_emb, cont_emb], 2)        \n",
    "        seq_emb = self.comb_proj(seq_emb)   \n",
    "        mask, _ = mask.view(batch_size, half_seq_len, -1).max(2)\n",
    "        # seq_emb = self.cnn(seq_emb.transpose(1, 2).contiguous()).transpose(1, 2).contiguous()\n",
    "        output, _ = self.encoder(seq_emb)\n",
    "        extended_attention_mask = mask.unsqueeze(1).unsqueeze(2)\n",
    "        extended_attention_mask = extended_attention_mask.to(dtype=torch.float32)\n",
    "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "        head_mask = [None] * self.config.num_hidden_layers\n",
    "        encoded_layers = self.attn(output, extended_attention_mask, head_mask=head_mask)        \n",
    "        sequence_output = encoded_layers[-1]\n",
    "        sequence_output = sequence_output[:, -1]\n",
    "        pred_y = self.reg_layer(sequence_output)\n",
    "        return pred_y\n",
    "\n",
    "\n",
    "def load_model(model_path, user_states, n_rows_per_step=2):\n",
    "    # 미리 정의된 설정 값\n",
    "    class CFG:\n",
    "        learning_rate=1.0e-4 # 러닝 레이트\n",
    "        batch_size=64 # 배치 사이즈\n",
    "        num_workers=4 # 워커의 개수\n",
    "        print_freq=50 # 결과 출력 빈도\n",
    "        valid_freq=1\n",
    "        start_epoch=0 # 시작 에폭\n",
    "        #num_pretrain_epochs=10\n",
    "        num_train_epochs=10 # 학습할 에폭수\n",
    "        warmup_steps=10 # lr을 서서히 증가시킬 step 수\n",
    "        max_grad_norm=10 # 그래디언트 클리핑에 사용\n",
    "        weight_decay=0.01\n",
    "        dropout=0.0 # dropout 확률    \n",
    "        emb_size=200\n",
    "        hidden_size=512 # 은닉 크기\n",
    "        nlayers=2\n",
    "        nheads=8\n",
    "        seq_len=100\n",
    "        cate_vocab_size=0\n",
    "        cate_col_size=0\n",
    "        cont_col_size=0\n",
    "        target_size=1\n",
    "        n_rows_per_step=2\n",
    "    \n",
    "    CFG.n_rows_per_step = n_rows_per_step  \n",
    "    CFG.cate_vocab_size = max(list(user_states.cate2id_dict['qu_content2id'].values())) + 1\n",
    "    print(CFG.cate_vocab_size)\n",
    "    CFG.cate_col_size = len(user_states.cate_cols)\n",
    "    CFG.cont_col_size = len(user_states.cont_cols)\n",
    "    # 카테고리 분류기 모델을 생성합니다.\n",
    "    \n",
    "    tokens = model_path.split('/')[-1].split('_')\n",
    "    seq_len = int([tok for tok in tokens if tok[:3]=='len'][0][3:])\n",
    "    hidden_size = int([tok for tok in tokens if tok[0]=='h'][0][1:])\n",
    "    architecture = [tok for tok in tokens if tok[0]=='a'][0][1:]\n",
    "    cfg = CFG()\n",
    "    cfg.hidden_size = hidden_size\n",
    "    cfg.seq_len = seq_len\n",
    "    cfg.encoder = architecture\n",
    "    model = encoders[architecture](cfg)\n",
    "    \n",
    "    checkpoint = torch.load(model_path, map_location='cpu')\n",
    "    state_dict = checkpoint['state_dict']\n",
    "    \n",
    "    model.load_state_dict(state_dict, strict=True)  \n",
    "    print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "          .format(model_path, checkpoint['epoch']))\n",
    "    \n",
    "    return model\n",
    "\n",
    "encoders = {\n",
    "    'LSTM':LSTMModel,\n",
    "    'LSTMATTN':LSTMATTNModel,    \n",
    "    'BERT':DSB_BertModel,\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "437.215px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
