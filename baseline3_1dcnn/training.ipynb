{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48b200f4",
   "metadata": {},
   "source": [
    "# ü¶Ü Training\n",
    "\n",
    "‚úÖ **needed to be checked**\n",
    "- mixed precision (minor code refactoring done) ‚úÖ\n",
    "- loss function (cross entropy loss and rce loss)\n",
    "- collate (does it properly implemented?)\n",
    "    - assumed torch padding function but was not used\n",
    "- entity_extraction function\n",
    "- does deverta accepted long sequence length even the config setted by 512 seq len?\n",
    "\n",
    "‚úÖ **needed to be added**\n",
    "- training depend on device\n",
    "- model output to prediction string converter\n",
    "- f1macro calculation by prediction string\n",
    "- training mode without gradient accumulation\n",
    "\n",
    "---\n",
    "\n",
    "- Environment Setting\n",
    "- Argument Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bd7c2d",
   "metadata": {},
   "source": [
    "## Environment Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0ab4178",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T08:18:45.895478Z",
     "start_time": "2022-02-27T08:18:45.887815Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "\n",
    "DATASET_PATH = ('../../feedback-prize-2021')\n",
    "\n",
    "sys.path.insert(0, './codes')\n",
    "sys.path.append('longformer/tvm/python/')\n",
    "sys.path.append('longformer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a2a83c79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T08:41:49.151617Z",
     "start_time": "2022-02-27T08:41:49.146957Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import easydict\n",
    "import argparse\n",
    "\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "import ftfy\n",
    "import dill as pickle\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import DebertaV2Model\n",
    "\n",
    "# torch.use_deterministic_algorithms(True)\n",
    "# from longformer.longformer import Longformer, LongformerConfig, RobertaModel\n",
    "# from longformer.sliding_chunks import pad_to_window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fb3b605",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T08:18:48.597538Z",
     "start_time": "2022-02-27T08:18:48.594463Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\"\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6997bb5",
   "metadata": {},
   "source": [
    "**why using `os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\"`?**\n",
    "- [torch.use_deterministic_algorithms](https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html)\n",
    "> **A handful of CUDA operations are nondeterministic if the CUDA version is 10.2 or greater**, unless the environment variable `CUBLAS_WORKSPACE_CONFIG=:4096:8` or `CUBLAS_WORKSPACE_CONFIG=:16:8` is set. See the CUDA documentation for more details: https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility If one of these environment variable configurations is not set, a RuntimeError will be raised from these operations when called with CUDA tensors:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c96213b",
   "metadata": {},
   "source": [
    "## Argument Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06d834b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T08:33:12.993682Z",
     "start_time": "2022-02-27T08:33:12.980520Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_config():\n",
    "    parser = argparse.ArgumentParser(description=\"use huggingface models\")\n",
    "    parser.add_argument(\"--wandb_user\", default='ducky', type=str)\n",
    "    parser.add_argument(\"--wandb_project\", default='feedback_deberta_large', type=str)\n",
    "    parser.add_argument(\"--dataset_path\", default='../../feedback-prize-2021', type=str)\n",
    "    parser.add_argument(\"--save_path\", default='result', type=str)\n",
    "    parser.add_argument(\"--seed\", default=0, type=int)\n",
    "    parser.add_argument(\"--min_len\", default=0, type=int)\n",
    "    parser.add_argument(\"--weight_decay\", default=1e-2, type=float)\n",
    "    parser.add_argument(\"--weights_pow\", default=0.1, type=float)\n",
    "    parser.add_argument(\"--use_groupped_weights\", default=False, type=bool)\n",
    "    parser.add_argument(\"--global_attn\", default=False, type=int)\n",
    "    parser.add_argument(\"--label_smoothing\", default= 0.1, type=float)\n",
    "    parser.add_argument(\"--extra_dense\", default= False, type=bool)\n",
    "    parser.add_argument(\"--epochs\", default=9, type=int)\n",
    "    parser.add_argument(\"--batch_size\", default=4, type=int)\n",
    "    parser.add_argument(\"--grad_acc_steps\", default=2, type=int)\n",
    "    parser.add_argument(\"--grad_checkpt\", default=True, type=bool)\n",
    "    parser.add_argument(\"--data_prefix\", default='', type=str)\n",
    "    parser.add_argument(\"--max_grad_norm\", default=35 * 8, type=int)\n",
    "    parser.add_argument(\"--start_eval_at\", default=0, type=int)\n",
    "    parser.add_argument(\"--lr\", default=32e-6, type=float)\n",
    "    parser.add_argument(\"--min_lr\", default=32e-6, type=float)\n",
    "    parser.add_argument(\"--dataset_version\", default=2, type=int)\n",
    "    parser.add_argument(\"--warmup_steps\", default=500, type=int)\n",
    "    parser.add_argument(\"--rce_weight\", default=0.1, type=float)\n",
    "    parser.add_argument(\"--ce_weight\", default=0.9, type=float)\n",
    "    parser.add_argument(\"--dropout_ratio\", default=0.0, type=float)\n",
    "    parser.add_argument(\"--decay_bias\", default=False, type=bool)\n",
    "    parser.add_argument(\"--val_fold\", default=0, type=int)\n",
    "    parser.add_argument(\"--num_worker\", default=8, type=int)\n",
    "    parser.add_argument(\"--model_name\", default=\"microsoft/deberta-v3-large\", type=str)\n",
    "    parser.add_argument(\"--local_rank\", type=int, default=-1, help=\"do not modify!\")\n",
    "    parser.add_argument(\"--device\", type=int, default=0, help=\"select the gpu device to train\")\n",
    "    args = parser.parse_args(args=[])\n",
    "\n",
    "    if args.local_rank !=-1:\n",
    "        print('[ DDP ] local rank', args.local_rank)\n",
    "        torch.cuda.set_device(args.local_rank)\n",
    "        dist.init_process_group(backend='nccl')\n",
    "        args.device = torch.device(\"cuda\", args.local_rank)\n",
    "        args.rank = torch.distributed.get_rank()\n",
    "        args.world_size = torch.distributed.get_world_size()  \n",
    "\n",
    "        # checking settings for distributed training\n",
    "        assert args.batch_size % args.world_size == 0, f'--batch_size {args.batch_size} must be multiple of world size'\n",
    "        assert torch.cuda.device_count() > args.local_rank, 'insufficient CUDA devices for DDP command'\n",
    "\n",
    "        args.ddp = True\n",
    "    else:\n",
    "        args.device = torch.device(\"cuda\")\n",
    "        args.rank = 0\n",
    "        args.ddp = False\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f00e56b",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b57f981b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T08:19:02.936400Z",
     "start_time": "2022-02-27T08:19:02.932593Z"
    }
   },
   "outputs": [],
   "source": [
    "from module.utils import get_token_weights\n",
    "from module.utils import get_prepare_data\n",
    "from module.utils import get_all_texts\n",
    "from module.utils import get_id_to_ix_map\n",
    "from module.utils import get_fold_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c3dca6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T08:19:03.322730Z",
     "start_time": "2022-02-27T08:19:03.316847Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data_files(args):\n",
    "    token_weights = get_token_weights(args.use_groupped_weights, args.weights_pow)\n",
    "    data = get_prepare_data()\n",
    "    csv = pd.read_csv(osp.join(args.dataset_path, 'train.csv'))\n",
    "    all_texts = get_all_texts(args)\n",
    "    id_to_ix_map = get_id_to_ix_map()\n",
    "    data_splits = get_fold_data()\n",
    "\n",
    "    # text_id example `16585724607E`\n",
    "    train_text_ids = [text_id for fold in range(5) if fold != args.val_fold for text_id in data_splits[args.seed][250]['normed'][fold]]\n",
    "    val_text_ids = data_splits[args.seed][250]['normed'][args.val_fold]\n",
    "\n",
    "    train_ids = [id_to_ix_map[text_id] for text_id in train_text_ids]\n",
    "    val_ids = [id_to_ix_map[text_id] for text_id in val_text_ids]\n",
    "\n",
    "    return all_texts, token_weights, data, csv, train_ids, val_ids, train_text_ids, val_text_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7774e93",
   "metadata": {},
   "source": [
    "## Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5387adc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T08:32:13.325690Z",
     "start_time": "2022-02-27T08:32:13.322058Z"
    }
   },
   "outputs": [],
   "source": [
    "def wandb_setting(args):\n",
    "    wandb.login()\n",
    "    run = wandb.init(entity=args.wandb_user, project=args.wandb_project)\n",
    "    run.name = f'v3_fold{args.val_fold}_minlr{args.min_lr}_maxlr{args.lr}_wd{args.weight_decay}_warmup{args.warmup_steps}_gradnorm{args.max_grad_norm}_biasdecay{args.decay_bias}_ls{args.label_smoothing}_wp{args.weights_pow}_data{args.dataset_version}_rce{args.rce_weight}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5d7840",
   "metadata": {},
   "source": [
    "## üê£ Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08b90b2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T08:35:51.983445Z",
     "start_time": "2022-02-27T08:35:51.978677Z"
    }
   },
   "outputs": [],
   "source": [
    "class TrainDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, ids, data, label_smoothing, token_weights, data_prefix):\n",
    "        self.ids = ids\n",
    "        self.data = data\n",
    "        self.label_smoothing = label_smoothing\n",
    "        self.token_weights = token_weights\n",
    "        self.data_prefix = data_prefix\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i = self.ids[idx]\n",
    "\n",
    "        # load train data\n",
    "        tokens = self.data['tokens'][i]\n",
    "        attention_mask = self.data['attention_masks'][i]\n",
    "        num_tokens = self.data['num_tokens'][i, 0]\n",
    "\n",
    "        # label smoothing\n",
    "        cbio_labels = self.data[f'{self.data_prefix}cbio_labels'][i]\n",
    "        cbio_labels *= (1 - self.label_smoothing)\n",
    "        cbio_labels += self.label_smoothing / 15\n",
    "\n",
    "        # class weight per token\n",
    "        class_weight = np.zeros_like(attention_mask)\n",
    "        argmax_labels = cbio_labels.argmax(-1)\n",
    "\n",
    "        for class_i in range(1, 15):\n",
    "            class_weight[argmax_labels == class_i] = self.token_weights[class_i]\n",
    "\n",
    "        class_none_index = argmax_labels == 0      # 0 is the text that is not entity\n",
    "        class_none_index[num_tokens - 1:] = False  # special token & padding\n",
    "        class_weight[class_none_index] = self.token_weights[0]\n",
    "        class_weight[0] = 0\n",
    "\n",
    "        return tokens, attention_mask, cbio_labels, class_weight, num_tokens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "362dcb5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T08:35:52.371082Z",
     "start_time": "2022-02-27T08:35:52.352753Z"
    }
   },
   "outputs": [],
   "source": [
    "class ValDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, ids, data, csv, all_texts, val_text_ids, class_names, token_weights):\n",
    "        self.ids = ids\n",
    "        self.data = data\n",
    "        self.csv = csv\n",
    "        self.space_regex = re.compile('[\\s\\n]')\n",
    "        self.all_texts = all_texts\n",
    "        self.val_text_ids = val_text_ids\n",
    "        self.class_names = class_names\n",
    "        self.token_weights = token_weights\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i = self.ids[idx]\n",
    "\n",
    "        # load text data & text dataframe\n",
    "        text_id = self.val_text_ids[idx]\n",
    "        text = self.all_texts[text_id]\n",
    "        sample_df = self.csv.query('id == @text_id')\n",
    "\n",
    "        # load ground truth prediction string for f1macro metric\n",
    "        gt_dict = {}\n",
    "        for class_i in range(1, 8):\n",
    "            class_name = self.class_names[class_i]\n",
    "            class_df = sample_df.query('discourse_type == @class_name')   \n",
    "            if len(class_df):\n",
    "                gt_dict[class_i] = [(x[0], x[1]) for x in class_df.predictionstring.map(split_predstring)]\n",
    "        \n",
    "        # load valid data\n",
    "        tokens = self.data['tokens'][i]\n",
    "        attention_mask = self.data['attention_masks'][i]\n",
    "        num_tokens = self.data['num_tokens'][i, 0]\n",
    "        token_bounds = self.data['token_offsets'][i]\n",
    "        cbio_labels = self.data['cbio_labels'][i]\n",
    "        \n",
    "        # class weight per token\n",
    "        class_weight = np.zeros_like(attention_mask)\n",
    "        argmax_labels = cbio_labels.argmax(-1)\n",
    "\n",
    "        for class_i in range(1, 15):\n",
    "            class_weight[argmax_labels == class_i] = self.token_weights[class_i]\n",
    "\n",
    "        class_none_index = argmax_labels == 0\n",
    "        class_none_index[num_tokens - 1:] = False\n",
    "        class_weight[class_none_index] = self.token_weights[0]\n",
    "        class_weight[0] = 0\n",
    "        \n",
    "        # ???\n",
    "        index_map = []\n",
    "        current_word = 0\n",
    "        blank = False\n",
    "        for char_ix in range(text.index(text.strip()[0]), len(text)):\n",
    "            if self.space_regex.match(text[char_ix]) is not None:\n",
    "                blank = True\n",
    "            elif blank:\n",
    "                current_word += 1\n",
    "                blank = False\n",
    "            index_map.append(current_word)\n",
    "        \n",
    "        return tokens, attention_mask, cbio_labels, class_weight, token_bounds, gt_dict, index_map, num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b98ae01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T08:30:56.190301Z",
     "start_time": "2022-02-27T08:30:56.185015Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_dataloader(train_ids, val_ids, data, csv, all_texts, val_text_ids, class_names, token_weights, args):\n",
    "    train_dataset = TrainDataset(train_ids, data, args.label_smoothing, token_weights, args.data_prefix)\n",
    "    val_dataset = ValDataset(val_ids, data, csv, all_texts, val_text_ids, class_names, token_weights)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, collate_fn=train_collate_fn, batch_size=args.batch_size, num_workers=args.num_worker)\n",
    "    val_dataloader = DataLoader(val_dataset, collate_fn=val_collate_fn, batch_size=args.batch_size, num_workers=8, persistent_workers=True)\n",
    "\n",
    "    return train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a597de49",
   "metadata": {},
   "source": [
    "## Collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07b75791",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T08:37:02.278309Z",
     "start_time": "2022-02-27T08:37:02.273520Z"
    }
   },
   "outputs": [],
   "source": [
    "first_batch = True\n",
    "def train_collate_fn(ins):\n",
    "    global first_batch\n",
    "    if first_batch:\n",
    "        max_len = 2048\n",
    "        first_batch = False\n",
    "    else:\n",
    "        max_len = (max(x[-1] for x in ins) + 7) // 8 * 8\n",
    "        \n",
    "    return tuple(torch.from_numpy(np.concatenate([ins[z][x][None, :max_len] for z in range(len(ins))])) for x in range(len(ins[0]) - 1))\n",
    "    \n",
    "def val_collate_fn(ins):\n",
    "    max_len = (max(x[-1] for x in ins) + 7) // 8 * 8\n",
    "    return tuple(torch.from_numpy(np.concatenate([ins[z][x][None, :max_len] for z in range(len(ins))])) for x in range(len(ins[0]) - 3)) + ([x[-3] for x in ins], [x[-2] for x in ins], np.array([x[-1] for x in ins]),)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6283a6aa",
   "metadata": {},
   "source": [
    "## üß£ Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "820989b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T09:03:35.347472Z",
     "start_time": "2022-02-27T09:03:35.336679Z"
    }
   },
   "outputs": [],
   "source": [
    "class TvmLongformer(torch.nn.Module):\n",
    "    \"\"\"Currently microsoft/deberta-v3-large\"\"\"\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "\n",
    "        self.feats = DebertaV2Model.from_pretrained('microsoft/deberta-v3-large')\n",
    "        self.feats.pooler = None\n",
    "\n",
    "        if args.grad_checkpt:\n",
    "            self.feats.gradient_checkpointing_enable()\n",
    "\n",
    "        self.feats.train()\n",
    "\n",
    "        self.conv1d_layer1 = torch.nn.Conv1d(1024, 1024, kernel_size=1)\n",
    "        self.conv1d_layer3 = torch.nn.Conv1d(1024, 1024, kernel_size=3, padding=1)\n",
    "        self.conv1d_layer5 = torch.nn.Conv1d(1024, 1024, kernel_size=5, padding=2)\n",
    "\n",
    "        if args.extra_dense:\n",
    "            self.class_projector = torch.nn.Sequential(\n",
    "                torch.nn.LayerNorm(1024*3),\n",
    "                torch.nn.Linear(1024*3, 256),\n",
    "                torch.nn.GELU(),\n",
    "                torch.nn.Linear(256, 15)\n",
    "            )\n",
    "        else:\n",
    "            self.class_projector = torch.nn.Sequential(\n",
    "                torch.nn.LayerNorm(1024*3),\n",
    "                torch.nn.Linear(1024*3, 15)\n",
    "            )\n",
    "    def forward(self, tokens, mask):\n",
    "        transformer_output = self.feats(tokens, mask, return_dict=False)[0]\n",
    "        conv_input = transformer_output.transpose(1, 2) # batch, hidden, seq\n",
    "\n",
    "        conv_output1 = F.relu(self.conv1d_layer1(conv_input)) \n",
    "        conv_output3 = F.relu(self.conv1d_layer3(conv_input)) \n",
    "        conv_output5 = F.relu(self.conv1d_layer5(conv_input)) \n",
    "\n",
    "        concat_output = torch.cat((conv_output1, conv_output3, conv_output5), dim=1).transpose(1, 2)\n",
    "\n",
    "        output = self.class_projector(concat_output)\n",
    "        return torch.log_softmax(output, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "163f4d15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T09:09:36.564590Z",
     "start_time": "2022-02-27T09:09:36.556703Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(args, train_dataloader):\n",
    "    model = TvmLongformer(args).to(args.device)\n",
    "\n",
    "    # dropout layer\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, torch.nn.Dropout):\n",
    "            m.p = args.dropout_ratio\n",
    "\n",
    "    # ...\n",
    "    weights = []\n",
    "    biases = []\n",
    "    for n, p in model.named_parameters():\n",
    "        if n.startswith('feats.embeddings') or 'LayerNorm' in n or n.endswith('bias'):\n",
    "            # embedding layer & bias layer\n",
    "            biases.append(p)\n",
    "        else:\n",
    "            # except above\n",
    "            weights.append(p)\n",
    "\n",
    "    optimizer = torch.optim.AdamW([{'params': weights, 'weight_decay': args.weight_decay, 'lr': 0},\n",
    "                                   {'params': biases, 'weight_decay': 0 if not args.decay_bias else args.weight_decay, 'lr': 0}])\n",
    "\n",
    "    lr_schedule = np.r_[np.linspace(0, args.lr, args.warmup_steps),\n",
    "                    (np.cos(np.linspace(0, np.pi, len(train_dataloader)*args.epochs - args.warmup_steps)) * .5 + .5) * (args.lr - args.min_lr)\n",
    "                    + args.min_lr]\n",
    "    \n",
    "    return model, optimizer, lr_schedule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25892d9f",
   "metadata": {},
   "source": [
    "## üöµüèª Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b17bf6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T08:33:18.437280Z",
     "start_time": "2022-02-27T08:33:18.432596Z"
    }
   },
   "outputs": [],
   "source": [
    "seed_everything(42)\n",
    "args = get_config()\n",
    "# wandb_setting(args)\n",
    "\n",
    "class_names = ['None',\n",
    "               'Lead',\n",
    "               'Position',\n",
    "               'Evidence',\n",
    "               'Claim',\n",
    "               'Concluding Statement',\n",
    "               'Counterclaim',\n",
    "               'Rebuttal']\n",
    "\n",
    "# create directory to save model\n",
    "if not osp.exists(args.save_path):\n",
    "    os.makedirs(args.save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c022404",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T08:34:06.251750Z",
     "start_time": "2022-02-27T08:34:06.249387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(batch_size=4, ce_weight=0.9, data_prefix='', dataset_path='../../feedback-prize-2021', dataset_version=2, ddp=False, decay_bias=False, device=device(type='cuda'), dropout_ratio=0.0, epochs=9, extra_dense=False, global_attn=False, grad_acc_steps=2, grad_checkpt=True, label_smoothing=0.1, local_rank=-1, lr=3.2e-05, max_grad_norm=280, min_len=0, min_lr=3.2e-05, model_name='microsoft/deberta-v3-large', num_worker=8, rank=0, rce_weight=0.1, save_path='result', seed=0, start_eval_at=0, use_groupped_weights=False, val_fold=0, wandb_project='feedback_deberta_large', wandb_user='ducky', warmup_steps=500, weight_decay=0.01, weights_pow=0.1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "270dbfe9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T08:37:09.162418Z",
     "start_time": "2022-02-27T08:37:08.387599Z"
    }
   },
   "outputs": [],
   "source": [
    "all_texts, token_weights, data, csv, train_ids, val_ids, train_text_ids, val_text_ids = get_data_files(args)\n",
    "train_dataloader, val_dataloader = get_dataloader(train_ids, val_ids, data, csv, all_texts, val_text_ids, class_names, token_weights, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "38cb9c20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T08:41:08.599611Z",
     "start_time": "2022-02-27T08:41:08.404231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1,  1258,   355,  ...,     0,     0,     0],\n",
      "        [    1, 10147,  6654,  ...,     0,     0,     0],\n",
      "        [    1,   279,  1574,  ...,     0,     0,     0],\n",
      "        [    1, 10147,   565,  ...,     0,     0,     0]])\n"
     ]
    }
   ],
   "source": [
    "for tokens, attention_mask, cbio_labels, class_weight in train_dataloader:\n",
    "    print(tokens)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cd08f792",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T13:16:38.073180Z",
     "start_time": "2022-02-27T13:16:37.606173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1,  1258,   355,  ...,     0,     0,     0],\n",
      "        [    1, 10147,  6654,  ...,     0,     0,     0],\n",
      "        [    1,   279,  1574,  ...,     0,     0,     0],\n",
      "        [    1, 10147,   565,  ...,     0,     0,     0]])\n"
     ]
    }
   ],
   "source": [
    "for tokens, attention_mask, cbio_labels, class_weight in train_dataloader:\n",
    "    print(tokens)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d1ade58f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T09:09:45.211783Z",
     "start_time": "2022-02-27T09:09:40.056083Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model, optimizer, lr_schedule = get_model(args, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b2adb102",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T09:09:46.711824Z",
     "start_time": "2022-02-27T09:09:46.704396Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TvmLongformer(\n",
       "  (feats): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 1024, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (1): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (2): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (3): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (4): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (5): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (6): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (7): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (8): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (9): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (10): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (11): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (12): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (13): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (14): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (15): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (16): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (17): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (18): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (19): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (20): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (21): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (22): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (23): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (conv1d_layer1): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "  (conv1d_layer3): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (conv1d_layer5): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "  (class_projector): Sequential(\n",
       "    (0): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=3072, out_features=15, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759f4039",
   "metadata": {},
   "source": [
    "# Test Laboratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13a93da",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP!!!! YOU SHALL NOT PASS!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd31e020",
   "metadata": {},
   "source": [
    "## scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2c06a1bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T09:01:10.580181Z",
     "start_time": "2022-02-27T09:01:10.504323Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "args.min_lr = 1e-07\n",
    "\n",
    "lr_schedule = np.r_[np.linspace(0, args.lr, args.warmup_steps),\n",
    "                    (np.cos(np.linspace(0, np.pi, len(train_dataloader)*args.epochs - args.warmup_steps)) * .5 + .5) * (args.lr - args.min_lr)\n",
    "                    + args.min_lr]\n",
    "\n",
    "plt.plot(np.arange(len(lr_schedule)), lr_schedule)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac6f0a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "261.033px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
