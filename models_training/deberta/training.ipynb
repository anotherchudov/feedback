{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48b200f4",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "- Environment Setting\n",
    "- Argument Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bd7c2d",
   "metadata": {},
   "source": [
    "## Environment Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0ab4178",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T14:08:17.822819Z",
     "start_time": "2022-02-24T14:08:17.819459Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/home/feedback/working/feedback/models_training/longformer/sumbission/codes')\n",
    "sys.path.append('longformer/tvm/python/')\n",
    "sys.path.append('longformer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2a83c79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T14:06:48.037359Z",
     "start_time": "2022-02-24T14:06:47.299469Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import easydict\n",
    "\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import h5py\n",
    "import ftfy\n",
    "import dill as pickle\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "from transformers import DebertaV2Model\n",
    "\n",
    "# torch.use_deterministic_algorithms(True)\n",
    "# from longformer.longformer import Longformer, LongformerConfig, RobertaModel\n",
    "# from longformer.sliding_chunks import pad_to_window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fb3b605",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T14:15:34.246714Z",
     "start_time": "2022-02-24T14:15:34.242649Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\"\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6997bb5",
   "metadata": {},
   "source": [
    "**why using `os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\"`?**\n",
    "- [torch.use_deterministic_algorithms](https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html)\n",
    "> **A handful of CUDA operations are nondeterministic if the CUDA version is 10.2 or greater**, unless the environment variable `CUBLAS_WORKSPACE_CONFIG=:4096:8` or `CUBLAS_WORKSPACE_CONFIG=:16:8` is set. See the CUDA documentation for more details: https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility If one of these environment variable configurations is not set, a RuntimeError will be raised from these operations when called with CUDA tensors:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03851309",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Text Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "297af6a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T14:26:37.788584Z",
     "start_time": "2022-02-24T14:26:37.572437Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_texts = {}\n",
    "for text_path in glob('../../../feedback-prize-2021/train/*.txt'):\n",
    "    with open(text_path, encoding='utf-8') as f:\n",
    "        text_id = text_path.split('/')[-1].split('.')[0]\n",
    "        all_texts[text_id] = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c96213b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Argument Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06d834b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T14:23:23.261447Z",
     "start_time": "2022-02-24T14:23:23.254004Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({})\n",
    "\n",
    "# version\n",
    "args.dataset_version = 2\n",
    "args.data_prefix = ''\n",
    "\n",
    "# setting\n",
    "args.seed = 0\n",
    "args.label_names = ['None', 'Lead', 'Position', 'Evidence', 'Claim',\n",
    "                    'Concluding Statement', 'Counterclaim', 'Rebuttal']\n",
    "\n",
    "# hyperparameter\n",
    "args.epochs = 9\n",
    "args.batch_size = 8\n",
    "args.lr = 32e-6\n",
    "args.min_lr = 32e-6\n",
    "args.label_smoothing = 0.1\n",
    "\n",
    "args.weight_decay = 1e-2\n",
    "args.weights_pow = 0.1\n",
    "args.use_groupped_weights = False\n",
    "\n",
    "args.use_groupped_weights = False\n",
    "args.global_attn = 0\n",
    "args.extra_dense = False\n",
    "\n",
    "args.max_grad_norm = 35 * batch_size\n",
    "args.start_eval_at = 3000\n",
    "args.warmup_steps = 500\n",
    "args.rce_weight = 0.1\n",
    "args.ce_weight = 1 - args.rce_weight\n",
    "\n",
    "args.decay_bias = False\n",
    "\n",
    "\n",
    "# inference\n",
    "args.grad_acc_steps = batch_size\n",
    "args.grad_checkpt = True\n",
    "args.min_len = 0\n",
    "args.eval_interval = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f53a8c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T14:23:51.858859Z",
     "start_time": "2022-02-24T14:23:51.853579Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "args.gpu_n = 4\n",
    "\n",
    "if args.gpu_n == 1:\n",
    "    args.max_grad_norm = 1.\n",
    "    args.val_fold = 0\n",
    "elif args.gpu_n == 2:\n",
    "    args.val_fold = 1\n",
    "elif args.gpu_n == 3:\n",
    "    args.val_fold = 0\n",
    "elif args.gpu_n == 4:\n",
    "    args.val_fold = 1\n",
    "    args.max_grad_norm = 1.\n",
    "    \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(args.gpu_n - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f00e56b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Token Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a1b4aa6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T14:10:31.215611Z",
     "start_time": "2022-02-24T14:10:31.211609Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('../../token_counts.pickle', 'rb') as f:\n",
    "    groupped_token_counts, ungroupped_token_counts = pickle.load(f)\n",
    "    \n",
    "if args.use_groupped_weights:\n",
    "    counts = groupped_token_counts\n",
    "else:\n",
    "    counts = ungroupped_token_counts\n",
    "\n",
    "token_weights = (counts.mean() / counts) ** args.weights_pow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e11bbc59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T14:10:50.306376Z",
     "start_time": "2022-02-24T14:10:50.302323Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 549185.,  561242.,  561242.,  317823.,  317823., 4069479.,\n",
       "        4069479.,  982228.,  982228.,  945061.,  945061.,  157527.,\n",
       "         157527.,  138255.,  138255.]),\n",
       " array([ 549185.,    9305.,  551937.,   15419.,  302404.,   45702.,\n",
       "        4023777.,   50206.,  932022.,   13505.,  931556.,    5817.,\n",
       "         151710.,    4337.,  133918.]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupped_token_counts, ungroupped_token_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7774e93",
   "metadata": {},
   "source": [
    "## Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "acacb8b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T14:24:09.496806Z",
     "start_time": "2022-02-24T14:23:58.935440Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:31xv6jo4) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 1437405... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">volcanic-gorge-3</strong>: <a href=\"https://wandb.ai/ducky/feedback_debertav3_large/runs/31xv6jo4\" target=\"_blank\">https://wandb.ai/ducky/feedback_debertav3_large/runs/31xv6jo4</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220224_142256-31xv6jo4/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:31xv6jo4). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ducky/feedback_debertav3_large/runs/2ba0lkf6\" target=\"_blank\">olive-valley-4</a></strong> to <a href=\"https://wandb.ai/ducky/feedback_debertav3_large\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(entity='ducky', project='feedback_debertav3_large')\n",
    "run.name = f'v3_fold{args.val_fold}_minlr{args.min_lr}_maxlr{args.lr}_wd{args.weight_decay}_warmup{args.warmup_steps}_gradnorm{args.max_grad_norm}_biasdecay{args.decay_bias}_ls{args.label_smoothing}_wp{args.weights_pow}_data{args.dataset_version}_rce{args.rce_weight}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2ad9dab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T14:26:46.305086Z",
     "start_time": "2022-02-24T14:26:46.301370Z"
    }
   },
   "outputs": [],
   "source": [
    "seed_everything(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362dcb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, args, ids):\n",
    "        self.args = args\n",
    "        self.ids = ids\n",
    "        self.data = h5py.File(f'../../deberta_spm_data_v{dataset_version}.h5py')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.ids[ix]\n",
    "        \n",
    "        tokens = self.data['tokens'][x]\n",
    "        attention_mask = self.data['attention_masks'][x]\n",
    "        num_tokens = self.data['num_tokens'][x, 0]\n",
    "        \n",
    "        cbio_labels = self.data[f'{data_prefix}cbio_labels'][x]\n",
    "        cbio_labels *= (1 - self.label_smoothing)\n",
    "        cbio_labels += label_smoothing / 15\n",
    "        \n",
    "        label_mask = np.zeros_like(attention_mask)\n",
    "        argmax_labels = cbio_labels.argmax(-1)\n",
    "        \n",
    "        for ix in range(1, 15):\n",
    "            label_mask[argmax_labels==ix] = token_weights[ix]\n",
    "        \n",
    "        zero_label_mask = argmax_labels==0\n",
    "        zero_label_mask[num_tokens - 1:] = False\n",
    "        \n",
    "        label_mask[zero_label_mask] = token_weights[0]\n",
    "        label_mask[0] = 0\n",
    "\n",
    "        return tokens, attention_mask, cbio_labels, label_mask, num_tokens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8a1c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, args, ids):\n",
    "        self.args = args\n",
    "        self.ids = ids\n",
    "        self.data = h5py.File(f'../../deberta_spm_data_v{dataset_version}.h5py')\n",
    "        self.csv = pd.read_csv('../../train.csv')\n",
    "        self.space_regex = re.compile('[\\s\\n]')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "    \n",
    "    def __getitem__(self, ix):\n",
    "        x = self.ids[ix]\n",
    "        text = all_texts[val_files[ix]]\n",
    "        gt_dict = {}\n",
    "        sample_df = self.csv.loc[self.csv.id==val_files[ix]]\n",
    "        for cat_ix in range(1, 8):\n",
    "            cat_name = label_names[cat_ix]\n",
    "            cat_entities = sample_df.loc[sample_df.discourse_type==cat_name]\n",
    "            if len(cat_entities):\n",
    "                gt_dict[cat_ix] = [(x[0], x[1]) for x in cat_entities.predictionstring.map(split_predstring)]\n",
    "        \n",
    "        tokens = self.data['tokens'][x]\n",
    "        attention_mask = self.data['attention_masks'][x]\n",
    "        num_tokens = self.data['num_tokens'][x, 0]\n",
    "        token_bounds = self.data['token_offsets'][x]\n",
    "\n",
    "        cbio_labels = self.data['cbio_labels'][x]\n",
    "        \n",
    "        label_mask = np.zeros_like(attention_mask)\n",
    "        argmax_labels = cbio_labels.argmax(-1)\n",
    "        for cat_ix in range(1, 15):\n",
    "            label_mask[argmax_labels==cat_ix] = token_weights[cat_ix]\n",
    "        zero_label_mask = argmax_labels==0\n",
    "        zero_label_mask[num_tokens - 1:] = False\n",
    "        label_mask[zero_label_mask] = token_weights[0]\n",
    "        label_mask[0] = 0\n",
    "        \n",
    "        index_map = []\n",
    "        current_word = 0\n",
    "        blank = False\n",
    "        for char_ix in range(text.index(text.strip()[0]), len(text)):\n",
    "            if self.space_regex.match(text[char_ix]) is not None:\n",
    "                blank = True\n",
    "            elif blank:\n",
    "                current_word += 1\n",
    "                blank = False\n",
    "            index_map.append(current_word)\n",
    "        \n",
    "        return tokens, attention_mask, cbio_labels, label_mask, token_bounds, gt_dict, index_map, num_tokens"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
