{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48b200f4",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "- Environment Setting\n",
    "- Argument Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bd7c2d",
   "metadata": {},
   "source": [
    "## Environment Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0ab4178",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T14:08:17.822819Z",
     "start_time": "2022-02-24T14:08:17.819459Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "\n",
    "DATASET_PATH = ('../../../feedback-prize-2021')\n",
    "\n",
    "sys.path.insert(0, '/home/feedback/working/feedback/models_training/longformer/sumbission/codes')\n",
    "sys.path.append('longformer/tvm/python/')\n",
    "sys.path.append('longformer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2a83c79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T14:06:48.037359Z",
     "start_time": "2022-02-24T14:06:47.299469Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import easydict\n",
    "\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import h5py\n",
    "import ftfy\n",
    "import dill as pickle\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "from transformers import DebertaV2Model\n",
    "\n",
    "# torch.use_deterministic_algorithms(True)\n",
    "# from longformer.longformer import Longformer, LongformerConfig, RobertaModel\n",
    "# from longformer.sliding_chunks import pad_to_window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fb3b605",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T14:15:34.246714Z",
     "start_time": "2022-02-24T14:15:34.242649Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\"\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6997bb5",
   "metadata": {},
   "source": [
    "**why using `os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\"`?**\n",
    "- [torch.use_deterministic_algorithms](https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html)\n",
    "> **A handful of CUDA operations are nondeterministic if the CUDA version is 10.2 or greater**, unless the environment variable `CUBLAS_WORKSPACE_CONFIG=:4096:8` or `CUBLAS_WORKSPACE_CONFIG=:16:8` is set. See the CUDA documentation for more details: https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility If one of these environment variable configurations is not set, a RuntimeError will be raised from these operations when called with CUDA tensors:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03851309",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Text Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "297af6a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T14:26:37.788584Z",
     "start_time": "2022-02-24T14:26:37.572437Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_texts = {}\n",
    "for text_path in glob('/train/*.txt'):\n",
    "    with open(text_path, encoding='utf-8') as f:\n",
    "        text_id = text_path.split('/')[-1].split('.')[0]\n",
    "        all_texts[text_id] = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c96213b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Argument Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06d834b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T14:23:23.261447Z",
     "start_time": "2022-02-24T14:23:23.254004Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def init_args():\n",
    "    args = easydict.EasyDict({})\n",
    "\n",
    "    # version\n",
    "    args.dataset_version = 2\n",
    "    args.data_prefix = ''\n",
    "    args.h5py_path = f'../../deberta_spm_data_v{args.dataset_version}.h5py'\n",
    "    args.csv_path = f'../../train.csv'\n",
    "\n",
    "    # setting\n",
    "    args.seed = 0\n",
    "    args.label_names = ['None', 'Lead', 'Position', 'Evidence', 'Claim',\n",
    "                        'Concluding Statement', 'Counterclaim', 'Rebuttal']\n",
    "\n",
    "    # hyperparameter\n",
    "    args.epochs = 9\n",
    "    args.batch_size = 8\n",
    "    args.lr = 32e-6\n",
    "    args.min_lr = 32e-6\n",
    "    args.label_smoothing = 0.1\n",
    "\n",
    "    args.weight_decay = 1e-2\n",
    "    args.weights_pow = 0.1\n",
    "    args.use_groupped_weights = False\n",
    "\n",
    "    args.use_groupped_weights = False\n",
    "    args.global_attn = 0\n",
    "    args.extra_dense = False\n",
    "\n",
    "    args.max_grad_norm = 35 * args.batch_size\n",
    "    args.start_eval_at = 3000\n",
    "    args.warmup_steps = 500\n",
    "    args.rce_weight = 0.1\n",
    "    args.ce_weight = 1 - args.rce_weight\n",
    "\n",
    "    args.decay_bias = False\n",
    "\n",
    "    # inference\n",
    "    args.grad_acc_steps = args.batch_size\n",
    "    args.grad_checkpt = True\n",
    "    args.min_len = 0\n",
    "    args.eval_interval = 200\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4b2ca90",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = init_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f53a8c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T14:23:51.858859Z",
     "start_time": "2022-02-24T14:23:51.853579Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "args.gpu_n = 4\n",
    "\n",
    "if args.gpu_n == 1:\n",
    "    args.max_grad_norm = 1.\n",
    "    args.val_fold = 0\n",
    "elif args.gpu_n == 2:\n",
    "    args.val_fold = 1\n",
    "elif args.gpu_n == 3:\n",
    "    args.val_fold = 0\n",
    "elif args.gpu_n == 4:\n",
    "    args.val_fold = 1\n",
    "    args.max_grad_norm = 1.\n",
    "    \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(args.gpu_n - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f00e56b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Token Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a1b4aa6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T14:10:31.215611Z",
     "start_time": "2022-02-24T14:10:31.211609Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('../../token_counts.pickle', 'rb') as f:\n",
    "    groupped_token_counts, ungroupped_token_counts = pickle.load(f)\n",
    "    \n",
    "if args.use_groupped_weights:\n",
    "    counts = groupped_token_counts\n",
    "else:\n",
    "    counts = ungroupped_token_counts\n",
    "\n",
    "args.token_weights = (counts.mean() / counts) ** args.weights_pow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e11bbc59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T14:10:50.306376Z",
     "start_time": "2022-02-24T14:10:50.302323Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 549185.,  561242.,  561242.,  317823.,  317823., 4069479.,\n",
       "        4069479.,  982228.,  982228.,  945061.,  945061.,  157527.,\n",
       "         157527.,  138255.,  138255.]),\n",
       " array([ 549185.,    9305.,  551937.,   15419.,  302404.,   45702.,\n",
       "        4023777.,   50206.,  932022.,   13505.,  931556.,    5817.,\n",
       "         151710.,    4337.,  133918.]),\n",
       " array([0.99353973, 1.49377596, 0.99304323, 1.42020646, 1.0546257 ,\n",
       "        1.27398286, 0.81412992, 1.26206447, 0.94235489, 1.43915525,\n",
       "        0.94240202, 1.56562302, 1.12994078, 1.61227144, 1.1441243 ]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupped_token_counts, ungroupped_token_counts, token_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7774e93",
   "metadata": {},
   "source": [
    "## Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acacb8b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T14:24:09.496806Z",
     "start_time": "2022-02-24T14:23:58.935440Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mducky\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ducky/feedback_debertav3_large/runs/2ktkintx\" target=\"_blank\">vital-darkness-5</a></strong> to <a href=\"https://wandb.ai/ducky/feedback_debertav3_large\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(entity='ducky', project='feedback_debertav3_large')\n",
    "run.name = f'v3_fold{args.val_fold}_minlr{args.min_lr}_maxlr{args.lr}_wd{args.weight_decay}_warmup{args.warmup_steps}_gradnorm{args.max_grad_norm}_biasdecay{args.decay_bias}_ls{args.label_smoothing}_wp{args.weights_pow}_data{args.dataset_version}_rce{args.rce_weight}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2ad9dab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T14:26:46.305086Z",
     "start_time": "2022-02-24T14:26:46.301370Z"
    }
   },
   "outputs": [],
   "source": [
    "seed_everything(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "362dcb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, args, ids):\n",
    "        self.args = args\n",
    "        self.ids = ids\n",
    "        self.data = h5py.File(args.h5py_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text_id = self.ids[idx]\n",
    "        \n",
    "        # TODO: Add Tokenizer and directly tokenize for typo injections\n",
    "        tokens = self.data['tokens'][text_id]\n",
    "        attention_mask = self.data['attention_masks'][text_id]\n",
    "        num_tokens = self.data['num_tokens'][text_id, 0]\n",
    "        \n",
    "        # label\n",
    "        cbio_labels = self.data[f'{self.args.data_prefix}cbio_labels'][text_id]\n",
    "        cbio_labels *= (1 - self.args.label_smoothing)\n",
    "        cbio_labels += self.args.label_smoothing / 15\n",
    "        \n",
    "        # label mask\n",
    "        label_mask = np.zeros_like(attention_mask)\n",
    "        argmax_labels = cbio_labels.argmax(-1)\n",
    "        \n",
    "        for i in range(1, 15):\n",
    "            label_mask[argmax_labels == i] = self.args.token_weights[i]\n",
    "        \n",
    "        zero_label_mask = argmax_labels == 0\n",
    "        zero_label_mask[num_tokens - 1:] = False\n",
    "\n",
    "        label_mask[zero_label_mask] = self.args.token_weights[0]\n",
    "        label_mask[0] = 0\n",
    "\n",
    "        return tokens, attention_mask, cbio_labels, label_mask, num_tokens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8a1c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, args, ids, val_files):\n",
    "        self.args = args\n",
    "        self.ids = ids\n",
    "        self.val_files = val_files\n",
    "\n",
    "        self.data = h5py.File(args.h5py_path)\n",
    "        self.csv = pd.read_csv(args.csv_path)\n",
    "        self.space_regex = re.compile('[\\s\\n]')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def split_predstring(self, x):\n",
    "        vals = x.split()\n",
    "        return int(vals[0]), int(vals[-1])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text_id = self.ids[idx]\n",
    "        text = all_texts[self.val_files[idx]]\n",
    "        gt_dict = {}\n",
    "        sample_df = self.csv.loc[self.csv.id == self.val_files[idx]]\n",
    "        sample_df = self.csv.query(\"id == @self.val_files[idx]\")\n",
    "        for class_i in range(1, 8):\n",
    "            class_name = self.args.label_names[class_i]\n",
    "            class_entities = sample_df.loc[sample_df.discourse_type == class_name]\n",
    "            if len(class_entities):\n",
    "                gt_dict[class_i] = [(x[0], x[1]) for x in class_entities.predictionstring.map(self.split_predstring)]\n",
    "        \n",
    "        tokens = self.data['tokens'][text_id]\n",
    "        attention_mask = self.data['attention_masks'][text_id]\n",
    "        num_tokens = self.data['num_tokens'][text_id, 0]\n",
    "        token_bounds = self.data['token_offsets'][text_id]\n",
    "        cbio_labels = self.data['cbio_labels'][text_id]\n",
    "        \n",
    "        label_mask = np.zeros_like(attention_mask)\n",
    "        argmax_labels = cbio_labels.argmax(-1)\n",
    "        for class_i in range(1, 15):\n",
    "            label_mask[argmax_labels == class_i] = self.args.token_weights[class_i]\n",
    "\n",
    "        zero_label_mask = argmax_labels == 0\n",
    "        zero_label_mask[num_tokens - 1:] = False\n",
    "        label_mask[zero_label_mask] = self.args.token_weights[0]\n",
    "        label_mask[0] = 0 # what is this for?\n",
    "        \n",
    "        index_map = []\n",
    "        current_word = 0\n",
    "        blank = False\n",
    "        for char_ix in range(text.index(text.strip()[0]), len(text)):\n",
    "            if self.space_regex.match(text[char_ix]) is not None:\n",
    "                blank = True\n",
    "            elif blank:\n",
    "                current_word += 1\n",
    "                blank = False\n",
    "            index_map.append(current_word)\n",
    "        \n",
    "        return tokens, attention_mask, cbio_labels, label_mask, token_bounds, gt_dict, index_map, num_tokens"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
