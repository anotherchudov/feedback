{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77bd1ea6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-02-20T05:05:17.067581Z",
     "iopub.status.busy": "2022-02-20T05:05:17.066064Z",
     "iopub.status.idle": "2022-02-20T05:05:19.721931Z",
     "shell.execute_reply": "2022-02-20T05:05:19.721361Z",
     "shell.execute_reply.started": "2022-02-20T04:49:57.249100Z"
    },
    "papermill": {
     "duration": 2.668516,
     "end_time": "2022-02-20T05:05:19.722096",
     "exception": false,
     "start_time": "2022-02-20T05:05:17.053580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../input/feedbackv1/codes')\n",
    "import torch as t\n",
    "t.autograd.set_grad_enabled(False)\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from transformers import RobertaTokenizerFast, DebertaModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59ee6a0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T05:05:19.743573Z",
     "iopub.status.busy": "2022-02-20T05:05:19.742903Z",
     "iopub.status.idle": "2022-02-20T05:05:37.913199Z",
     "shell.execute_reply": "2022-02-20T05:05:37.912700Z",
     "shell.execute_reply.started": "2022-02-20T04:50:00.001330Z"
    },
    "papermill": {
     "duration": 18.182705,
     "end_time": "2022-02-20T05:05:37.913343",
     "exception": false,
     "start_time": "2022-02-20T05:05:19.730638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TvmLongformer(t.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feats = DebertaModel.from_pretrained(\n",
    "            '../input/feedbackv1/pretrained_checkpoints/deberta_large/')\n",
    "        self.feats.pooler = None\n",
    "        self.class_projector = t.nn.Sequential(\n",
    "            t.nn.LayerNorm(1024),\n",
    "            t.nn.Linear(1024, 15)\n",
    "        )\n",
    "    def forward(self, tokens, mask):\n",
    "        return self.class_projector(self.feats(tokens, mask, return_dict=False)[0])\n",
    "    \n",
    "model = TvmLongformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef322f72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T05:05:37.943920Z",
     "iopub.status.busy": "2022-02-20T05:05:37.943325Z",
     "iopub.status.idle": "2022-02-20T05:05:38.105465Z",
     "shell.execute_reply": "2022-02-20T05:05:38.104913Z",
     "shell.execute_reply.started": "2022-02-20T04:50:18.063170Z"
    },
    "papermill": {
     "duration": 0.185206,
     "end_time": "2022-02-20T05:05:38.105599",
     "exception": false,
     "start_time": "2022-02-20T05:05:37.920393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dataset(t.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        tokenizer = RobertaTokenizerFast.from_pretrained('../input/feedbackv1/tokenizer')\n",
    "        tokenizer.model_max_length = 4096\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = {}\n",
    "        for fname in glob('../input/feedback-prize-2021/test/*.txt'):\n",
    "            with open(fname) as f:\n",
    "                self.texts[fname.split('/')[-1].split('.')[0]] = f.read().strip()\n",
    "        self.keys = list(self.texts.keys())\n",
    "        self.space_regex = re.compile('[\\s\\n]')\n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "    def __getitem__(self, ix):\n",
    "        tokens_array = np.zeros(4096, 'i8')\n",
    "        mask_array = np.zeros(4096, 'f4')\n",
    "        offsets_array = np.zeros((4096, 2), 'i4')\n",
    "        \n",
    "        text = self.texts[self.keys[ix]]\n",
    "        key = self.keys[ix]\n",
    "        tokenizer_outs = self.tokenizer(text, return_offsets_mapping=True)\n",
    "        tokens = np.array(tokenizer_outs['input_ids'], 'i8')\n",
    "        mask = np.array(tokenizer_outs['attention_mask'], 'f4')\n",
    "        offsets = np.vstack(tokenizer_outs['offset_mapping']).astype('i4')\n",
    "        \n",
    "        tokens_array[:len(tokens)] = tokens\n",
    "        mask_array[:len(tokens)] = mask\n",
    "        offsets_array[:len(tokens)] = offsets\n",
    "        \n",
    "        index_map = []\n",
    "        current_word = 0\n",
    "        blank = False\n",
    "        for char_ix in range(text.index(text.strip()[0]), len(text)):\n",
    "            if self.space_regex.match(text[char_ix]) is not None:\n",
    "                blank = True\n",
    "            elif blank:\n",
    "                current_word += 1\n",
    "                blank = False\n",
    "            index_map.append(current_word)\n",
    "            \n",
    "        return tokens_array, mask_array, offsets_array, index_map, key, len(tokens)\n",
    "    \n",
    "first_batch = True\n",
    "def collate_fn(ins):\n",
    "    global first_batch\n",
    "    if first_batch:\n",
    "        max_len = 2048\n",
    "        first_batch = False\n",
    "    else:\n",
    "        max_len = (max(x[-1] for x in ins) + 7) // 8 * 8\n",
    "    return tuple(t.from_numpy(np.concatenate([ins[z][x][None, :max_len]\n",
    "                                              for z in range(len(ins))]))\n",
    "                 for x in range(len(ins[0]) - 3)) \\\n",
    "                 + ([x[-3] for x in ins], [x[-2] for x in ins], np.array([x[-1] for x in ins]),)    \n",
    "\n",
    "\n",
    "label_names = ['None', 'Lead', 'Position', 'Evidence', 'Claim',\n",
    "               'Concluding Statement', 'Counterclaim', 'Rebuttal']\n",
    "\n",
    "dataset = t.utils.data.DataLoader(Dataset(), collate_fn=collate_fn,\n",
    "                                  batch_size=1, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0b96ab9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T05:05:38.132364Z",
     "iopub.status.busy": "2022-02-20T05:05:38.131501Z",
     "iopub.status.idle": "2022-02-20T05:05:38.133363Z",
     "shell.execute_reply": "2022-02-20T05:05:38.133816Z",
     "shell.execute_reply.started": "2022-02-20T04:50:37.096190Z"
    },
    "papermill": {
     "duration": 0.021113,
     "end_time": "2022-02-20T05:05:38.133936",
     "exception": false,
     "start_time": "2022-02-20T05:05:38.112823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def map_span_to_word_indices(span, index_map, bounds):\n",
    "    return (index_map[bounds[span[0], 0]], \n",
    "            index_map[bounds[span[1], 1] - 1])\n",
    "\n",
    "def calc_entity_score(span, ps, c):\n",
    "    s, e = span\n",
    "    score = (ps[s, c * 2 - 1] + ps[s + 1: e + 1, c * 2].sum())/(e - s + 1)\n",
    "    return score\n",
    "\n",
    "def extract_entities(ps, n):\n",
    "    cat_ps = ps.argmax(-1)\n",
    "    all_entities = {}\n",
    "    current_cat = None\n",
    "    current_start = None\n",
    "    for ix in range(1, n - 1):\n",
    "        if cat_ps[ix] % 2 == 1:\n",
    "            if current_cat is not None:\n",
    "                if current_cat not in all_entities:\n",
    "                    all_entities[current_cat] = []\n",
    "                all_entities[current_cat].append((current_start, ix - 1))\n",
    "            current_cat = (cat_ps[ix] + 1) // 2\n",
    "            current_start = ix        \n",
    "        elif cat_ps[ix] == 0:\n",
    "            if current_cat is not None:\n",
    "                if current_cat not in all_entities:\n",
    "                    all_entities[current_cat] = []\n",
    "                all_entities[current_cat].append((current_start, ix - 1))\n",
    "            current_cat = None\n",
    "        elif current_cat is not None and cat_ps[ix] != current_cat * 2:\n",
    "            if current_cat not in all_entities:\n",
    "                all_entities[current_cat] = []\n",
    "            all_entities[current_cat].append((current_start, ix - 1))\n",
    "            current_cat = None\n",
    "    if current_cat is not None:\n",
    "        if current_cat not in all_entities:\n",
    "            all_entities[current_cat] = []\n",
    "        all_entities[current_cat].append((current_start, ix))\n",
    "\n",
    "#     score_thresholds = [None, -.9 * 5, -.56 * 5, -.55 * 5, -.65 * 5,\n",
    "#                             -.56 * 5, -.76 * 5, -.68 * 5]\n",
    "    \n",
    "    for cat_ix, min_len in zip(range(1, 8), (2, 2, 5, 2, 4, 3, 2)):\n",
    "        if cat_ix in all_entities:\n",
    "            all_entities[cat_ix] = [x for x in all_entities[cat_ix] if x[1] - x[0] + 1 >= min_len]\n",
    "            # and calc_entity_score(x, ps, cat_ix) > score_thresholds[cat_ix]]\n",
    "            \n",
    "        \n",
    "    return all_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "795377a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T05:05:38.150917Z",
     "iopub.status.busy": "2022-02-20T05:05:38.150397Z",
     "iopub.status.idle": "2022-02-20T05:05:41.608335Z",
     "shell.execute_reply": "2022-02-20T05:05:41.607780Z",
     "shell.execute_reply.started": "2022-02-20T04:50:38.314188Z"
    },
    "papermill": {
     "duration": 3.467911,
     "end_time": "2022-02-20T05:05:41.608466",
     "exception": false,
     "start_time": "2022-02-20T05:05:38.140555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# checkpoints = glob('../input/feedbackv1/weights/*attn0')\n",
    "checkpoints = glob('../input/feedbackv2/debertav1/*')\n",
    "model.eval().cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54eb9fcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T05:05:41.630882Z",
     "iopub.status.busy": "2022-02-20T05:05:41.630145Z",
     "iopub.status.idle": "2022-02-20T05:07:02.644754Z",
     "shell.execute_reply": "2022-02-20T05:07:02.644066Z",
     "shell.execute_reply.started": "2022-02-20T04:50:41.619000Z"
    },
    "papermill": {
     "duration": 81.029454,
     "end_time": "2022-02-20T05:07:02.644913",
     "exception": false,
     "start_time": "2022-02-20T05:05:41.615459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_outs = np.zeros((len(glob('../input/feedback-prize-2021/test/*.txt')), 2048, 15), 'f4')\n",
    "all_bounds = np.zeros((len(glob('../input/feedback-prize-2021/test/*.txt')), 2048, 2), 'i4')\n",
    "all_token_nums = np.zeros((len(glob('../input/feedback-prize-2021/test/*.txt')),), 'i4')\n",
    "all_word_indices = []\n",
    "all_sample_ids = []\n",
    "for checkpoint_ix, checkpoint in enumerate(checkpoints):\n",
    "    model.load_state_dict(t.load(checkpoint));\n",
    "    ix = 0\n",
    "    for batch in dataset:\n",
    "        tokens, mask, bounds, word_indices, sample_ids, num_tokens = batch\n",
    "        batch_size, batch_len = tokens.shape[:2]\n",
    "        outs = t.log_softmax(model(tokens.cuda(), mask.cuda()), -1)\n",
    "        all_outs[ix: ix + batch_size, :batch_len] += outs.cpu().numpy()\n",
    "        if checkpoint_ix == 0:\n",
    "            all_bounds[ix: ix + batch_size, :batch_len] = bounds\n",
    "            all_token_nums[ix: ix + batch_size] = num_tokens\n",
    "            all_word_indices.extend(word_indices)\n",
    "            all_sample_ids.extend(sample_ids)\n",
    "        ix += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9efd346e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T05:07:02.670457Z",
     "iopub.status.busy": "2022-02-20T05:07:02.668902Z",
     "iopub.status.idle": "2022-02-20T05:07:02.678793Z",
     "shell.execute_reply": "2022-02-20T05:07:02.678369Z",
     "shell.execute_reply.started": "2022-02-20T04:53:53.557360Z"
    },
    "papermill": {
     "duration": 0.026264,
     "end_time": "2022-02-20T05:07:02.678910",
     "exception": false,
     "start_time": "2022-02-20T05:07:02.652646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_sample_ids = []\n",
    "sub_cat_names = []\n",
    "sub_spans = []\n",
    "for sample_ix in range(len(all_token_nums)):\n",
    "    predicted_spans = {x: [map_span_to_word_indices(span, all_word_indices[sample_ix],\n",
    "                                                    all_bounds[sample_ix]) for span in y] \n",
    "                       for x, y in extract_entities(all_outs[sample_ix], \n",
    "                                                    all_token_nums[sample_ix]).items()}\n",
    "    for cat_ix in predicted_spans:\n",
    "        for entity in predicted_spans[cat_ix]:\n",
    "            sub_sample_ids.append(all_sample_ids[sample_ix])\n",
    "            sub_cat_names.append(label_names[cat_ix])\n",
    "            sub_spans.append(' '.join(str(x) for x in range(entity[0], entity[1] + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4c0daff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-20T05:07:02.706875Z",
     "iopub.status.busy": "2022-02-20T05:07:02.706074Z",
     "iopub.status.idle": "2022-02-20T05:07:02.713743Z",
     "shell.execute_reply": "2022-02-20T05:07:02.714125Z",
     "shell.execute_reply.started": "2022-02-20T04:54:31.840285Z"
    },
    "papermill": {
     "duration": 0.028076,
     "end_time": "2022-02-20T05:07:02.714262",
     "exception": false,
     "start_time": "2022-02-20T05:07:02.686186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'id': sub_sample_ids, \n",
    "              'class': sub_cat_names,\n",
    "              'predictionstring': sub_spans}).to_csv('submission.csv', index=False);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 117.383581,
   "end_time": "2022-02-20T05:07:06.356701",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-20T05:05:08.973120",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
